%Tipo de documento
    \documentclass{article}
%Temas de matematica
    %Usar expresiones matematica
    \usepackage{amsmath}
    %Encuadrar enunciados (teoremas, corolarios, lemas)
    \usepackage{mdframed}
    %Paquete para cambiar los estilos de teoremas.
    \usepackage{amsthm}
    %Images
    \usepackage{graphicx}
    %Para usar mathbb
    \usepackage{amsfonts}
    %Alinear matrices
    \usepackage{mathtools}
%Temas de idioma
    % Set the font (output) encodings
    \usepackage[T1]{fontenc}
    % Spanish-specific commands
    \usepackage[spanish]{babel}
    % Simbolos
    \usepackage{amssymb}
%Usando mdframed para dar un contorno negro a los enunciados
    \theoremstyle{definition}
      \newmdtheoremenv{teo}{Teorema}
      \newmdtheoremenv{lema}{Lema}
      \newmdtheoremenv{defi}{Definición}
      \newmdtheoremenv{corol}{Corolario}
      \newmdtheoremenv{axi}{Axioma}
%Para poder usar Enunciados
    %El estilo dentro del los enunciados (de letra, espaciado, etc)
    \theoremstyle{definition}
    %Todos estos estan con el \theoremstyle{definition}
    \newtheorem*{obs}{Observación}
    \newtheorem{prop}[teo]{Proposición}
    \newtheorem*{ej}{Por ejemplo}
    \newtheorem*{notacion}{Notación}
    %
    \theoremstyle{remark}
    \newtheorem*{demo}{Demostración}
%Estilos de letra
    % \textbf{ }               Negrita.
    % \underline{ }            Subrayado.
    % \textit{ }               Cursiva.
%Enunciados: Teoremas, lemas, corolarios.
    % \begin{theorem}[ ]       Teorema. [nombre del teorema](opcional)
    % \begin{corollary}[ ]     Corolario
% These are the fancy headers
    \usepackage{fancyhdr}
    \pagestyle{fancy}
    % LE: left even
    % RO: right odd
    % CE, CO: center even, center odd
    \fancyhead[R]{\today}%Numero de clase} % Right odd,  Left even
    \fancyfoot[R]{\thepage}  % Right odd,  Left even
    \fancyfoot[C]{\leftmark}     % Center
    \fancyfoot[L]{Hecho por Jx.}     % Center
    \makeatother
%No indentacion al iniciar un parrafo.
\setlength{\parindent}{0cm}
%Shortcuts para simbolos de matematica
    \newcommand\N{\ensuremath{\mathbb{N}}}
    \newcommand\R{\ensuremath{\mathbb{R}}}
    \newcommand\Z{\ensuremath{\mathbb{Z}}}
    \renewcommand\O{\ensuremath{\emptyset}}
    \newcommand\Q{\ensuremath{\mathbb{Q}}}
    \newcommand\C{\ensuremath{\mathbb{C}}}
    \newcommand\fun{$f$\;}
    \newcommand\I{$I$\;}
    \newcommand\e{$\in$\:}
    \newcommand\bl{$\bullet\;$}
    \newcommand\U{\cup}
    \newcommand\ok{\checkmark}
    \newcommand\qtilde{\overset{\sim}{q}}
    \newcommand\ptilde{\overset{\sim}{p}}
    \newcommand\infi{\infty}
%Imagenes con inkscape
    \usepackage{graphicx}
    \graphicspath{{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras}}    %Folder en el mismo directorio que .tex donde estan las imagenes
    %Para escalar la imagen
    %Para omitir warnings boludas
   %Para meter el archivo con latex adentro de golpe
    %\input{<filename>.pdf_tex}
    %Paquetes para que ande el tema este
    \usepackage{color}
    \usepackage{import}
    %iz y der imagen
    \usepackage{subfigure}
%Algunos colores
    \usepackage{xcolor}
    %Colores pastel
    \definecolor{verdep}{RGB}{61, 184, 143}
    \definecolor{rojop}{RGB}{227, 93, 133}
    \definecolor{azulp}{RGB}{22, 69, 122}
    %v2
    \definecolor{verdep2}{RGB}{78, 204, 190}
    \definecolor{rojop2}{RGB}{225, 131, 48}
    \definecolor{azulp2}{RGB}{36, 115, 171}
    %v2prima
    \definecolor{azulp2prima}{RGB}{150,186,255}
    \definecolor{rojop2prima}{RGB}{225,131,140}
%Mostrar toda 'math' en grande.
    \everymath{\displaystyle} 
%Para graficar 
    \usepackage{pgfplots}
    \def\FunctionF(#1){(#1)^3- 3*(#1)}%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\tableofcontents

\section{Integrales}
$ \bullet $ En AM1 se introdujo el concepto de derivada de una función. Dada $f$ se define la función $f'$ como $f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$.

\begin{center}
\textbf{Algunas de las propiedades de la derivada son:}
\end{center}

\begin{enumerate}
  \item Si $f(x)\;\;\;\;\;\;\;=c$ \;\text{(constante)} \quad $\Rightarrow$ \quad \; $f'(x)=0$
  \item $(a \cdot f)'(x) \;\;\;= a\cdot f'(x) $
  \item $(f\pm g)'(x)'   = f'(x)\pm g'(x)$
  \item $(f\cdot g)'(x)' \;\;=f'(x)\cdot g(x)+f(x)\cdot g'(x)$
  \item $(fog)'(x)'      \;\;=f'(g(x))\cdot g'(x)$ \quad \quad (Regla de la cadena)
\end{enumerate}

$\bullet$ Ahora nos interesa estudiar el concepto ``inverso'' a la derivacion, esto es:
\[\boxed{\text{Dada una función $f$, encontrar $F$ tal que $F'(x)=f(x)$.}}\]
$\bullet$ Sabemos dada $F$ encontrar $F'$ (derivacion). \\
$\bullet$ Problema a resolver, dada $f=F'$ encontrar $F$ (integración).

\begin{defi}
  Sea $I \in \R$ un intervalo y $f : I \to \R $ una funcion. \\
  Decimos que $F : I \to \R $ es una antiderivada o primitiva de $f$ en $I$ si
  \center{$F'(x)=f(x)$\quad $\forall x \in I$}.
\end{defi}

\begin{obs}
  Las primitvas \underline{\textbf{no}} son únicas. \\
  Por ejemplo, si $f(x)=x$ entonces $F_1(x)=\frac{x^2}{2}$ y $F_2(x)=\frac{x^2}{2}+3$ son primitivas de $f$ ya que $F_1'=x=f(x)$ y $F_2'(x)=x=f(x)$.
\end{obs}

El siguiente teorema nos dice que las primtivas de una funcion \fun difieren en una constante.

\begin{teo}
Si $F$  es una primitiva de \fun en $I$, entonces toda primitiva de \fun en $I$ es de la forma $F(x)+c$ para alguna constante $c \in \R $
\end{teo}

\begin{demo}
Sea $G$ una primitiva de $f$ en $I$, o sea $G'(x)=f(x)$\quad$\forall x \in I$. \\
Queremos ver que $G(x)=F(x)+c$
$$H'(x)=G'(x)-F'(x)=f(x)-f(x)=0.$$
Por lo tanto $H(x)=c$\quad$\forall x \in I$, o sea $G(x)=F(x)+C$\quad $\forall x \in I$ \qed
\end{demo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defi}
  Dado \I \e \R \; y $f : I \to \R $, se llama \underline{integral indefinida} de \fun al \underline{conjunto de} todas las \underline{primitivas} de \fun y se denota $\int{f(x)\;dx}$
\end{defi}

\begin{obs}
A tener en cuenta: \\
1) El símbolo $\int$ se llama integral y $dx$ se llama diferencial (de $x$).
Ademas, denotamos por diferencial de una funcion $F$ a $d(F(x))=F'(x)\;dx$.\\
2) En la definición de integral indefinida podríamos usar otra letra. Por ejemplo $$\int{f(y)\;dy},\int{f(t)\;dt,\;etc}$$
\end{obs}

\begin{ej}
Algunos ejemplos son: \; \\\\
\bl $\int{cos(x)\;dx=sen(x)+c}$,\quad con $c\in\R$ ya que $(sen(x)+c)'=cos(x)$ \\

\bl $\int{x}\;dx=(\frac{x^2}{2}+c)'=2\frac{x}{2}=x$.\\\\
En general, si $n\in\R$ y $n\neq -1$ tenemos que $(x^{n+1})'=(n+1)x^n$, con lo cual \\
$\int{x^n\;dx}=\frac{x^{n+1}}{n+1}+c$,\quad con $c\in\R$\\

\bl $\int{tx\;dx}=t\frac{x^2}{2}+c$,\quad pero $\int{tx\;dt}=x\frac{t^2}{2}+c$\\\\
El diferencial nos indica cual es la variable de integración.
\end{ej}

\begin{center}
\textbf{Algunas propiedades de la integral indefinida:}
\end{center}

\begin{enumerate}
  \item $\int{0\;dx}=c$.
  \item $\int{a\cdot f(x)\;dx=a\cdot \int{f(x)\;dx}},\quad \forall a \in \R $.
  \item $\int{(f\pm g)(x)\;dx=\int{f(x)\;dx\pm \int{g(x)\;dx}}}$.
\end{enumerate}

\begin{ej} Integral de una suma. \\
  $\int{(e^x+4x^2+3)\;dx}=\int{e^x\;dx}+4\int{x^2\;dx}+\int{3\;dx}=e^x+\frac{4}{3}x^3+3x+c,\quad c \in \R$.
\end{ej}

El siguiente teorema es el ``equivalente'' a la propiedad $(5)$ de derivacion.
\pagebreak
\begin{teo}[Método de sustitución]$\;$  \\
Sean $f:(d,e)\to \R$ y $g:(a,b,)\to(d,e)$ derivable en su dominio.\\ Entonces si $F$ es una primitiva de $f$ en $(d,e)$, $H(x)=(Fog)(x)$ es primitiva de $h(x)=f(g(x))\cdot g'(x)$ en $(a,b)$. O sea,
\[
\int{f(g(x)) \cdot g'(x)dx}=F(g(x))+c,\quad \text{con}\; c\in\R \;\text{y}\; \forall x \in (a,b).
\]
\end{teo}

\begin{demo} \; \\
  Basta verificar que $H'(x)=h(x)\quad \forall x \in (a,b)$. Por la regla de la cadena tenemos que \[
  H'(x)\overset{(1)}{=}F(g(x))'\overset{(2)}{=}F'(g(x))\cdot g'(x) \overset{(3)}{=} f(g(x)) \cdot g(x)' = h(x) \quad \forall x \in (a,b). \qed \]
(1) Definición.   \\
(2) Regla de la cadena.   \\
(3) Hipótesis: $F$ es primitiva de $f$.
\end{demo}

\begin{obs} \; \\
  El teorema anterior nos provee un método para calcular primitivas para funciones de la forma $f(g(x))\cdot g'(x)$. En efecto, hagamos la siguiente sustitucion: $u=g(x)$ y $ du=d(g(x))=g'(x)dx$.\\
  Luego, \[
  \int{f(\underbrace{g(x)}_{u})\cdot \underbrace{g'(x)dx}_{du}}=\int{f(u)du}\overset{(1)}{=}F(u)+c=F(g(x))+c
\]
(1) $F$ primitiva de $f$.
\end{obs}

\begin{ej} \; \\

\bl $\int{sen(x^2)2x\;dx}.\quad$ Sea $u=x^2$,\quad $du=2xdx$.
\\Entonces\[
\int{sen(x^2)2x\;dx}=\int{sen(u)du}=-cos(u)+c=-cos(x^2)+c. \]
\\
\bl ${\int{e^{3x}\;dx}}\overset{1}{=}\int{e^u}\frac{1}{3}\;du=\frac{1}{3}\int{e^u\;du}=\frac{1}{3}e^u+c=\frac{1}{3}e^{3x}+c$.\\
(1) $u=3x,\quad du=3dx$
\end{ej}
El siguiente teorema es el ``equivalente'' a la propiedad $(4)$ de derivación. 
\pagebreak
\begin{teo}[Método de integración por partes]\; \\
Si $f'$ y $g'$ son continuas, entonces \[
\int{f(x)\cdot g'(x)\; dx}=f(x)\cdot g(x) - \int{f'(x)g(x)\;dx}\quad \quad (*) \]
\end{teo}
\begin{demo} \; \\
  Por la regla de la derivación del producto de funciones $Prop (4)$ tenemos que
\begin{align*}
    (f\cdot g)'(x)  &= f'(x)g(x)+f(x)g'(x),\quad \text{o equivalentemente}\\
    f(x)\cdot g'(x) &= (f\cdot g)'(x)-f'(x)g(x).
\end{align*}
Integrando a ambos lados obtenemos
\[
\int{f(x) \cdot g'(x)\; dx}=\int{(f\cdot g)'(x)\;dx}-\int{f'(x)\cdot g(x)\; dx}\overset{1}{=}f(x)\cdot g(x)-\int{f'(x) g(x)\; dx}\]
(1) Pues $f\cdot g$ es primitiva de $(f\cdot g)'$.  \qed
\end{demo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{obs} \; \\
  La ecuacion (*) se llama fórmula de integración por partes. Resulta más fácilñ recordarla utilizando la siguiente notación.
\[
  \begin{array}[t]{llcl}
  Si       & $\;\;u=f(x)$     & y & $\;\;v=g(x)$ \\
  Entonces & $du=f'(x)dx$ & y & $dv=g'(x)dx$,
    \end{array}
\]
luego $(*)$ se reescribe como $\int{u\cdot dv}=u\cdot v-\int{v\cdot du}$.
\end{obs}

\begin{ej} Algunos ejemplos son: \\

\bl $\int{\underbrace{x}_u\underbrace{e^x\;dx}_{dv}}$\quad.\quad Si \
$\begin{array}{l}
\;\;u=x\\
dv=e^xdx
\end{array}$, entonces \
$\begin{array}{l}
du=1dx \\
\;\;v=e^x
\end{array}$, con lo cual \\\\
$\int{xe^x\;dx}=xe^x-\int{e^x\cdot1\cdot dx}=xe^x-e^x+c$
\\\\

\bl $
\int{\underbrace{x}_{\underset{du=dx}{u}} \underbrace{sen(x)dx}_{\underset{v=-cos(x)}{dv}}}=x\cdot(-cos(x))-\int(-cos(x))dx=-x\cdot cos(x)+\int{cos(x)dx} \overset{\cdot}{=}$ \\ $\overset{\cdot}{=}-x\cdot cos(x) +sen(x)+C$ \\\\

\bl  $\int{ln(x)\;dx}=\int{
\underbrace{ln(x)}_{
\underset{du=\frac{1}{x}dx}{u}
}
\underbrace{1dx}_{
\underset{v=x}{dv}}
}
= ln(x)\cdot x-\int{x\cdot \frac{1}{x}dx}=ln(x)\cdot x-\int{1dx}\overset{\cdot}{=}\\\overset{\cdot}{=}xln(x)-x+c
$.
\end{ej}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\textbf{Algunas propiedades de la integral indefinida:}
\end{center}
\underline{Área bajo una curva:}
\\ \\
 Sea $f : [a,b] \to \R $ una función continua y tal que
$f(x) \geq 0 \quad \forall x\in [a,b]$.
\\
¿Cuál es el valor del área $A$ comprendida entre la curva $y=f(x)$, el eje $x$ y las rectas $x=a$ y $x=b$?

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v4.pdf_tex}
\end{figure}

$\bullet$ Primera aproximación: Sean $\begin{array}{l}
m_k  \;$=$\;  minimo\; de\; $f$\; en $\;[a,b]$ \\
M_k  \;$=$\;  maximo\; de\; $f$\; en $\;[a,b]$
  \end{array}$

\[
\boxed{
\text{$a_1=m\cdot (b-a) \leq A \leq M \cdot (b-a) = A_1$}
}
\]\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/vbien.pdf_tex}
\end{figure}

$\bullet$ Segunda aproximación: Particionamos el intervalo $[a,b]$ como \\
\[[a,b] = [a,x_1] \; \U \; [x_1,b]=[x_0,x_1]\; \U \; [x_1,x_2]\]

Si $\begin{array}{l}
$$m_k$  \;$=$\;  minimo\; de\; $f$\; en $\;$$[x_k,x_{k+1}]$$ \\
$$M_k$  \;$=$\;  maximo\; de\; $f$\; en $\;$$[x_k,x_{k+1}]$$
  \end{array}$, $k=0,1$. \\\\

  \begin{figure}[h]
  \centering
  \def\svgwidth{0.55\textwidth}
  \input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v6.pdf_tex}
  \end{figure}
  Entonces
  $$ a_1 \leq a_2 = m_0 (x_1-x_0)+m_1(x_2-x_1) \leq A \leq M_0 (x_1 - x_0) + M_1 (x_2 - x_1) = A_2 \leq A_1$$\\
\bl De manera general, tomamos $a=x_0 < x_1 < \cdots < x_{n-1}<x_n=b $ una particion de $[a,b]$. \\\\
Si denotamos $\begin{array}{lcl}
\Delta_k = x_{k+1}-x_n & \text{y} & \Delta \; \text{al mayor de todos los}\;  \Delta_k \\
m_k=\text{minimo de} & f & \text{en} [x_k,x_{k+1}] \\
M_k=\text{minimo de} & f & \text{en} [x_k,x_{k+1}] \quad \quad \text{con}\;  k=0, \dots , n-1\\
  \end{array}$\\\\
entonces es claro que
\[
\begin{array}{c}
  suma \\
  inferior
\end{array} \longleftarrow \sum_{k=0}^{n-1}{m_k\Delta_k}\leq A \leq \sum_{k=0}^{n-1}{M_k\Delta_k} \longrightarrow \begin{array}{c}
  suma \\
  superior
\end{array}
\]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defi} \; \\
  Sea $f : [a,b] \to \R$ continua y tal que $f(x) \geq 0 \quad \forall x \in [a,b]$, se define el área encerrada por la curva $y=f(x)$, el eje $x$ y las rectas $x=a$ y $x=b$ por \[
\text{A} = \lim_{\Delta \to 0}\left( \sum_{k=0}^{n-1}{m_k\Delta_k}\right)
  \]
Llamaremos a este \underline{\textbf{número} integral definida} de $f$ en $[a,b]$ y lo denotaremos por $\int_{a}^{b}{f(x)\;dx}$.
\end{defi}
\begin{obs} \; \\
    \begin{enumerate}
      \item Se puede probar que tomar el límite de las sumas superiores coincide con tomar el límite de las sumas inferiores, es decir
      \[
    \text{A} =\int_{a}^{b}{f(x)\; dx}= \lim_{\Delta \to 0}\left( \sum_{k=0}^{n-1}{M_k\Delta_k}\right)=\lim_{\Delta \to 0}\left( \sum_{k=0}^{n-1}{m_k\Delta_k}\right)
      \]
      \item Para el caso $a=a$, se define $\int_{a}^{b}{f(x)\;dx}=0$. Además de la definición se puede probar que $\int_{a}^{b}f(x)\; dx=-\int_{b}^{a}{f(x)\;dx}$.
      \item La integral definida se puede extender a funciones que tomen valores positivos y negativos, escribiendo $f(x)=f^+(x)-f^-(x)$ con $\begin{array}{lcl}
f^+(x)= & \text{máx}  (\phantom{-}f(x),0) \geq 0 \\
f^-(x)= & \text{máx}  (-f(x),0) \geq 0 \\
  \end{array}$\\


  \begin{figure}[h]
      \centering
      \subfigure[]{\includegraphics[width=0.40\textwidth]{Figuras/v7prima.pdf}}
      \quad \quad \quad \quad
      \subfigure[]{\includegraphics[width=0.40\textwidth]{Figuras/v7.pdf}}
  \end{figure}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \pagebreak
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \item También se puede extender la definición a funciones continuas $[a,b]$ salvo un numero \underline{finito} de puntos y siempre que $f$ esté \underline{acotada} en $[a,b]$

      \begin{figure}[h]
      \centering
      \def\svgwidth{0.55\textwidth}
      \input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v8.pdf_tex}
      \end{figure}
\end{enumerate}
\end{obs}

\begin{center}
\textbf{Algunas propiedades de la integral definida:}
\end{center}
Sean $f,g : [a,b] \to \R $ funciones acotadas y continuas, salvo a lo sumo en un número finito de puntos. Las siguientes son válidas:
\begin{enumerate}
  \item Si $f \geq 0 $ en $[a,b]$ $\Rightarrow$ $\int_{a}^{b}f(x)\; dx \geq 0$.
  \item $\int_{a}^{b}c\;f(x)\;dx=c\int_{a}^{b}f(x)\;dx,\quad \forall c \in \R $.
  \item $\int_{a}^{b}{(f(x) \pm g(x))\;dx}=\int_{a}^{b}{f(x)} \; dx \pm \int_{a}^{b} {g(x)} \; dx$.
  \item Si $d \in [a,b],\quad  \int_{a}^{b}f(x)\;dx=\int_{a}^{d} f(x)\;dx+\int_{d}^{b} f(x)\;dx$.
  \item Si $f \leq g \; \text{en} \; $[a,b]$, \quad \int_{a}^{b}{f(x)\;dx}\leq\int_{a}^{b}{g(x)\;dx}$.
\end{enumerate}
\pagebreak
\begin{center}
\textbf{Relación entre la integral definida y la integral indefinida/primitiva:}
\end{center}
\begin{teo}[Teorema Fundamental del Cálculo] \; \\
  Sea $f : [a,b] \to \R $ continua y $F(x):=\int_{a}^{x}f(t)\;dt,\;\forall x \in [a,b]$. Entonces\\\\
  \emph{\phantom{i}(i)}\quad$F$ es derivable y $F'(x)=f(x)\quad \forall x \in (a,b)$. O sea, $F$ es primitiva de $f$. \\
  \emph{(ii)}\quad  Si $g$ es una primitiva de $f$ en $[a,b]$, entonces $\int_{a}^{b}{f(t)\;dt}=G(b)-G(a)$. \\\\
  \emph{Notas: \\ \bl $G(b)-G(a)$ se suele definir como $G(x)|^b_a$. \\\bl La parte (ii) se conoce como \emph{Regla de Barrow}.}
\end{teo}

\begin{demo} \; \\
  \emph{(i)} (Sólo la idea) Queremos ver que $F'(x)=f(x).$ \\
  Sean $h>0$ y $
  \begin{array}{l}
m_h = min \; f \; en \;  [x,x+h] \\
M_h = max \; f \; en \;  [x,x+h]
    \end{array} \quad \\\\ \therefore \; m_h \leq f(x) \leq M_h \quad \forall x \in [x,x+h]$\\ \\
Tenemos que \\
\[
F(x+h)-F(x)=\int_{a}^{x+h}{f(t)dt} - \int_{a}^{x}{f(t)dt} = \int_{a}^{x}{f(t)dt}+\int_{x}^{x+h}{f(t)dt}-\int_{a}^{x}{f(t)dt}=\int_{x}^{x+h}{f(t)dt.}
\]
Entonces
\[
m_h\cdot h \leq F(x+h) -F(x) \leq M_h\cdot h, \; \text{o equivalentemente} \; m_h \leq \frac{F(x+h)-F(x)}{h} \leq M_h.
\]
Luego, como $f$ es continua $\begin{array}{c}
m_h \to f(x) \\
h \to 0\phantom{x}
\end{array}$ y $\begin{array}{c}
  M_h \to f(x) \\
  h \to 0\phantom{x}
\end{array}$.\\
 $\therefore$ $f(x) \leq F'(x)\; \leq f(x)$.
\\
\\
\emph{(ii)} Por la parte \emph{(i)} sabemos que $F$ es primitiva de $f$. Luego, si $G$ es otra primitiva de $f$ $\exists c \in \R \; tq. \; G(x)=F(x)+c, \quad \forall x \in [a,b]$.  Entonces tenemos que \[
G(b)-G(a)=\left(F(b)+c)\right) - \left( F(a)+c \right) = F(b)-F(a)=\int_{a}^{b}{f(t)dt}-\underbrace{\int_{a}^{a}{f(t)dt}}_{=\;0}=\int_{a}^{b}{f(t)dt}.
\] \qed
\end{demo}
\begin{obs}
  Si $f$ es acotada y con un número finitio de discontinuidades en $[a,b]$, también podemos aplicar \emph{(ii)} del Teorema en cada subintervalo donde $f$ es continua gracias al siguiente teorema:
\end{obs}

\begin{teo} Sean $f,g : [a,b] \to \R $, con $f$ continua y $g$ tq. $g(x)=f(x) \quad \forall x \in [a,b]$. Entonces,\[
\int_{a}^{b}{f(x)dx}=\int_{a}^{b}{g(x)dx}.
  \]
\end{teo}
\begin{ej}
  Apliquemos la Regla de Barrow a
  $f(x)=\left\{ \begin{array}{lr}
x+2   & \text{si} \; 0 \leq x < 1 \\
x^3-1 & \text{si} \; 1 \leq x \leq 2
    \end{array}\right.$
    \\
\begin{flalign*}
\int_{0}^{2}{f(x)dx} & =\int_{0}^{1}{f(x)dx}+\int_{1}^{2}{f(x)dx} &\\
                     & =\int_{0}^{1}{(x+2)dx}+\int_{1}^{2}{(x^3-1)dx} &\\
                     & =\left. \left( \frac{x^2}{2}+2x \right) \right\vert^{1}_{0} +   \left. \left( \frac{x^4}{4}-x \right) \right\vert^{2}_{1} \quad =\quad\frac{5}{2}-0+2+\frac{3}{4} \quad = \quad \frac{21}{4} &\\
\end{flalign*}
\begin{figure}[h!]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v9.pdf_tex}
\end{figure}
\end{ej}
\pagebreak
\begin{teo}[Método de sustitución]Sean $f: [c,d] \to \R $ y $ g:[a,b] \to [c,d]$ tq. $f$ y $g'$ son continuas en sus respectivos dominios. Entonces, si $u=g(x)$ vale que \[ \
\int_{a}^{b}{f(g(x))\cdot g'(x)dx}=\int_{g(a)}^{g(h)}{f(u)du}.
\]
En particular, si $F$ es primtiiva de $f$ tenemos que $$\int_{a}^{b}{f(g(x))\cdot g'(x)dx}=F(g(b))-F(g(a))$$.
\end{teo}
\begin{ej}
  Calcular $\int_{0}^{2}{2x\; sen(x^2)dx}$ \\
Sea $u=x^2$, entonces $du=2xdx$, $u(0)=0^2=0$ y $u(2)=2^2=4$. Luego, \[
\int_{0}^{2}{2x\;sen(x^2)dx}=\int_{0}^{4}{sen(u)du}=-cos(u)\vert_{0}^{4}=-cos(4)+cos(0).
\]
\end{ej}

\begin{teo}[Integración por partes] Sean $f$ y $g$ derivables en $(a,b)$ y tq. $f'$ y $g'$ tienen a lo sumo un número finito de discontinuidades en $[a,b]$ y son acotadas. Entonces
  \[
\int_{a}^{b}{
\underset{\textcolor{red}{u}}{f(x)} \cdot
\underset{\textcolor{red}{dv}}{g'(x)}
}
=
\underset{\textcolor{red}{u}}{f(x)}\underset{\textcolor{red}{v}}{g(x)}\vert_a^b - \int_{a}^{b}{
\underset{\textcolor{red}{v}}{g(x)}
\underset{\textcolor{red}{du}}{f'(x)}dx
}
  \]
\end{teo}
\begin{ej}
    \[
    \int_{1}^{e}{ln(x)dx}=\int_{1}^{e}{ln(x)\;1dx}=ln(x) \cdot x\vert_1^e-\int_{1}^{e}{x\cdot \frac{1}{x}dx}=e-0-x\vert_1^e=e-(e-1)=1.
    \]
\end{ej}

\begin{center}
\textbf{Área entre gráficos de funciones.}
\end{center}
\bl Si $f : [a,b] \to \R $ es no negativa, acotada y con un número finito de discontinuidades, hemos definido el área A entre el gráfico de $f$, y el eje $x$ y las rectas verticales $x=a$ y $x=b$ como \[
\text{A} = \int_{a}^{b}{f(x)dx}.
\]
\bl Si $f(x) \geq g(x) \geq 0 \quad \forall x \in [a,b] $ es razonable definir el área entre los gráficos de $f$ y $g$ (y las rectas $x=a$ y $x=b$) como \[
\text{A} = \int_{a}^{b}{(f(x)-g(x))dx}, \quad \text{ya que}\; f(x)-g(x) \geq 0 \quad \forall x \in [a,b].
\]
Además por las propiedades de la integral definida \[
\text{A} = \int_{a}^{b}{(f(x)-g(x))dx}=\int_{a}^{b}{f(x)dx}-\int_{a}^{b}{g(x)dx}=\text{A}_1-\text{A}_2.
\]

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v10.pdf_tex}
\end{figure}
\begin{teo}
  Sea $f$ y $g$ funciones acotadas, con un número finito de discontinuidades y tales que $f(x) \geq g(x) \quad \forall x \in [a,b]$. Entonces, el área entre los gráficos de $f$ y $g$ y las rectas $x=a$ y $x=b$ es \[
\text{A} = \int_{a}^{b}{\underbrace{f(x)-g(x)}_{\geq \; 0}dx}
  \]
\emph{Notar que $f(x) \geq g(x)$ nos dice que $f(x)-g(x)\geq 0 \quad \forall x \in [a,b]$. }
\end{teo}

\begin{obs}
  En el caso en que los gráficos se crucen, calculamos el área por partes.

\begin{figure}[h]
\centering
\def\svgwidth{0.35\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v11.pdf_tex}
\end{figure}
$$
\text{A}=\int_{a}^{c}{(f(x)-g(x))dx}+\int_{c}^{b}{(g(x)-f(x))dx}
$$
\end{obs} 
\pagebreak
\begin{ej}
  Primero grafiquemos $f$ y $g$ en $[-1,4]$
  \begin{figure}[h]
  \centering
  \def\svgwidth{1.20\textwidth}
  \input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v12.pdf_tex}
  \end{figure}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v13.pdf_tex}
\end{figure}
\begin{flalign*}
\text{\textcolor{red}{A}}    & =\int_{-1}^{0}{\big((x^2-4x)-x\big)dx}+\int_{0}^{4}{\big(x-(x^2-4x)\big)dx} \quad \quad
  \big( \textcolor{red}{\text{A}}=\textcolor{red}{\text{A}_1}+\textcolor{red}{\text{A}_2}\big) & \\
     & = \int_{-1}^{0}{(x^2-5x)dx}+\int_{0}^{4}{(5x-x^2)dx}=\left.\left(\frac{x^3}{3}-5\frac{x^2}{2}\right)\right\vert_{-1}^0 + \left.\left(5\frac{x^2}{2}-\frac{x^3}{3}\right)\right\vert_0^4                       &\\
     & = - \left(-\frac{1}{3}-\frac{5}{2}\right)+\left(40-\frac{64}{3}\right)= \cdots \textcolor{red}{\geq 0}
\end{flalign*}
\end{ej}
\pagebreak

\begin{center}
\textbf{Integración de funciones racionales usando fracciones simples:}
\end{center}
\bl Queremos integrar funciones que son cocientes de polinomios (funciones racionales), o sea $\int{\frac{P(x)}{Q(x)}dx}$. \\
Hay algunas que ya sabemos integrar, por ejemplo \[
\int{\frac{1}{x-2}dx}=ln\left(x-2\right)+c, \quad
\int{\frac{1}{x+3}dx}=\frac{(x+3)^{-2}}{-2}+c=\frac{-1}{2(x+3)^2}+c,
\]
pero otras más complicadas no sabemos, por ejemplo $\int{\frac{x^2+3x}{x^3-1}dx}.$ \\\\

\bl De ahora en más vamos a suponer que la función racional $\frac{p(x)}{q(x)}$ satisface:

\begin{enumerate}
  \item gr(p)<gr(q) \quad \quad \quad \big($gr(p)$ \text{es el grado del polinomio} $p$\big) \\
  \text{Ya que si no fuera cierto hacemos la división de $p(x)$  por $q(x)$ y por lo tanto}\\
\begin{center}
  $\frac{p(x)}{q(x)}=\underbrace{Q(x)}_{\textcolor{red}{\underset{\textcolor{red}{\text{de integrar $\checkmark$}}}{\textcolor{red}{\text{polinomio fácil}}}}}+\frac{r(x)}{q(x)},\quad$
\end{center}
  \text{donde} $r(x)$ \text{es}\; \text{el resto que satisface}\; $gr(r)<gr(q)$,\\
  $\Rightarrow$ saber integrar $\frac{p(x)}{q(x)}$ se traduce en saber integrar $\frac{r(x)}{q(x)}$ con $gr(r)<gr(q)$. \\
  \item El coeficiente que acompaña a la potencia de mayor grado de $q$ es $1$. \\
              Ya que si no fuera cierto hacemos
              \[
\frac{p(x)}{q(x)}=\frac{p(x)}{a_nx^n+a_{n-1}x^{n-1}+ \dots + a_0}=\frac{p(x)}{a_n\underbrace{\left(x^n+\frac{a_{n-1}}{a_n}x^{n-1}+\dots+\frac{a_0}{a_n}\right)}_{\textcolor{red}{\overset{\sim}{q}(x)}}{}}=\frac{p(x)/a_n}{\overset{\sim}{q}(x)}=\frac{\overset{\sim}{p}(x)}{\overset{\sim}{q}(x)}.
              \]
con $\qtilde$ $(x)$ (es decir es mónico).\\\\
Utilizaremos el siguiente teorema para factorizar al polinomio $q(x)$.
\end{enumerate} 
\pagebreak
\begin{teo}
  Todo polinomio mónico se puede escribir como producto de polinomios de grado $1$ y/o polinomios de grado $2$ \underline{sin} raices reales.\\
  O sea, si \\
  $q(x)=x^n+a_{n-1}x^{n-1}+\dots + a_0$, entonces \\
   $q(x)=(x-r_1)\dots(x-r_k)\underbrace{(x^2+\alpha_1x+\beta_1)\dots (x^2+\alpha_lx+\beta_l)}_{\text{\textcolor{red}{sin raíces reales}}}$
\end{teo}

\begin{ej} \; \\
  $\phantom{1}x^3+2x^2-3x=x(x^2+2x-3)=x(x-1)(x+3)$ ; \\
  $\phantom{1}x^2-2x\phantom{^x}+1\phantom{x}=(x-1)^2$ \\
  $3x^3+3x^{\phantom{x}}\phantom{-2xx}=3x\underbrace{(x^2+1)}_{\textcolor{red}{\text{sin raíces reales}}}$
\end{ej}

\bl Para \textbf{calcular} $\int{\frac{p(x)}{q(x)}dx}$, suponemos $gr(p)<gr(q)$ y $q$ mónico (sino hacemos lo que dijimos antes). Vamos a separar en casos según cómo se factoriza $q$. \\

\underline{\textbf{Caso 1:}} $q$ es producto de polinomios de grado $1$ y todos distintos. O sea, \[
q(x)=(x-r_1)\dots(x-r_k),\quad \text{con} \; r_j \neq r_i \; \; \text{si} \; \; j \neq i.\]
En este caso buscamos constante $\text{A}_1, \dots , \text{A}_k$ (una constante por cada polinomio de grado $=1$) tales que \[
\frac{p(x)}{q(x)}=\frac{\text{A}_1}{x-r_1}+ \dots + \frac{\text{A}_k}{x-r_k} \quad,\quad \text{luego cada término $\frac{A_i}{(x-r_i)}$ es muy facil de integrar \ok}.
\]

\begin{ej}
  Calcular $\int{\frac{7x-1}{x^2-x-6}dx}$.\\
  Tenemos que $q(x)=x^2-x-6=(x-3)(x+2).$ Entonces debemos hallar A$_1$ y A$_2$ tq \[
\frac{7x-1}{(x-3)(x+2)}
=
\frac{A_1}{x-3}+\frac{A_2}{x+2}
=
\frac{A_1(x+2)+A_2(x-3)}{(x-3)(x+2)}
=
\frac{(A_1+A_2)x+(2A_1-3A_2)}{(x-3)(x+2)}.
  \]
  Igualando los coeficientes de los numeradores tenemos que\\
  $\begin{array}{llll}
\phantom{-}7=A_1+A_2 & \longrightarrow A_1=7-A_2 & & \\
-1=2A_1-3A_2 & \longrightarrow -1=14-2A_2-3A_2 & \longrightarrow -15 =-5A_2 & \Longrightarrow A_2=3 \; \text{y} A_1 = 4.
  \end{array}$\\\\
Luego
$$\int{\frac{7x-1}{x^2-x-6}dx}
=
\int{\frac{4}{x-3}dx}+\int{\frac{3}{x+2}dx}=4\; ln(|x-3|)+3\; ln (|x+2|)+c$$
\end{ej}

\underline{\textbf{Caso 2}}: $q$ es producto de polinomios de grado $1$ \textbf{todos iguales}. O sea $q(x)=(x-r)^k$. \\
En este caso buscamos constantes $A_1 , \dots , A_k$ (tantas como grado de $q$) tales que \[
\frac{p(x)}{q(x)}
=
\frac{A_1}{(x-r)^1}+\frac{A_2}{(x-r)^2} + \dots + \frac{A_k}{(x-r)^k}
\]
Luego, cada termino $\frac{A_i}{(x-r)^i}$ es fácil de integrar $\ok$.

\begin{ej}
Calcular $\int\frac{1-2x}{(x+2)^3}dx$.\\
Tenemos que $q(x)=(x+2)^3$. Entonces debemos hallar $A_1$,$A_2$ y $A_3$ tq. \[
\frac{1-2x}{(x+2)^3}
=
\frac{A_1}{x+2}+\frac{A_2}{(x+2)^2}+\frac{A_3}{(x+2)^3}
=
\frac{A_1  (x+2)^2 + A_2  (x+2) + A_3}{(x+2)^3}
=
\frac{A_1(x^2+4x+4)+A_2(x+2)+A_3}{(x+2)^3}.
\]
Luego, igualando los coeficientes de los numeradores tenemos que \\
$\begin{array}{llll}
\phantom{-}0 = A_1        &                         &       & \textcolor{red}{\ok}    \\
-2=4A_1+A_2    & \longrightarrow A_2=-2  &       & \textcolor{red}{\ok}    \\
\phantom{-}1=4A_1+2A_2+A_3& \longrightarrow A_3 = 5 &       & \textcolor{red}{\ok}
\end{array}$ \\ \\
Entonces \[
\int{\frac{1-2x}{(x+2)^3}dx}
=
\int{\frac{-2}{(x+2)^2}dx}+\int{\frac{5}{(x+2)^3}dx}
=
-2\frac{(x+2)^{-2+1}}{(-3+1)}+c
=
\frac{2}{x+2}-\frac{5}{2(x+2)^2}+c.
\]
\end{ej}

\underline{\textbf{Caso 3}}: $q$ es producto de polinomios de grado $1$ algunos de los cuales se repiten. O sea \[
q(x)=(x-r_1)\dots(x-r_{i-1})(x-r_i)^{k_i}\dots(x-r_n)^{k_n}.
\]
En este caso aplicamos los procedimientos de los casos $1$ y $2$.

\begin{ej}
Si $\frac{p(x)}{q(x)}
=
\frac{x^3-x+1}{\underbrace{\textcolor{rojop}{x(x-2)}}_{\text{caso 1}}\underbrace{\textcolor{verdep}{(x-1)^3}}_{\text{caso 2}}}$, entonces buscamos $A_1, A_2, A_3, A_4, \; \text {y} \\ A_5 \in \R $ tales que \[
\frac{x^3-x+1}{x(x-2)(x-1)^3}
=
\underbrace{\textcolor{rojop}{\frac{A_1}{x}}+\textcolor{rojop}{\frac{A_2}{x-2}}}_{\text{caso 1}}
+
\underbrace{\textcolor{verdep}{\frac{A_3}{x-1}}+\textcolor{verdep}{\frac{A_4}{(x-1)^2}}+\textcolor{verdep}{\frac{A_5}{(x-1)^3}}}_{\text{caso 2}}.
\]
\end{ej}
\pagebreak
\underline{\textbf{Caso 4}}: $q$ es producto de factores $(x-r_i)^{k_i}$ y/o de polinomios de grado 2 \underline{\textbf{sin}} raíces reales y no se repiten. O sea, \[
q(x)=
\textcolor{verdep}{(x-r_1)^{k_1} \dots (x-r_n)^{k_n} }
\cdot
\textcolor{rojop}{(x^2+\alpha_1x+\beta_1) \dots (x^2+\alpha_mx+\beta_mx)}.
\]
En este caso $\frac{p}{q}$ se escribe como una suma donde por cada ``\textcolor{verdep}{factor lineal}''  aparecen tantos términos como indican los casos $1$ y $2$, y para cada ``\textcolor{rojop}{factor cuadrático}'' aparecen términos de la forma $\frac{Bx+C}{x^2+\alpha x+\beta}$, con $B$ y $C$ constantes a encontrar.

\begin{ej}
  Si $\frac{p(x)}{q(x)}=\frac{x-1}{\textcolor{azulp2}{(x-2)}\textcolor{verdep2}{x^2}\textcolor{rojop2}{(x^2+4)}}$, entonces debemos hallar constantes $A_1, A_2, A_3, B \; \text{y} \; C$ tales que \[
\frac{x-1}{(x-2)x^2(x^2+4)}=
\underbrace{
{
\overbrace{
\textcolor{azulp2}{\frac{A_1}{(x-2)}}}^{\text{Caso 1}}
}+
\overbrace{\textcolor{verdep2}{\frac{A_2}{x}}
+
\textcolor{verdep2}{\frac{A_3}{x^2}}}^{\text{Caso 2}}}
_{\text{\textcolor{red}{Fácil de integrar $\ok$ }
}
}
+
\underbrace{
\overbrace{\textcolor{rojop2}{
\frac{Bx+C}{x^2+4}}}^{\text{Caso nuevo}}
}
_{\textcolor{red}{\text{Integral ¿?}
}
}
  \]
\end{ej}

\begin{obs}
Para integrar terminos de la forma $\frac{Bx+C}{x^2+\alpha x + \beta}$, debemos hallar constantes $K_1$ y $K_2$ tales que
\[
\frac{Bx+C}{x^2+\alpha x + \beta}
=
K_1 \cdot \frac{2x+\alpha}{\underbrace{x^2+\alpha x + \beta}_{\underset{\text{la sust. $u=x^2+\alpha x + \beta $}}{\text{Fácil de integrar usando}}}}
+
K_2 \cdot \frac{1}{\underbrace{x^2+\alpha x + \beta}_{\textcolor{rojop2}{(\bigstar)}}}.
\]
Igualando los coeficientes de los numeradores se obtiene $K_1=\frac{B}{2}$ y\\ $K_2=C-K_1 \alpha$. \\\\
\textcolor{rojop2}{($\bigstar$)} Se debe completar cuadrado y se usa sustitución para llegar a algo de la forma \[
\frac{1}{y^2+a^2} \quad \text{y luego usar que}\quad \int{\frac{1}{y^2+a^2}dy}=\frac{1}{a}\arctg(\frac{y}{a})+c.
\]
\end{obs}

\begin{ej}
Calcular $\int{\frac{x-1}{x^2-4x+5}dx}$  \quad (estamos suponiendo $B=1$ y $C=-1$). \\\\
Debemos hallar $K_1$ y $K_2$ tales que \[
\frac{x-1}{x^2-4x+5}
=
\textcolor{azulp2}{\frac{K_1(2x-4)}{x^2-4x+5}}
+
\textcolor{rojop2}{\frac{K_2}{x^2-4x+5}}
\quad \quad \Longrightarrow \quad \quad \begin{array}{l}
\text{Igualando los coeficientes de los numeradores} \\
\;\;\; $\bl$ \quad \phantom{-}1=\phantom{-}2K_1 \phantom{+k_2+}\longrightarrow K_1=\frac{1}{2} \\
\;\;\; $\bl$ \quad -1=-4K_1+K_2 \longrightarrow K_2=1
\end{array}
\]
Luego, debemos resolver \[
\textcolor{azulp2}{\bullet} \; \frac{1}{2}\int{\frac{2x-4}{x^2-4x+5}dx}
\overset{\textcolor{azulp2}{(\star)}}{=}
\frac{1}{2} \int{\frac{1}{u}du}
=
\frac{1}{2} ln(|u|)+c
=
\frac{1}{2} ln(|x^2-4x+5|)+c
\]
\textcolor{azulp2}{($\star$)} Sustitución $\phantom{d}u=x^2-4x+5$ \\
\phantom{{($\star$)} Sustitución} $du=(2x-4)dx$.
\[
\textcolor{rojop2}{\bullet} \; 1 \int{\frac{1}{x^2-4x+5}dx}
=
\int{\frac{1}{(x+2)^2+1}dx}
\overset{\textcolor{rojop2}{(\star)}}{=}
\int{\frac{1}{y^2+1}dy}
=
\arctg(y) + c
=
\arctg(x-2)+c
\]
\textcolor{rojop2}{$(\star)$} Sustitución $\phantom{d}y=x-2$ \\
\phantom{\textcolor{rojop2}{$(\star)$} Sustitución} $dy=dx$
\\\\
Finalmente, $\int{\frac{x-1}{x^2-4x+5}dx}
=
\frac{1}{2}ln\left(|x^2-4x+5|\right)
+
\arctg(x-2)+c$.
\end{ej}

\begin{center}
\textbf{Integrales impropias:}
\end{center}

Hemos definido $\int_{a}^{b}{f(x)dx}$ para el caso en que \underline{\textbf{$a,b \in \R $}} y $f$ es \underline{\textbf{acotada}} y continua salvo a lo sumo en un número finito de puntos. Ahora extenderemos la definición para el caso en que $a$ o $b$ $\notin \R $ o en que $f$ no sea acotada en $[a,b]$.\\\\
\textbf{\underline{Integrales Impropias de tipo I:}} funciones continuas y al menos uno de los límites de integración no es finito.\\ 
\pagebreak
\begin{defi}
  Sea $a \in \R $.\\\\
  \bl Si $f$ es continua en $[a, \infi )$, definimos $\int_{a}^{\infi
  }{f(x)dx}:=\lim_{t\to \infi} {\int_{a}^{t}{f(x)}dx}$, si este límite existe y es finito. En tal caso decimos que $\int_{a}^{\infi}{f(x)dx}$ converge; si no decimos que $\int_{a}^{\infi}{f(x)dx}$ diverge.\\\\
  \bl Si $f$ es continua en $(-\infi,a]$, definimos $\int_{-\infi}^{a}{f(x)dx}:=\lim_{t\to-\infi}{\int_{t}^{a}{f(x)dx}}$; y decimos que converge o diverge según corresponda. \\\\
  \bl Si $f$ es continua en $\R$, definimos $\int_{-\infi}^{\infi}{f(x)dx}:=\int_{-\infi}^{a}{f(x)dx}+\int_{a}^{\infi}{f(x)dx}$ siempre que estas últimas \underline{\textbf{dos}} integrales converjan, y en tal caso decimos que $\int_{-\infi}^{\infi}{f(x)dx}$ converge. \\ Si alguna no converge, decimos que $\int_{-\infi}^{\infi}{f(x)dx}$ diverge.
\end{defi}

\begin{obs}
  Se puede ver que la definición de $\int_{-\infi}^{\infi}{f(x)dx}$ no depende del valor de $a$.
\end{obs}
\begin{ej} \; \\
\begin{enumerate}
  \item \[\int_{0}^{\infi}{e^{-x}dx}
  =
  \lim_{t\to \infi}{\int_{0}^{t}{e^{-t}dx}}
  =
  \left.    \lim_{t\to \infi}{-e^{-x}}    \right\vert_0^t
  =
  \lim_{t \to \infi }{\left(-e^{-t}+e^0\right)}
  =
  1<\infi, \; \text{por lo tanto}
  \]
  la integral impropia converge.
  \item \[
\int_{\infi}^{-1}{\frac{1}{x}dx}
=
\lim_{t\to \infi}{\int_{t}^{-1}{\frac{1}{x}dx}}
=
\left.    \lim_{t  \to -\infi}{\ln{(|x|)}} \right\vert_t^{-1}
=
\lim_{t \to -\infi}{\big(ln(1)-ln(t)\big)}
=
-\infi
\]
por lo tanto la integral impropia diverge (el límite \underline{\textbf{no}} es un número finito).
\item \[
\int_{-\infi}^{\infi}{\frac{1}{x^2+1}dx}.\quad\quad \text{Elegimos $a=0$ (por comodidad ya que la función es par),} \]
\[
 \bullet \int_{0}^{\infi}{\frac{1}{x^2+1}dx}
=
\lim_{t \to \infi}{\int_{0}^{t}{\frac{1}{x^2+1}dx}}
=
\left.\lim_{t \to \infi}{\arctg (x)}\right\vert_0^t
=
\lim_{t \to \infi}{\big(\arctg(t)-\arctg(0)\big)}
=
\frac{\pi}{2}
\]
\[
\bullet \int_{-\infi}^{0}{\frac{1}{x^2+1}dx}
=
\lim_{t \to -\infi}{\int_{t}^{0}{\frac{1}{x^2+1}dx}
=
\left.\lim_{t \to -\infi }{\arctg(x)}\right\vert_t^0
=
\lim_{t \to -\infi}{\big(\arctg(t)-\arctg(t)\big)}
\frac{\pi}{2}}
\]
\text{Por lo tanto }
\[
\int_{\infi}^{\infi}{\frac{1}{x^2+1}dx}
=
\frac{\pi}{2}+\frac{\pi}{2}
=
\pi\quad\quad\quad\quad\text{ \big(es convergente\big)}.
\]
\end{enumerate}
\end{ej}
\textbf{\underline{Ejercicio:}} ver que $\int_{1}^{\infi}{\frac{1}{x^p}dx}$, converge si $p>1$ y diverge si $p\leq 1$.\\
\\\\
\textbf{\underline{Integrales Impropias de tipo II:}} Límites de integración finitos $(a,b \in \R)$ pero funciones que tienen una asíntota vertical en un punto $c \in [a,b]$
\begin{defi} \; \\\\
$\bullet$ Sea $f$ continua en $[a.b)$ y $\lim_{x \to b^-}{f(x)}=\pm \infi$. Definimos \\ $$\int_{a}^{b}{f(x)dx}:=\lim_{t \to b^-}{\int_{a}^{t}{f(x)dx}}$$
si este límite existe y es finito.
\\
\\
$\bullet$ Sea $f$ continua en $(a,b]$ y $\lim_{x \to a^+}{f(x)}=\pm \infi$. Definimos \[
\int_{a}^{b}{f(x)dx}:=\lim_{t \to a^+}{\int_t^bf(x)dx}
\]
si el límite existe y es finito.
\\
\\
$\bullet$ Sea $c \in (a,b)$. Si $f$ es continua en $[a,c)\cup(c,b]$ y las $\underbrace{\text{integrales existen}}_{\int_{a}^{c}{f(x)}\text{ y }\int_{c}^{b}{f(x)}}$ y son finitas definimos \[
\int_{a}^{b}{f(x)dx}:=\int_{a}^{c}{f(x)dx}+\int_{c}^{b}{f(x)dx}.\]
$\bullet$ \text{ Cuando las integrales que hemos definido existen y son $< \infi$, decimos }\\\text{que convergen, si no decimos que divergen.}
\end{defi}
\begin{ej}
  Decidir si las siguientes integrales impropias son convergentes o divergentes. \\
  \begin{enumerate}
    \item $\int_0^1\frac{1}{x}dx$. Tenemos que $f(x)=\frac{1}{x}$ es continua en $(0,1]$ y $\lim_{x \to 0^+}{\frac{1}{x}}=\infi$.\\\\ Aplicando la definición tenemos que \[
\int_0^1{\frac{1}{x}dx}
=
\lim_{t \to 0^+}{\int_t^1\frac{1}{x}dx}
=
\left.\lim_{t \to 0^+}{ln\big(|x|\big)}\right\vert_t^1
=
\lim_{t \to 0^+}{\big(ln(1)-ln(t)\big)}=\infi\text{ y,}
    \]
por lo tanto la integral diverge.
\item $\int_0^1{\frac{1}{x^p}dx}$, con $0<p<1$ (por ejemplo si $p=\frac{1}{2}, \int_0^1{\frac{dx}{\sqrt{x}}})\quad\quad$
$\left(\begin{array}{l}
\text{Recien vimos que} \\
\text{para } $p=1$ \text{ diverge}
  \end{array}\right)$ \\
  Aplicamos la definición \[
\int_0^1\frac{1}{x^p}dx
=
\lim_{t \to 0^+}{\int_t^1{\frac{1}{x^p}dx}}
=
\left.\lim_{t \to 0^+}{\frac{x^{-p+1}}{-p+1}}\right\vert_t^1
=
\frac{1}{1-p}
\left.\lim_{t \to 0^+}{x^
{\overbrace{1-p}^{\textbf{\textcolor{rojop2}{>0}}}}}\right\vert_t^1
\overset{\textbf{$\cdot$}}{=}\]
\[
\overset{\textbf{$\cdot$}}{=}
\frac{1}{1-p}\lim_{t \to 0^+}{\left(1-t^{1-p}\right)}
=
\frac{1}{1-p}<\infi\phantom{sssssssssssssssssssssss+++++++}
\]
\\
Por lo tanto la integrtal impropia converge
  \end{enumerate}
\end{ej}

\underline{\textbf{Ejercicio}}: ver que $\int_0^1\frac{1}{x^p}dx$, es divergente para $p>1$.\\\\

\pagebreak 

\underline{\textbf{Criterio de Comparación para integrales impropias.}} \\
En algunos casos encontrar la primitiva de una función puede ser muy difícil y por lo tanto se complica decidir si una integral impropia converge o diverge utilizando directamente la definición.
\\\\
 A continuación veremos un criterio que nos servirá para determinar si una integral impropia es convergente o divergente (sin hacer el cálculo directo, si no que lo hacemos con una función más fácil de integrar).
\begin{teo}[Crit. de Comp. para Integrales Impropias de Tipo I]  \; \\
  Sean $f$ y $g$ funciones continuas y $a \in \R$. \\\\

  $\bullet$ Si $|f(x)| \leq g(x) \quad \forall x \in (\infi,a]$. Entonces $$\int_{a}^{\infi}g(x) \text{ conv.}  \Longrightarrow \int_{a}^{\infi}f(x)dx \text{ conv}.$$
  o equivalentemente si $$
\int_{a}^{\infi}{f(x)dx} \text{ div.} \Longrightarrow \int_{a}^{\infi}{g(x)dx} \text{ div.}
  $$
$\bullet$ $f(x) \leq g(x) \quad \forall x \in (\infi,a]$. Entonces $$
\int_{-\infi}^{a}g(x)dx \text{ conv.} \Longrightarrow \int_{-\infi}^{a}{f(x)dx} \text{ conv.} $$
o equivalentemente si \[
\int_{-\infi}^{a}{f(x)dx} \text{ div.} \Longrightarrow \int_{-\infi}^{a}{g(x)} \text{ div.}
\]
\end{teo}
\pagebreak
\begin{teo}[Crit. de Comp. para Integrales Impropias de Tipo II] \; \\
  Sean $f$,$g$ funciones continuas en $[a,b)$ y tal que
  $ |f(x)| \leq g(x)$ \quad $ \forall x \in [a,b) $ y
  $\lim_{x \to b^-}f(x) = \pm \infi $ Entonces si
  \[
  \int_a^bg(x)dx \text{ converge} \Longrightarrow \int_a^b f(x)dx \text{ converge,}
  \]
  o equivalentemente
  \[
\int_a^bf(x)dx \text{ diverge} \Longrightarrow \int_a^b g(x)dx \text{ diverge.}
  \]
$\bullet$ \emph{Nota:} Vale un resultado analogo para $\lim_{x \to a^+}{f(x)}=\pm \infi$.
\end{teo}
\begin{obs}
  En todos los casos si $f(x) \geq 0$, la hipótesis se reduce a $f(x) \leq g(x)$.
\end{obs}
\begin{ej}
Decidir si la integral $\int_{0}^{\infi}{e^{-x^2}dx}$ converge o diverge. \\
\\
Notemos que no podemos calcular directamente la integral ya que la primitiva de $e^{-x^2}$ \underline{\textbf{no}} es una función elemental. Utilicemos el teorema anterior.\\
Primero notemos que \[
\int_{0}^{\infi}{e^{-x^2}dx}
=
\underbrace{\int_{0}^{1}{e^{-x^2}dx}}_{\textcolor{rojop2}{\text{I}_1}}
+
\underbrace{\int_{1}^{\infi}{e^{-x^2}dx}}_{\textcolor{rojop2}{\text{I}_2}}
\]
$\bullet$ Tenemos que \textcolor{rojop2}{I$_1$} converge ya que $f(x)=e^{-x^2}$ es continua en $[0,1]$. \quad $\left(
\begin{array}{l}
  \text{Notar que es una} \\
  \textbf{integral definida $\ok$}
\end{array}
\right)$
$\bullet$ Para ver que $ $\textcolor{rojop2}{\text{I}$_2$} converge utilicemos el teorema anterior \\
Como nos interesa $1 \leq x $ \;$\Rightarrow$\; $x \leq x^2 $ \;$\Rightarrow$\; $-(x^2)\leq -x$ \;$\Rightarrow$\; $e^{-x^2}\leq e^{-x}$ para $x \in [1,\infi)$. \\
Sean $f(x)=e^{-x^2}$ y $g(x)=e^{-x}$, tenemos que $0 \leq f(x) \leq g(x)\quad \forall x \in [1,\infi)$. \\
Ademas \[
\int_1^\infi {g(x)dx}
=
\int_1^\infi {e^{-x}dx}
=
\lim_{t\to \infi} {\int_1^t {e^{-x}dx}
=
\left.\lim_{t \to \infi}{-e^{-x}}\right\vert_1^t
=
\lim_{t \to \infi} {\left(-e^{-t}+e^{-1} \right)}
=
e^{-1} < \infi
}
\]
es decir, la integral $\int_1^\infi g(x)dx$ es convergente.
\\\\Entonces por el teorema anterior \textcolor{rojop2}{I$_2$} es convergente.
Luego, como \textcolor{rojop2}{I$_1$} e \textcolor{rojop2}{I$_2$} son convergentes, $\int_0^\infi e^{-x^2}$ es convergente.
\end{ej}


\section{Sucesiones}
\begin{defi}
Una sucesión infinita de números reales es una función cuyo dominio son los naturales $\N$ y cuya imagen está incluicda en $\R$. O sea $a : \N \to \R $ tal que $1 \mapsto a(1) := a_1 \; ,\;  2 \mapsto a(2) := a_2 $, y en general $n \mapsto a(n) := a_n$.
\end{defi}

\begin{notacion}
  $\{a_1,a_2,a_3, \dots \},$ $\{a_n\}_{n=1}^{\infty}$, $\{a_n\}$.
\end{notacion}
\begin{ej} \; \\
  $\begin{array}{lllll}

    \emph{(1)} &  & \{1,2,3, \dots \}& \{n\}_{n=1}^{\infty}& a_n=n.  \\

    \emph{(2)} &  & \{-1,1,-1,1, \dots (-1)^n, \dots \}&\{(-1)^n\}& a_n=(-1)^n. \\
    \emph{(3)} &  & \{1,\frac{1}{2},\frac{1}{3},\dots, \frac{1}{n},\dots\}& \{\frac{1}{n}\}& a_n=\frac{1}{n}.   \\
    \emph{(4)} &  & \text{Dada } f : \mathbb{R} \to \mathbb{R}, & \text{la restricción de $f$ a } \mathbb{N} & \text{ define una sucesión}.
  \end{array}$
\end{ej}
\begin{obs}
  Una sucesión $\{a_n\}$ se puede representar como el gráfico de una función o como un conjunto de números reales.

  \begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v14.pdf_tex}
\end{figure}
\end{obs}
\begin{defi}
  Una sucesión $\{a_n\}$ tiene límite $ l \in \mathbb{R} $ y se escribe \\
  $\lim_{n \to \infty}{a_n}=l$ o $a_n \underset{n \to \infty}{\longrightarrow} l$ si los términos $a_n$ se acercan a $l$ tanto como queramos al hacer $n$ suficientemente grande. Esto es,
  \[
    \lim_{n \to \infty } {a_n} = l\quad  \Longleftrightarrow \quad \forall \epsilon > 0\quad  \exists n_0 \in \mathbb{N} \;  / \;  |a_n - l| < \epsilon\quad  \forall n \geq n_0.
  \]
\end{defi}
\begin{obs}
    Recordemos que \[
      | a_n - l| < \epsilon \quad \Leftrightarrow \quad -\epsilon < a_n - l < \epsilon \quad \Leftrightarrow \quad l - \epsilon < a_n < l + \epsilon.
    \]
\end{obs}
\textbf{\underline{Gráficamente}}  $a_n \underset{n \to \infty}{\longrightarrow} l$.
\begin{figure}
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v15.pdf_tex}
\end{figure}
\begin{ej}
  Probar que $\lim_{n \to \infty}{\frac{1}{n}}=0$ \\
  \\
  Sea $\epsilon > 0$. Quremos encontrar $n_0 \in \mathbb{N}$ tal que $\left\vert \frac{1}{n}-0\right\vert=\left\vert \frac{1}{n} \right\vert = \frac{1}{n} < \epsilon$.

  Luego, como $\frac{1}{n} < \epsilon$ $\Leftrightarrow$ $\frac{1}{\epsilon} < n$. Entonces, basta tomar $n_0 > \frac{1}{\epsilon}$.
\end{ej}

\pagebreak
\begin{defi}
  Dada una sucesion $\{a _n\}$, decimos que $\lim_{n \to \infty}{a_n}=\infty$ o $a_n\underset{n\to\infty}{\longrightarrow}\infty$ si los términos se hacen arbitrariamente grandes al hacer $n$ grande. Esto es \[
    \forall M > 0, \quad \exists n_0 \in \mathbb{N} \; / \; a_n > M \quad \forall n \geq n_0.
  \]
  Análogamente, decimos que $\lim_{n\to\infty}{a_n}=-\infty$ o $a_n\underset{n\to\infty}{\longrightarrow}-\infty$ si
  \[
    \forall k<0, \quad \exists n_0 \in \mathbb{N} \; / \; a_n < k\quad \forall n \geq n_0.
  \]
\end{defi}
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v16.pdf_tex}
\end{figure}
\pagebreak
\begin{defi}
Si existe $\lim_{n \to \infty} a_n=l$ y $l \in \mathbb{R}$ (o sea $l \neq \pm \infty)$ decimos que \{$a_n$\} \textbf{\underline{converge}} a $l$. En los demás casos decimos que \underline{\textbf{diverge}}.
\end{defi}
\begin{ej}
Decida si la sucesión dada converge o diverge. \\
\begin{enumerate}
    \item $a_n=\frac{1}{n}$. Recién vimos que $\lim_{n \to \infty }{\frac{1}{n}}=0 \quad \Rightarrow \quad \{\frac{1}{n}\}$ converge a $0$.
    \item $a_n=n$. Como $\lim_{n\to \infty}{n}=\infty$ $\left(\underset{\text{la definición}}{\text{Probarlo usando}}\right)$
      $\Rightarrow$ \{n\} diverge.
    \item $a_n=(-1)^n$. Como $\lim_{n\to \infty}{(-1)^n}$ no existe $\left(\underset{\text{$1$ y $-1$}}{\text{Alterna entre}}\right)$ $\Rightarrow$ $\{(-1)^n\}$ diverge.
\end{enumerate}
\end{ej}

\begin{obs}
  Se puede demostrar que si el límite existe, entonces es \underline{único}.
\end{obs}


\pagebreak

\begin{teo}
  Sea $\{a_n\}$ y $\{b_n\}$ dos sucesiones convergentes y sea $c \in \mathbb{R}$. Entonces $$\begin{array}{llcl}

    \emph{(i)}      &   \lim_{n\to\infty}{\left(a_n \pm b_n\right)}\;&=&\phantom{c}\lim_{n \to \infty} a_n \pm \lim_{n \to \infty}{b_n}. \\
    \emph{(ii)}     &   \lim_{n \to \infty}{(c\; a_n)}\: \;\;\;\;\;\;&=& c \lim_{n \to \infty}{a_n}. \\
    \emph{(iii)}    &   \lim_{n\to\infty}(a_n\cdot b_n)&=&\phantom{c}\lim_{n\to\infty}a_n\cdot\lim_{n\to\infty}b_n. \\
    \emph{(iv)}     &  \text{Si } \lim_{n \to \infty}{b_n} \neq 0,\quad &\text{entonces   }& \; \lim_{n \to \infty} {\frac{a_n}{b_n}} = \frac{\lim_{n\to\infty}{a_n}}{\lim_{n\to\infty}{b_n}}.

  \end{array}$$
\end{teo}
\begin{ej}
  \[
  \begin{array}{llll}
    \emph{(1)} & \lim_{n\to\infty}{\left(1+\frac{1}{n}\right)} & = & \lim_{n \to \infty}{1} + \lim_{n \to \infty}{\frac{1}{n}}=1+0=1. \\
    \emph{(2)} & \lim_{n\to\infty}{\frac{2n}{n+1}} & \overset{\cdot}{=} & \lim_{n \to \infty}{\frac{2n}{n\left(1+\frac{1}{n}\right)}} = \lim_{n\to \infty}{\frac{2}{\left(1+\frac{1}{n}\right)}} = \frac{2}{1}=2. \\
  \emph{(3)} & \lim_{n\to\infty}{\frac{n}{n^3+7}} & = & \lim_{n \to \infty}{\frac{n}{n^3\left(1+\frac{7}{n^3}\right)}}=\lim_{n\to\infty}{\frac{1}{n^2\left(1+\frac{7}{n^3}\right)}}=\lim_{n \to \infty}{\frac{1}{n^2}\cdot \frac{1}{\left(1+\frac{7}{n^3}\right)}}= 0 \cdot 1 = 0.\\
  \end{array}
\]
\begin{obs}
  En $\overset{\cdot}{=}$ no puedo usar \emph{(iv)}.
\end{obs}
 \end{ej}

\begin{teo}[Relación entre límite de funciones y sucesiones] \; \\
Si $\lim_{x \to \infty }{f(x)}=l$ y $a_n=f(n) \quad \forall n \geq n_0$, para algún $n_0 \in \mathbb{N}$ entonces \[
  \lim_{x\to\infty}{a_n}=l.
\]

\end{teo}
\begin{ej}
  Calcular $\lim_{n \to \infty}{a_n}$, con $a_n=\frac{ln(n)}{n}$. \\
  Sea $f(x)=\frac{ln(x)}{x}$, para $x>0$. Tenemos que $\lim_{x \to \infty}{\frac{ln(x)}{x}} \overset{\text{L'Hopital}}{=} \lim_{x \to \infty}{\frac{\frac{1}{x}}{1}}=0.$ \\
  y como $f(n)=a_n \quad \forall n \geq 1=n_0 \quad \Rightarrow \quad$ por Teorema $\lim_{n \to \infty }{\frac{ln(n)}{n}}=0$.
\end{ej}
\begin{obs}
  \underline{No} es cierto que si $\lim_{n \to \infty}{a_n}=l$, entonces cualquier función $f$ tal que $f(n)=a_n$ cumple que $\lim_{x \to \infty }{f(x)}=l$ (este límite puede no existir). \\\\
  Por ejemplo, si $a_n=\sen{(\pi n)}$ $(=0) \forall n \in \mathbb{N}$es claro que $\lim_{n \to \infty}{a_n=0}$ pero $\lim_{x \to \infty}{\sen{(\pi x)}}$ \underline{\textbf{no}} existe.
\end{obs}

\pagebreak

\begin{teo}[del ``sandwich'' \;para sucesiones] \; \\
  Si $a_n \leq b_n \leq c_n \quad \forall n \geq n_0$, para algun $n_0 \in \mathbb{N}$, y $\lim_{n \to \infty}{a_n}=\lim_{n \to \infty}{c_n}=l$, entonces $lim_{n \to \infty}{b_n}=l$.
\end{teo}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v17.pdf_tex}
\end{figure}

\begin{ej} \; \\

\end{ej}

\begin{teo}
Sea $\{ a_n \}$ una sucesión. Entonces, $$\lim_{n \to \infty } a_n = 0 \quad \Leftrightarrow \quad \lim_{n \to \infty } |a_n| = 0.$$
\end{teo}

\begin{ej} \; \\
    \begin{enumerate}
      \item Probar que la sucesión $\{ \frac{(-1)^y}{n} \}$ converge a $0$. \\
        Tenemos que $a_n=\frac{(-1)^y}{n}$ y con lo cual $|a_n| = \frac{|-1|^n}{n}=\frac{1}{n}$. \\
        Luego, como $\lim_{n \to \infty }{|a_n|} = \lim_{n \to \infty }{\frac{1}{n}}=0$, por el Teorema anterior $\lim_{n \to \infty}{\frac{(-1)^n}{n}}=0$.
      \item ¿Para que valores de $r$ es convergente la sucesión $\{r^n\}$? \\\\
        \textcolor{rojop2}{$\bullet$} Analicemos primero el caso $r>0$. \\
        Recordemos que $r^x=e^{ln(r^x)}=e^{xln(r)}$ y además $ln(r) \rightarrow \begin{array}{ll}
           > 0 & \text{si } 1<r. \\
           < 0 & \text{si } 0<r<1.
        \end{array}$ \\ 
        Luego, sea $f(x)=r^x$. Tenemos que $r^n=f(n)$ y como\\ $$\lim_{x \to \infty }{f(x)} = \left\{
          \begin{array}{ll}
            \infty & \text{si } 1<r. \\
            0 & \text{si } 0<r<1.
        \end{array}\right. $$
        entonces por teorema 
        $$\lim_{n \to \infty }{r^n} = \left\{
          \begin{array}{ll}
            \infty & \text{si } 1<r. \quad \quad \quad \quad (I) \\
            0 & \text{si } 0<r<1. \quad \quad (II)
        \end{array}\right. $$ \\
        Por otra parte, \\
        $\bullet$ si $r=1$, $r^n=1$ $\forall n \in \mathbb{N}$ y con lo cual $\lim_{n \to \infty} r^n = 1.$ \quad (III). \\
        $\bullet$ si $r=0$, $r^n=0$ $\forall n \in \mathbb{N}$ y con lo cual $\lim_{n \to \infty} r^n = 0$. (IV) \\\\
        \textcolor{rojop2}{$\bullet$} Ahora consideramos el caso $r<0$. \\\\
        $\bullet$ si $r \in (-1,0)\quad \Rightarrow \quad 0<|r|<1 \quad$ y por (II) $\lim_{n \to \infty}{|r|^n}=0$ \\ $\therefore$ por Teo. anterior $\lim_{n \to \infty}{r^n}=0$ \\
        $\bullet$ si $r = -1$, $r^n=(-1)^n$ que ya sabemos que no tiene límite para $n \to \infty$. \\
        $\bullet$ si $r< -1$, $r^n$ no tiene límite cuando $n \to \infty$. 
    \end{enumerate}
\textbf{\underline{Conclusión}:}
\[ 
  \lim_{n \to \infty}{r^n} = \left\{ 
    \begin{array}{lcl}
      0 & \text{si} & r \in (-1,1) \\
      1 &\text{si} & r=1 \\
      \text{diverge} & \text{en} & \text{los otros casos.}
    \end{array}
  \right.
\]
\end{ej}

\begin{teo}
  Sea $\{ a_n \}$ tal que $\lim_{n \to \infty }{a_n}=a$ y $f$ una función continua en $x=a$. Entonces \[ 
    \lim_{n \to \infty}{f(a_n)}=f(a) \quad \quad \big(=f(\lim_{n \to \infty}{a_n})\big).
  \]
\end{teo}
\begin{ej} \; \\
    \begin{enumerate}
      \item Calcule el límite de la sucesión $\{e^{\frac{1}{n}}\}$. \\
        Como $\lim_{n \to \infty}{\frac{1}{n}}=0$ y $f(x)=e^x$ es continua en $x=0$, entonces por teorema \[ 
          \lim_{n \to \infty}{e^{\frac{1}{n}}}=e^{\lim{n\to\infty}{\frac{1}{n}}}=e^0=1.
        \]
      \item  Calcule el límite de la sucesión $\{ n \cdot sen\left(\frac{1}{n}\right)\}$. \\\\
        Primero notemos que $n\sen\left(\frac{1}{n}\right)=\frac{\sen\left(\frac{1}{n}\right)}{\frac{1}{n}}$.\\
        Tomamos $a_n=\frac{1}{n}$ ; sabemos que $\lim_{n \to \infty}{a_n}=0$ (o sea $a=0$ en el teorema). \\
        Elegimos $ f(x)=\left\{ \begin{array}{cl}
            \frac{sen(x)}{x} & \text{si } x \neq 0 \\
            1                & \text{si } x=0
        \end{array}. \right. $ 
        Tenemos que $f$ es continua en $x=0$ ya que \[\lim_{x\to 0}{f(x)}=\lim_{x \to 0}{\frac{\sen(x)}{x}}=\lim_{x \to 0}{\frac{\cos(x)}{1}}=1=f(0).
        \]
      Luego, \[
      \lim_{n \to \infty}{n\sen\left(\frac{1}{n}\right)}=\lim_{n \to \infty}{\frac{\sen\left(\frac{1}{n}\right)}{\frac{1}{n}}}=\lim_{n \to \infty }{f(a_n)}\overset{\cdot}{=}f(a)=f(0)=1. \]
      $\overset{\cdot}{=}$ Aplico el teorema.

    \end{enumerate}
\end{ej}

\begin{defi}
  Decimos que la sucesión $\{a_n\}$ es \\
  $\begin{array}{lcll}
    \bullet & \text{creciente}& \text{si} & a_{n\phantom{+1}} \leq a_{n+1} \forall n \; ; \\

    \bullet & \text{estríctamente creciente} & \text{si} & a_{n\phantom{+1}} < a_{n+1} \forall n \; ; \\
    \bullet &  \text{decreciente} & \text{si} & a_{n+1} \leq a_{n\phantom{+1}}\forall n ; \\ 
    \bullet & \text{estríctamente decreciente} & \text{si} & a_{n+1} < a_{n\phantom{+1}} \forall n \; ; \\

  \end{array}$ \\\\
  Si $\{a_{n}\}$ es creciente o decreciente, decimos que es \textbf{\underline{monótona}}.

\end{defi}

\begin{ej}
  \begin{enumerate} \; \\

    \item $\{n\}$. Como $a_n=n<n+1=a_{n+1}$ $\forall n$,$\{n\}$ es estrictamente creciente.
    \item $\{ln(n)\}$. Sabemos que $f(x)=ln(x)$ es estrictamente creciente, por lo tanto $n<n+1 \Rightarrow a_n=ln(n)<ln(n+1)=a_{n+1}$. Luego $\{ln(n)\}$ es estrictamente creciente. 
       \item $\{1,1,2,2,3,3,\dots\}$. Como $a_n \leq a_{n+1}$ $\forall n $ $ \Rightarrow $ $\{a_n\}$ es creciente.
    \item $\{\frac{1}{n}\}$. Tenemos que $n<{n+1}$ $\Rightarrow \frac{1}{n+1} < \frac{1}{n}$ $\forall n \in \mathbb{N}$. O sea, $a_{n+1}<a_n$ $\forall n$. Y entonces $\{\frac{1}{n}\}$ es estrictamente decreciente.

  \end{enumerate}
\end{ej} 

\pagebreak
\begin{defi}
  decimos que la sucesión $\{a_n\}$ es \\
  $\begin{array}{clll} 
    \text{acotada inferiormente} & \text{si} & \exists M_i \in \mathbb{R} \text{ tq } M_i \leq a_n  &  \forall n \in \mathbb{N} ;  \\ 
    \text{acotada superiormente} & \text{si} & \exists M_s \in \mathbb{R} \text{ tq } a_n \leq M_s & \forall n \in \mathbb{N};  \\
    \text{acotada} & \text{si} & \exists M_{\phantom{s}}\in\mathbb{R} \text{ tq } |a|<M & \forall n \in \mathbb{N}. 
  \end{array}$
\end{defi}
\begin{ej} \; \\
  \begin{enumerate}
    \item $\{\frac{1}{n}\}$.\;\;\;\; Como $\phantom{.}0\leq \frac{1}{n} \leq 1 \; \forall n\in \mathbb{N} \Rightarrow $$\{\frac{1}{n}\}$ es acotada (puedo tomar $M=1$).
  \item $\{-n\}$. \;   Como $-n \leq 0$ \;\;\;\;\; $\forall n \in \mathbb{N} \Rightarrow $ $\{-n\}$ \; \; es acotada sup. pero \textbf{\underline{no}} inf. 
  \item $\{n+3\}$. Como $\phantom{-}4 \leq n+3 \; \forall n \in \mathbb{N} \Rightarrow$ $\{n+3\}$ es acotada inf. pero \textbf{\underline{no}} sup.

  \end{enumerate}
\end{ej}

\begin{obs}
  a la definición anterior decimos que $M_i$ es \textbf{una }\underline{cota inferior} de $\{a_n\}$ y $M_s$ es \textbf{una} \underline{cota superior} $\{a_n\}$. \\ \\
$\bullet$ Análogamente se puede definir cota superior e inferior de cualquier subconjunto de números reales. \\
$\bullet$ Notar que las cotas sup. e inf. \textbf{\underline{no}} son únicas. \\
Por ejemplo si $a_n=(-1)^n$ $\Rightarrow$ $M_s=10,\;$$M_s=2,\;$$M_s=1$ son todas cotas superiores.
\end{obs}

\begin{axi}[Axioma de completitud de los números reales.] \; \\
  Todo conjunto no vacío de números reales que es acotado sup. tiene una \underline{menor} cota sup. en $\mathbb{R}$ y; \\
  Todo conjunto no vacío de números reales que es acotado inf. tiene una \underline{mayor} cota inf. en $\mathbb{R}$.
\end{axi}

\begin{defi}
  Sea $A \subset \R $, $A\neq \emptyset $. \; \\ \\
  $\bullet$ \; Si $A$ es acotada sup., la menor cota superior se llama \underline{supremo de $A$} y la denotamos $\sup(A)$. \\
  $\bullet$ \; Si $A$ es acotada inf., la mayor cota inferior se llama \underline{ínfimo de $A$} y la denotamos $\inf(A)$. \\ \\
Además, 
$\begin{array}{lcl}
  \text{si } & \sup(A) \in A, & \text{decimos que es el máximo de $A$ y} \\
  \text{si } & \inf(A) \in A & \text{decimos que es el mínimo de $A$}.  
  \end{array}$
\end{defi}
\pagebreak
\begin{ej}
Pensemos a las siguientes sucesiones como conjuntos de números reales, entonces \\
$ \begin{array}{lrlrll}
  \emph{(1)} & \{\frac{1}{n}\}=A. & \sup(A)=\phantom{-}1 & , &\inf(A)=0,   &  A \text{ tiene máximo pero no tiene un mínimo.} \\
\emph{(2)} & \{-n\}=B.          & \sup(B)=-1 & \text{ y} & \text{$-1$ es el máximo.} &  \text{$B$ no tiene ínfimo y $\therefore$ no tiene mínimo.} \\
\emph{(3)} & \{(-1)^n\}=C.      & \sup(C)=\phantom{-}1 &,&\inf(C)=-1.             & \text{Además $1$ es el max. de $C$ y $-1$ su mín.} \\
\emph{(4)} & \{n+3\}=D.         & \inf(D)=\phantom{-}4 &,&    \text{ y $4$ es el mínimo de $D$.} & \begin{array}{l}
  \text{ Además $D$ no tiene supremo y} \\
  \text{ $\therefore$ no tiene máximo.}        
  \end{array}
  \end{array}$
\end {ej}


\begin{teo}
  Si $\{a_n\}$ es convergente $\Rightarrow$ es acotada.
\end{teo}

\begin{obs}
  La reciproca es falsa, o sea $\{a_n\}$ acotada $\not\Rightarrow$ convergente. \\
  Por ejemplo, $a_n=(-1)^n$. \\
  Sin embargo, sí es cierto si la sucesión es creciente o decreciente.
\end{obs}
\begin{teo} \; \\

  $\begin{array}{llcl}
    \emph{(i)} & \text{Si } \{a_n\} \text{ es creciente \;\;\; y acotada superiormente} & \Rightarrow & \{a_n\} \text{ converge y}
    \end{array}$ 
    \[ \lim_{n \to \infty}{a_n}=l_1=\sup\left(\{a_n\}\right).\] 
    $\begin{array}{llcl}
    \emph{(i)} & \text{Si } \{a_n\} \text{ es decreciente y acotada inferiormente } & \Rightarrow & \{a_n\} \text{ converge y}
    \end{array}$ 
    \[ \lim_{n \to \infty}{a_n}=l_2=\inf\left(\{a_n\}\right).\] 
 \end{teo}

\begin{obs}
Se puede demostrar que si $\{a_n\}$ es creciente entonces converge o $\lim_{n \to \infty}{a_n}=\infty$ \\
Análogamente, si $\{a_n\}$ es decreciente, entonces converge o $\lim_{n \to \infty}{a_n}=\infty$
\end{obs}


\begin{center}
\textbf{Subsucesiones.}
\end{center}

$\bullet$ Dada una sucesión $\{a_n\}$ podemos extraer de ésta otras sucesiones descartando algunos términos (quizá una cantidad infinita). Cada una de estas nuevas sucesioens se llama subsucesión de $\{a_n\}$. 

\begin{ej}
  Consideremos la sucesión $\left\{-1,\frac{1}{2},-1,\frac{1}{3},-1,\frac{1}{4},-1,\frac{1}{5},-1,\dots\right\}$. Podemos extraer las siguientes subsucesiones \\ \\
  $\bullet$ $\{-1,-1,-1,\dots\}$  \quad (términos impares) \\
  $\bullet$ $\{\frac{1}{2},\frac{1}{3},\frac{1}{4},\dots\}$  \quad \quad \; \;(términos pares). \\
  $\bullet$ $\left\{-1,-1,-1,\frac{1}{4},-1,-1,-1,\frac{1}{7},\dots\right\}$

\end{ej}
\begin{defi}
  Una subsucesión de una sucesión $\{a_n\}$ es una sucesión de la forma $\left\{a_{n_1},a_{n_2},a_{n_3},\dots \right\} =\left\{a_{n_j}\right\}_{j=1}^{\infty}$ donde los $n_j \in \mathbb{N}$ y cumplen $n_1 < n_2 < n_3 < \dots$ . 
\end{defi}
\begin{ej}

$\begin{matrix*}
  \{a_1, & a_2, & a_3, & a_4, & a_5, & a_6, & \dots \} \\ 
  \downarrow & & \downarrow & & \downarrow & & \\
  a_{n_1} & & a_{n_2} & & a_{n_3} & & \\
  n_1=1 & & n_2=3 & & n_3=5
\end{matrix*}$ \\

O sea $n_j=2j-1 $ , $j \in \mathbb{N}$. \\

$\bullet$ \; Notar que $\{a_{nj}\}$ es una sucesión, o sea podemos escribir $\{a_{nj}\}=\{b_j\}$.

\end{ej} 
\begin{teo}
  toda subsucesión de una sucesión convergente es convergente y además los límites son iguales.
\end{teo}
\begin{ej}
  Dado $\left\{\frac{1}{n}\right\}$, tenemos que $\left\{\frac{1}{2j-1}\right\}$ es una subsucesión. $\big($ \text{Otra forma de} \\ \text{escribirlo es } $a_n=\frac{1}{n}, a_{n_j}=\frac{1}{2j-1}\big).$ \\ 
  Y como \[\lim_{n \to \infty}{a_n}=0 \Rightarrow \lim_{j \to \infty}{a_{n_j}}=0. \]
\end{ej}
\begin{obs}
  el teorema anterior es muy útil para demostrar que una sucesión NO tiene límite: basta encontrar dos subsucesiones distintas que converjan a distintos límtes.
\end{obs}
\begin{ej}
  Sea $\{a_n\}=\{(-1)^n\}$. \\
  Luego $a_{n_j}=(-1)^{2_j}$ y $a_{n_k}=(-1)^{2k+1)}$ son dos subsucesiones de $\{a_k\}$ que convergen a $1$ y $-1$ respectivamente. $\therefore \; \{a_n\}$ \textbf{\underline{no}} tiene límite, o sea diverge.
\end{ej}

\begin{teo}[Bolzano - Weierstrass] \; \\
  Toda sucesión acotada tiene al menos una subsucesión convergente.
\end{teo}
\begin{obs}
  Puede haber más de una subsucesión convergente. 
\end{obs}

Si $\{a_n\} = \left\{ -1,\frac{1}{2},-1,\frac{1}{3},-1,\frac{1}{4},\dots \right\}$
$\Rightarrow$ 
$\begin{array}{l}
  b_j = n_{2_j} \; \; \; \; = \left\{ \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \dots \right\}\\
  c_k = n_{2k+1} = \{ -1,-1,-1,\dots \}
\end{array}.$
Y en este caso ambas sucesiones son convergentes.

\section{Series.}

Dada una sucesión $\{ a_n \}$ queremos sumar sus infinitos términos, esto es $a_1+a_2+a_3+ \dots + a_n + a_{n+1} + \dots $; lo cual escribiremos como $\sum_{n=1}^{\infty}{a_n} $. \\

\begin{ej}  Si $a_n=\frac{1}{2^n}$, tenemos que  $$\sum_{n=1}^{\infty}{\frac{1}{2^n}}=\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\frac{1}{16}+\dots$$

\end{ej}

Podemos pensar $a_n$ como longitudes y entonces sumar un término se puede interpretar como agregar la mitad de lo que falta para llegar a $1$.\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v18.pdf_tex}
\end{figure}

Gráficamente, es claro que la suma se paroxima a $1$ tanto com ose quiera. Pero, ¿Cómo puedo sumar una cantidad \textbf{\underline{infinita}} de números, podemos definir \[
  s_1:=a_1, \quad s_2:=a_1+a_2,\quad s_k:= a_1+a_2+\dots + a_k
\]
y después hacer $ \lim_{k \to \infty}{s_k} $

\begin{defi}
  dada $ \{ a_n \} $ sucesión de números reales, llamaremos \textbf{\underline{serie}} de términos $a_n$ a $$\sum_{n=1}^{\infty}{a_n}.$$ \\\\
 Para cada $k \in \mathbb{N}$, definimos la k-ésima \textbf{\underline{suma parcial}} $s_k$ de la serie $\sum_{n=1}^{\infty}{a_n}$ como $$s_k:=a_1 + \dots + a_k = \sum_{n=1}^{k}{a_n}.$$ \\
 Luego, $\{s_k\}$ es una sucesión de números reales.\\\\ Si el límite de la sucesión $\{s_k\}$ existe y es finito, i.e. $\lim_{k \to \infty}{s_k}:=s<\infty$, decimos que la serie $\sum_{n=1}^{\infty}{a_n}$ es \textbf{\underline{convergente}} y definimos $\sum_{n=1}^{\infty}{a_n}:=s$. \\\\
 Si $\lim_{k \to \infty}{s_k}$ no existe o es $\pm \infty$, decimos que la serie $\sum_{n=1}^{\infty}{a_n}$ es \textbf{\underline{divergente}}.


\end{defi}

\pagebreak
\begin{ej}
  Determine si las siguientes series son convergentes o divergentes. \\
  \begin{enumerate}
    \item $\sum_{n=1}^{\infty}{n}.$ \quad Tenemos que $a_n=n\; \forall n \in \mathbb{N}$ y por lo tanto \[ 
        s_1=1, \quad s_2=1+2=3, \quad s_3=1+2+3=6, \quad \dots \quad ,s_k=1+2+\dots + k= \frac{k(k+1)}{2} .
      \] 
      Luego, como $\lim_{k \to \infty}{s_k}=\lim_{k \to \infty}{\frac{k(k+1)}{2}}=\infty \Rightarrow \sum_{n=1}^{\infty}{n}$ es divergente.
    \item $\sum_{n=0}^{\infty}{(-1)^n}$. Observemos que esta serie comienza desde $n=0$. Entonces \[ 
        S_0=1, \quad S_1=1 + (-1) = 0, \quad s_2=1+(-1)+1=1, \text{ y en general } s_k \left\{ \begin{array}{l}
            1 \; $\text{ si $k$ es par}$  \\
0 \; $\text{ si $k$ es impar}$  
        \end{array}.\right.
      \]
      Luego, \underline{NO} existe $\lim_{k\to \infty}^{s_k}$ pues $\{s_k\}$ admiten dos subsucesiones con límites distintos : $\{s_{2j}\}$ tiene límite $1$ $\{s_{2j+1} \}$ tiene límite $0$.  \\\\ 
      Al no existir $\lim_{k \to \infty}{s_k}$ tenemos que $\sum_{n=0}^{\infty}{(-1)^n}$ es divergente.

    \item $\sum_{n=1}^{\infty}{\frac{1}{2^n}}=\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\dots $ parece convergente. Veremos que efectivamente, es convergente.
  \end{enumerate}
\end{ej}

\begin{defi}
  dado $r \in \mathbb{R}$, la serie $\sum_{n=0}^{\infty}r^n=1+r+r^2+\dots $ se llama \underline{serie geométrica}.
\end{defi}

\pagebreak
\begin{teo}
  \begin{enumerate} \; \\
    \item Si $|r|<1$, la serie $\sum_{n=0}^{\infty}{r^n}$ es convergente y además $\sum_{n=0}^{\infty}{r^n} = \frac{1}{1-r}$.
     \item Si $|r| \geq 1$, la serie $\sum_{n=0}^{\infty}{r^n}$
      es divergente.
    \end{enumerate}
\end{teo}

\begin{demo}
  Fijamos $r \in \mathbb{R} $. Luego tenemos que \[  
  \left. \begin{array}{rcl}
      s_k  & = & 1+r+r^2+ \cdots + r^k \\
      r \cdot s_k & = & r+r^2+r^3+\cdots + r^{k+1}
  \end{array} \right\} \; \Rightarrow \; s_k-r\cdot s_k=1-r^{k+1}. \]
\text{ O que es lo mismo, } $$(1-r)s_k=1-r^{k+1}$$
$\begin{array}{l}
  \emph{(i)} \text{ Supongamos } |r|<1. \\\\ 
  \text{Por un lado, como $r \neq 1$, tenemos que $s_k=\frac{1-r^{k+1}}{1-r}.$} \\
\text{Por otra parte, como $|r|<1$, tenemos que $\lim_{k \to \infty}{r^{k+1}=r\lim_{k\to\infty}{r^k}=0}$} \quad (*) \\
\text{Luego, $\lim_{k \to \infty}{s_k}=\lim_{k \to \infty}{\frac{1-r^{k+1}}{1-r}}=\frac{1}{1-r}$ y listo!.} \\ \\

\text{(*) \quad (Recordar cuando analizamos la sucesión $\{r^n\}$)} \\\\ 
\emph{(ii)} \text{ Supongamos $|r| \geq 1$}. \\\\
\bullet \text{ Si $r=-1$, ya vimos en el ejemplo (2) que $\sum_{n=0}^{\infty}{(-1)^n} $ es divergente.} \\
\bullet \text{ Si $r=1$, entonces $s_k=\underbrace{1+1+\dots+1}_{\textcolor{azulp2}{k-veces}}=k.$ Luego, $\lim_{k\to\infty}{s_k=\infty}$ y con lo cual $\sum_{n=0}^{\infty}{1^n}$ es divergente.} \\
\bullet \text{ Si $|r|>1$.} \\ 
\text{Por un lado tenemos que $s_k=\frac{1-r^{k+1}}{1-r}$.} \\ 
\text{Por otra parte, ya sabemos que $\lim_{k\to\infty}{r^{k+1}}=\left\{ \begin{array}{l}
\infty \text{ si $r>\phantom{.}1$}\\
\nexists  \text{ \; si $r<-1$}
\end{array}\right. \therefore \begin{array}l 
\text{en ambos casos} \\ 
\text{no es finito}
\end{array}$}
\\
\text{Luego, $\lim_{k\to\infty}{s_k}=\lim_{k\to\infty}{\left(\frac{1}{1-r}-\frac{r^{k+1}}{1-r}\right)}$ es divergente y con lo cual la} \\ \text{ serie $\sum_{n=0}^{\infty}{r^n}$ también será divergente.}
\end{array}$\\\\
\end{demo}
\begin{obs}
Si $|r|<1$, entonces $$\sum_{n=1}^{\infty}{r^n}=\sum_{n=0}^{\infty}{r^n}-r^0=\frac{1}{1-r}-1=\frac{r}{1-r}.$$
(Notar que $r^0=1$.)
\end{obs}
\begin{ej} \; \\
  $\bullet$ \; $\sum_{n=1}^{\infty}{\frac{1}{2^n}}=\sum_{n=1}^{\infty}{\left(\frac{1}{2}\right)^n}=\frac{\frac{1}{2}}{1-\frac{1}{2}}=1$ \text{ (La serie que vimos antes!)}\\
  $\bullet$ \; $\sum_{n=0}^{\infty}{\left(-\frac{2}{3}\right)^n}=\frac{1}{1-\left(-\frac{2}{3}\right)}=\frac{1}{\frac{5}{3}}=\frac{3}{5}$ \\

  $ \bullet $ \; $\sum_{n=1}^{\infty}{\left(\frac{4}{3}\right)^n}$ es divergente pues $r=\frac{4}{3}>1$ 

\end{ej}

\begin{center}
\textbf{Propiedades de series convergentes.}
\end{center}
\begin{teo}
  Si $\sum_{n=1}^{\infty}{a_n}$ y $\sum_{n=1}^{\infty}{b_n}$ son series convergentes y $c \in \mathbb{R}$, entonces $\sum_{n=1}^{\infty}{a_n \pm b_n}$ y $\sum_{n=1}^{\infty}{c\cdot a_n}$ son series convergentes y además \\ $\begin{array}{lcl}
    \bullet \; \sum_{n=1}^{\infty}{(a_n \pm b_n)}&=&\sum_{n=1}^{\infty}{a_n} \pm \sum_{n=1}^{\infty}{b_n}\\
    \bullet \; \sum_{n=1}^{\infty}{c\cdot a_n}&=&c\sum_{n=1}^{\infty}{a_n}
  \end{array}$
\end{teo}
\pagebreak 
\begin{demo}[Idea] \; \\
  estas propiedades se desprenden de la def. de serie convergente y de las propiedades de los límites. Ejemplo: veamos que $\sum_{}^{}{(a_n+b_n)}=\sum a_n + \sum b_n$. \\
  $\bullet$ \; Sean $s_k=\sum_{n=1}^ka_n$ y $t_k=\sum_{n=1}^{k}{b_n}.$ \\
  Por hipótesis $\lim_{k\to\infty}{s_k}:=s<\infty$ y $\lim_{k \to \infty}{t_k}:=t<\infty.$ \\\\
  $\bullet$ \; Sea $u_k=\sum_{n=1}^{k}{(a_n+b_n)}\rightarrow $ k-ésima suma parcial de la serie $\sum_{n=1}^{\infty}{(a_n+b_n)}.$ \\\\
  $\bullet$ \; Veamos que $\{u_k\}$ converge. \\
  \begin{align*}
    \lim_{k \to \infty}{u_k} = \lim_{k\to\infty}{\sum_{n=1}^{k}{(a_n+b_n)}} &= \lim_{k\to\infty}{\left(\sum_{n=1}^{k}{a_n}+\sum_{n=1}^{k}{b_n}\right)} \\
                                                                            &= \lim_{k\to\infty}{s_k+t_k} \\
                                                                            &= \lim_{k\to\infty}{s_k}+\lim_{k \to \infty}{t_k} = s+t
  \end{align*}
$\Rightarrow \; \sum_{n=1}^{\infty}{(a_n+b_n)}$ es convergente, y además $$\sum_{n=1}^{\infty}{(a_n+b_n)} = s+t=\sum_{n=1}^{\infty}{a_n}+\sum_{n=1}^{\infty}{b_n}$$ 
\end{demo}
\underline{Ejercicio}: Probar que $\sum_{n=1}^{\infty}{c\cdot a_n}=c\sum_{n=1}^{\infty}{a_n}$.
\\\\
$\bullet$ \; En general, es difícil determinar la suma exacta de una serie ya que es difícil deducir una fórmula por $s_k$. Sin embargo, hay varios criterios que permiten establecer si una serie converge o diverge sin tener que hallar una fórmula explícita para $s_k$

\begin{teo}[Criterio de la divergencia] \; \\
  Si $\sum_{n=1}^{\infty}{a_n}$ converge, entonces $\lim_{n \to \infty}{a_n}=0$. \\ 
  Equivalentemente, si $\lim_{n \to \infty}{a_n} \neq 0$ o $\lim_{n \to \infty}{a_n} \; \nexists$ entonces $\sum_{n=1}^{\infty}{a_n}$ diverge.
\end{teo}
\pagebreak
\begin{demo} tenemos que \\
$\left.\begin{array}{l}
  s_{k\phantom{-1}}=a_1+\dots+a_{k-1}+a_k \\
  s_{k-1}=a_1+\dots+a_{k-1}
\end{array}\right\} \Rightarrow s_k-s_{k-1}=a_k.$\\
Ahora, como $\sum_{n=1}^{\infty}{a_n}$ es convergente, entonces por definición existe $\lim_{k \to \infty}{s_k}:=s$. \\
Pero entonces también vale que $\lim_{k \to \infty}{s_{k-1}}=s$ \quad \big(pues $k\to\infty \Leftrightarrow k-1 \to \infty $\big)\\
Luego, $\lim_{k\to\infty}{a_k} = \lim_{k\to\infty}{\left(s_k-s_{k-1}\right)}=\lim_{k\to\infty}{s_k} - \lim_{k\to\infty}{s_{k-1}}=s-s=0 \quad \qed $
\end{demo}
\begin{ej}
  Probar que la serie $\sum_{n=1}^{\infty}{\frac{n^2}{5n^2+4}}$ es divergente. \\
  Tenemos que $a_n=\frac{n^2}{5n^2+4}.$ \\
  Luego, como $\lim_{n\to\infty}{a_n}=\lim_{n\to\infty}{\frac{n^2}{5n^2+4}}=\lim_{n\to\infty}{\frac{1}{5+\frac{4}{n^2}}}=\frac{1}{5}$ \\
  $\Rightarrow \; \text{por el criterio de la divergencia la serie es divergente.}$
\end{ej}
\begin{obs}
  no vale el recíproco del teorema. Es decir, \\
  $$\lim_{n\to\infty}{a_n=0}\not\Rightarrow \sum_{n=1}^{\infty}{a_n} \; \text{converge}$$
\end{obs}

\begin{ej}
  $\sum_{n=1}^{\infty}{\frac{1}{n}}$ \quad \big(\underline{serie armónica}\big) \\
Vale que $\lim_{n\to\infty}{\frac{1}{n}}=0$, per veamos que $\sum_{n=1}{\infty}{\frac{1}{n}}$ es divergente. \\\\
Vamos a probar que una subsucesión de la sucesión de sumas parciales $\{s_k\}$ es divergente (y por lo tanto, por teo. visto anteriormente, la sucesión $\{s_k\}$ también diverge, o sea que la serie diverge). \\\\
Consideramos la subsucesión $\{s_{2^j}\}$. Tenemos que si \\
$j=1 \; \longrightarrow \; s_{2^1}=s_2=1+\frac{1}{2}$ \\
$j=2 \; \longrightarrow \; s_{2^2}=s_4=s_2+\left(\frac{1}{3}+\frac{1}{4}\right)>s_2+2\cdot \frac{1}{4}=s_2+\frac{1}{2}=1+\frac{1}{2}+\frac{1}{2}=1+2\cdot\frac{1}{2}$ \\
$$j=3\;  \longrightarrow \; s_{2^3}=s_8=s_4+\left(\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+\frac{1}{8}\right)>s_4+4\cdot\frac{1}{8}=s_4+\frac{1}{2}>1+2\cdot\frac{1}{2}+\frac{1}{2}=1+3\frac{1}{2}$$
$$j=4\;\longrightarrow \; s_{2^4}=s_{16}=s_8+\left(\frac{1}{9}+\frac{1}{10}+\dots+\frac{1}{16}\right)>s_8+8\cdot\frac{1}{16}=s_8+\frac{1}{2}>1+3\cdot\frac{1}{2}+\frac{1}{2}=1+4\frac{1}{2}$$ \vdots \\
De manera general $s_{2^j}=1+j\frac{1}{2}$.\\
Luego, $\lim_{j \to \infty}{s_{2^j}} \geq \lim_{j \to \infty} \left(1+j\frac{1}{2}\right)=\infty$. O sea, $\{s_{2^j}\}$ es una subsucesión  de sumas parciales que diverge, Luego $\{s_k\}$ diverge y por def. $\sum_{n=1}^{\infty}{\frac{1}{n}}$ diverge.
\end{ej}

\begin{obs}
  $\sum_{n=1}^{\infty}{a_n} \text{ converge } \Longleftrightarrow \sum_{n=n_0}^{\infty}{a_n} \text{ converge, pues}$ $$
  \sum_{n=1}^{\infty}{a_n}=\underbrace{a_1+a_2+\dots+a_{n_0-1}}_{\textcolor{rojop2}{\text{cantidad finita de sumandos } <\; \infty}}+\sum_{n=n_0}^{\infty}{a_n}
  $$
\end{obs}

\begin{teo}[Criterio de comparación para series] \; \\
  Si $0 \leq a_n \leq b_n \quad \forall n \geq n_0$, para algún $n_0 \in \mathbb{N}$, entonces $$\sum_{n=n_0}^{\infty}{b_n}\text{ converge }\Rightarrow \sum_{n=n_0}^{\infty}{a_n} \text{ converge.}$$
  Equivalentemente,$$
  \sum_{n=n_0}^{\infty}a_n \text{ diverge } \Rightarrow \sum_{n=n_0}^{\infty}{b_n} \text{ diverge}
  .$$
\end{teo}

\begin{demo} \; \\
  Para cada $k \in \mathbb{N}$ con $k \geq n_0$ definimos $$s_k := a_{n_0}+a_{n_{0}+1}+\dots+a_k \text{\quad y \quad} t_k := b_{n_0}+b_{n_0+1}+\dots+b_k.$$
  Como $\sum_{n=n_0}^{\infty}{b_n}$ converge, entonces existe $\lim_{k \to \infty}{t_k}:=t$.
  \\ 
  Queremos ver que existe $\lim_{k\to\infty}{s_k}.$
\\\\
Por un lado, como $a_n \geq 0$ y $b_n \geq 0$, las sucesiones $\{s_k\}$ y $\{t_k\}$ son crecientes. \\
Además, $a_n \leq b_n$ implica que $s_k \leq t_k \leq \lim_{k \to \infty}{t_k}=t<\infty$, con $t$ que no depdende de $k$. O sea que la sucesión $\{s_k\}$ está acotada y ademas es creciente, por lo tanto existe su límite. Entonces, por definición $\sum_{n=n_0}^{\infty}{a_n}$ es convergente. 

\end{demo}
\pagebreak
\begin{ej}
  Analice la convergencia de las siguientes series.
  \begin{enumerate}
    \item $\sum_{n=1}^{\infty}{\frac{sen(n^2)}{2^n+n}}$. Tenemos que $0 \leq \frac{sen(n)^2}{2^n+n} \leq \frac{1}{2^n}\quad \forall n \in \mathbb{N}.$ Luego, como $\sum_{n=1}^{1\frac{1}{2^n}}$ es convergente (por ser serie geomémtrica con $|r|<1$) por el teorema anterior podemos concluir que $\sum_{n=1}^{\infty}{\frac{sen^2(n)}{2^n+n}}$ converge. \\
    \item $\sum_{n=1}^{\infty}{\frac{2}{n^2+1}}.$ Tenemos que $0 \leq \frac{n}{n^2+n^2}\leq \frac{n}{n^2+1} \quad \forall n \in \mathbb{N}$. Luego, \\
      como $\frac{n}{n^2+n^2}=\frac{n}{2n^2}=\frac{1}{2n}$ y $\sum_{n=1}^{\infty}{\frac{1}{2n}}$ diverge (por ser serie armónica), entonces por el teorema concluimos que $\sum_{n=1}^{\infty}{\frac{n}{n^2+1}}$ diverge.
      
  \end{enumerate}
\end{ej}


\begin{teo}[Criterio de comparación en el límite] \; \\
  Sean $\sum_{n=n_0}^{\infty}{a_n}$ y $\sum_{n=n_0}^{\infty}{b_n}$ series de términos positivos. Entonces \\
  \emph{(i)} \quad Si $\lim_{n \to \infty}{\frac{a_n}{b_n}}:=c>0$, entonces $\sum_{n=n_0}^{\infty}{a_n}$ converge $\Leftrightarrow$ $\sum_{n=n_0}^{\infty}{b_n}$ converge. \\
  \emph{(ii)}\phantom{ii}   Si $\lim_{n\to\infty}{\frac{a_n}{b_n}}=0$, entonces $\sum_{n=n_0}^{\infty}{b_n}$ converge $\Rightarrow \sum_{n=n_0}^{\infty}{a_n}$ converge. $\left(\text{o equivalentemente }\sum_{n=n_0}^{\infty}{a_n} \text{ diverge} \Rightarrow \sum_{n=n_0}^{\infty}{b_n}\text{ diverge.}\right)$ \\
  \emph{(iii)}\; Si $lim_{n\to\infty}{\frac{a_n}{b_n}}=\infty,$ entonces $\sum_{n=n_0}^{\infty}{b_n}$ diverge.$\Rightarrow$ $\Rightarrow \sum_{n=n_0}^{\infty}{a_n}$ diverge.\\ $\left(\text{ o equivalentemente $\sum_{n=n_0}^{\infty}{a_n}\text{ converge} \Rightarrow \sum_{n=n_0}^{\infty}{b_n}\text{ converge.}$}\right)$ 

\end{teo}

\begin{demo} \; \\
  \emph{(i)} \quad $\lim_{n\to\infty}{\frac{a_n}{b_n}}=c$, dado $\epsilon > 0 \; \exists n_1 \in \mathbb{N}$ tq $c-\epsilon \leq \frac{a_n}{b_n} \leq c+\epsilon \quad \forall n \geq n_1$. \\ 
  Tomemos $\epsilon = \frac{c}{2}$, entonces $\exists n_1$ tq $\frac{c}{2} \leq \frac{a_n}{b_n} \leq \frac{3}{2}c$ \quad $\forall n \geq n_1$.\\ Ahora, como $b_n >0$ tenemos que $\frac{c}{2}b_n \underset{(*)}{\leq}a_n \underset{(**)}{\leq} \frac{3}{2} c b_n$ \quad $\forall n \geq n_1$. \\\\
  Luego, si $\sum_{n=n_0}^{\infty}{a_n}$ converge $\Rightarrow \sum_{n=n_1}^{\infty}{a_n}$ converge y como además se cumple (*) por el Teo. de Comparación de series tenemos que $\sum_{n=n_1}^{\infty}{\frac{c}{2}b_n}$ converge y $\therefore \sum_{n=n_0}^{\infty}{b_n}$ es convergente. De la misma forma pero usando (**) podemos ver que \\ 
  $\sum_{n=n_0}^{\infty}{b_n}$ convergente $\Rightarrow \sum_{n=n_0}^{\infty}{a_n}$ convergente. 
Con lo cual vimos \emph{(i)}. \\ \\
\emph{(ii)} Dado $\epsilon=1$, $\exists n_1 \in \mathbb{N}$ tq $-1 \leq \frac{a_n}{b_n} \leq 1$ \; $\forall n \geq n_1$. Más aún, como $a_n$ y $b_n$ son positivos tenemos que $0 < \frac{a_n}{b_N}<1 \; \forall n \geq n_1 $, o sea $0 < a_n \overset{(\cdot)}{\leq}b_n \quad \forall n \geq n_1$. \\
Ahora, si $\sum_{n=n_0}^{\infty}{b_n}$ converge. $\Rightarrow \sum_{n=n_1}^{\infty}{b_n}$ converge y como además se cumple ($\cdot$) por el Teo. de Comparación de series tenemos que $\sum_{n=n_1}^{\infty}{a_n}$ converge $\Rightarrow \sum_{n=n_0}^{\infty}{a_n}$ converge. O sea, vale que \emph{(ii)}. \\ \\ 
\emph{(iii)} Dado $M>0, \exists n_1 \in \mathbb{N}$ tq $\frac{a_n}{b_n} > M \; \forall n \geq n_1$. \\
O sea, $a_n > Mb_n $ \quad $\forall n \geq n_1$ ($\square$). \\
Luego, si $\sum_{n=n_0}^{\infty}{a_n}$ conv. $\Rightarrow \sum_{n=n_1}^{\infty}{a_n}$ conv. y como vale ($\square$), por el Teo. de Comp. tenemos que $\sum_{n=n_1}^{\infty}{Mb_n}$ conv. $\Rightarrow \sum_{n=n_0}^{\infty}{b_n}$ converge.
\end{demo}

\begin{ej}
  determine si la serie $\sum_{n=1}^{\infty}{\frac{1}{2^n-1}}$ converge o diverge. \\
  Notemos que para $n$ muy grande $\frac{1}{2^n-1}$ se comporta como $\frac{1}{2^n}$. Entonces, \\
  sean $a_n=\frac{1}{2^n-1}$ y $b_n=\frac{1}{2^n}$. \\
Luego, $\lim_{n\to\infty}{\frac{a_n}{b_n}}=\lim_{n\to\infty}{\frac{\frac{1}{2^n-1}}{\frac{1}{2^n}}}=\lim_{n\to\infty} {\frac{1}{\frac{2^n-1}{2^n}}}=\lim_{n\to\infty}{\frac{1}{1-\frac{1}{2^n}}}=1$ y \\
como $\sum_{n=1}^{\infty}{\frac{1}{2^n}}$ converge $\left(\text{serie geométrica } r=\frac{1}{2}<1\right)$ $\Rightarrow$ por Teo. $\sum_{n=1}^{\infty}{\frac{1}{2^n-1}}$ converge. 

\end{ej}

\pagebreak

\begin{teo}[Criterio de la integral para series] \; \\
  Sea $f$ una función continua, positiva y decreciente en $[1,\infty)$. Si $a_n=f(n)$, entonces 
  \[
    \underbrace{\sum_{n=1}^{\infty}{a_n}}_{c_1} \text{ converge} \Leftrightarrow \underbrace{\int_{1}^{\infty}{f(x)dx}}_{c_2} \text{ converge.}
  \]
\end{teo}

\begin{obs} \; \\
  \emph{(1)} No es cierto en general que $c_1=c_2$. \\
  \emph{(2)} No es necesario iniciar la serie o la integral en $n=1$. Por ejemplo para la serie $\sum_{n=5}^{\infty}{\frac{1}{(n-4)^2}}$ consideramos la integral $\int_{5}^{\infty}{\frac{1}{(x-4)^2}dx.}$
\end{obs}


\begin{ej}
Analice la convergencia de la serie $\sum_{n=1}^{\infty}{\frac{1}{n^p}}$, para $0<p<\infty$. (también conocida como \underline{serie p}) \\ 
Sea $f(x)=x^{-p}$. Tenemos que $f$ es cont. posit. y decreciente en $[1,\infty)$.\\
Ademas $f(n)=\frac{1}{n^p}$. \\
Es facil ver que $\int_{1}^\infty{\frac{1}{x^p}dx}$ converge $\Leftrightarrow$ $p>1$. (Ejercicio). Luego, por el teo. del Crit. Int. Imp. para series $\sum_{n=1}^{\infty}{\frac{1}{n^p}}$ converge si $p>1$ y diverge si $0<p\leq 1$.
\end{ej}

\begin{defi}
  decimos que una serie es \underline{alternante} si sus terminos son positivos y negativos alternadamente. 
\end{defi}


\begin{ej} \; \\
  \emph{(1)} \quad $1-\frac{1}{2} + \frac{1}{3} - \frac{1}{4}+\frac{1}{5} - \dots = \sum_{n=1}^{\infty}{(-1)^{n+1}\frac{1}{n}}$ \\
  \emph{(2)} \quad $\phantom{1}-\frac{1}{2}+\frac{2}{3}-\frac{3}{4}+\frac{4}{5}-\dots = \sum_{n=1}^{\infty}{(-1)^{n}\frac{n}{n+1}}$
\end{ej}

\pagebreak

\begin{teo}[Criterio para series alternantes]. \; \\
  Si $a_n \geq a_{n+1} > 0 \quad \forall n$ y $\lim_{n\to\infty}{a_n}=0$.   Entonces, $$\sum_{n=1}^{\infty}{(-1)^{n}a_n} \text{ converge} \quad (\text{y por lo tanto} \sum_{n=1}^{\infty}{(-1)^{n+1}a_n} \text{ tambien converge}) $$
\end{teo}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v19.pdf_tex}
\end{figure}

\begin{ej}
  Determine si las siguientes series convergen o divergen. \\
  \emph{(1)} \quad $\sum_{n=1}^{\infty}{(-1)^{n+1}\frac{1}{n}}$. Tenemos que $a_n=\frac{1}{n}$. \\
  Sabemos que $0<n<n+1 \quad \forall n \in \mathbb{N}$ o equiv. $0<\frac{1}{n+1}<\frac{1}{n} \quad \forall n$. O sea, $0<a_{n+1}<a_n \quad \forall n$. Ademas $\lim_{n \to \infty}{a_n}=\lim_{n\to\infty}{\frac{1}{n}}=0.$ Entonces, por el Crit. para series alternantes la serie $\sum_{n=1}^{\infty}{(-1)^{n+1}\frac{1}{n}}$ converge. \\ \\

  \emph{(2)} \quad $\sum_{n=1}^{\infty}{(-1)^{n+1}{\frac{3n}{4n-1}}}$. Como $\lim_{n\to\infty}{a_n}=\lim_{n\to\infty}{\frac{3n}{4n-1}}=\frac{3}{4} \; \Rightarrow \; \lim_{n\to\infty}{(-1)^{n+1}\frac{3n}{4n-1}}$ no existe! y entonces la serie diverge por el crit. de la divergencia.
\\
\\
\emph{(3)} \quad $\sum_{n=1}^{\infty}{(-1)^{n}\frac{ln(n)}{n}}$. Tenemos que $a_n=\frac{ln(n)}{n}\quad \forall n > 1$. \textcolor{rojop2}{(1)} \\
Ademas, como $\lim_{x \to \infty}{\frac{ln(x)}{x}}=\lim_{x\to\infty}{\frac{\frac{1}{x}}{1}}=0 \; \Rightarrow \; $por Teo de Suc. $\lim_{n \to \infty}{\frac{ln(n)}{n}}=\overset{\textcolor{rojop2}{(2)}}{0}$.  \\
Por ultimo, como $\left(\frac{ln(x)}{x}\right)'=\frac{\frac{1}{x}\cdot x -ln(x)}{x^2}=\frac{1}{x^2}\big(1-ln(x)\big)<0 \quad \forall x >e$ \\
tenemos que $a_{n+1}<a_n \quad \forall n \geq 3$ \textcolor{rojop2}{(3)}. \\\\
Luego, de \textcolor{rojop2}{(1)},\textcolor{rojop2}{(2)},\textcolor{rojop2}{(3)} y por el crit. de series alternadas $\sum_{n=3}^{\infty}{(-1)^{n}\frac{ln(n)}{n}}$ converge y con lo cual $\sum_{n=1}^{\infty}{(-1)^{n}\frac{ln(n)}{n}}$ converge. 
\end{ej}

\begin{defi}
  decimos que la serie $\sum_{n=1}^{\infty}{a_n}$ \\
  \underline{converge absolutamente} si la serie $\sum_{n=1}^{\infty}{|a_n|}$ converge y \\
  \underline{converge condicionalmente} si $\sum_{n=1}^{\infty}{a_n}$ converge pero $\sum_{n=1}^{\infty}{|a_n|}$ no converge.
\end{defi}

\begin{ej}
  La serie $\sum_{n=1}^{\infty}{\frac{(-1)^{n+1}}{n^2}}$ converge absolutamente ya que la serie\\
  $\sum_{n=1}^{\infty}{\left\vert\frac{(-1)^{n+1}}{n^2}\right\vert} = \sum_{n=1}^{\infty}{\frac{1}{n^2}}$ converge por ser serie $p$ con $p=2>1$.
\end{ej}

\begin{teo}
  Si $\sum_{n=1}^{\infty}{a_n}$ converge absolutamente $\Longrightarrow \sum_{n=1}^{\infty}{a_n}$ converge.
\end{teo}

\begin{demo} \; \\
  Tenemos que $-|a_n| \leq a_n \leq |a_n| \quad \forall n \in \mathbb{N}$, luego, $0 \leq a_n + |a_n \leq 2 |a_n| \quad \forall n \in \mathbb{N}$. Como por hipótesis $\sum_{n=1}^{\infty}{a_n}$ es convergente, entonces por el Teo. de Comparacion de series $\sum_{n=1}^{\infty}{a_n+|a_n|}$ es convergente. Luego $\sum_{n=1}^{\infty}{a_n+|a_n|}-\sum_{n=1}^{\infty}{|a_n|}=\sum_{n=1}^{\infty}{a_n}$ es convergente. \qed
\end{demo}


\begin{ej}
  Decida si la serie $\sum_{n=1}^{\infty}{\frac{cos(n)}{n^2}}$ converge o diverge. \\
  Tenemos que $0 \leq \left| \frac{cos(n)}{n^2} \right| \leq \frac{1}{n^2} \quad \forall n \in \mathbb{N}$. Ademas, $\sum_{n=1}^{\infty}{\frac{1}{n^2}}$ converge (es serie $p=2>1$). \\
  Luego, por Teo. Comparacion $\sum_{n=1}^{\infty}{\left| \frac{cos(n)}{n^2} \right|}$ converge y con lo cual $\sum_{n=1}^{\infty}{\frac{cos(n)}{n^2}}$ converge.
\end{ej}

\begin{obs}
  NO vale la reciproca, o sea $\sum_{n=1}^{\infty}{a_n}$ conv. $\not\Rightarrow \sum_{n=1}^{\infty}{|a_n|}$ conv. \\
  Por ejemplo, $\sum_{n=1}^{\infty}{\frac{(-1)^{n+1}}{n}}$ converge (por crit. series alternantes) pero \\ $\sum_{n=1}^{\infty}{ \left| \frac{(-1)^{n+1}}{n} \right|} = \sum_{n=1}^{\infty}{\frac{1}{n}}$ diverge (serie armonica). \\
  $\bullet$ \quad En este caso decimos que la serie converge condicionalmente.
\end{obs}

\begin{teo}[Criterio del cociente] \; \\
Sean $a_n \neq 0 \quad \forall n \geq n_0$ y $r := \lim_{n\to\infty}{ \left| \frac{a_{n+1}}{a_n} \right|}$. \\ 
\emph{(i)} \quad Si $r<1$, entonces la serie $\sum_{n=1}^{\infty}{a_n}$ converge absolutamente (y por lo tanto es convergente). \\
\emph{(ii)} \quad Si $r>1$, entonces la serie $\sum_{n=1}^{\infty}{a_n}$ es divergente (puede ser $r=\infty$). \\
\emph{(iii)} \quad Si $r=1$, entonces no se puede asegurar nada.
\end{teo}


\begin{ej} analice si la serie $\sum_{n=1}^{\infty}{\frac{c^n}{n!}}$, con $c\neq0$, converge o diverge. \\
  Tenemos que $\lim_{n\to\infty}{\frac{|a_{n+1}|}{|a_n|}}=\lim_{n\to\infty}{\frac{\frac{|c|^{n+1}}{(n+1)!}}{\frac{|c|^n}{n!}}}=\lim_{n\to\infty}{\frac{|c|^{c+1}n!}{|c|^n(n+1)!}}=\lim_{n\to\infty}{\frac{|c|}{n+1}}=0.$ \\ Luego, por el crit. del cociente la serie $\sum_{n=1}^{\infty}{\frac{c^n}{n!}}$ conv. absolutamente (ya que $0 = r < 1$) (y $\therefore$ converge). \\
\end{ej}

\begin{obs}
  notar que del ejemplo anterior podemos concluir que \\$\lim_{n\to\infty}{\frac{c^n}{n!}}=0 \quad \forall c \in \mathbb{R}$ (sale usando el criterio de la divergencia).
\end{obs}

\pagebreak
\begin{ej}
  analice la convergencia de la serie $\sum_{n=1}^{\infty}{nc^n}$, para $c \neq 0$. \\
  Tenemos que $\lim_{n\to\infty}{\frac{|a_{n+1}|}{|a_n|}}=\lim_{n\to\infty}{\frac{(n+1)|c|^{n+1}}{n|c|^n}}=\lim_{n\to\infty}{|c| \frac{(n+1)}{n}}=|c|.$ Por lo tanto, \\
  $\bullet$ \quad si $|c| < 1$, la serie converge absolutamente. \\
  $\bullet$ \quad si $|c| > 1$, la serie diverge. \\
  $\bullet$ \quad si $c=1$, la serie $\sum_{n=1}^{\infty}{n}$ diverge por crit. divergencia. \\
  $\bullet$ \quad si $c=-1$, la serie $\sum_{n=1}^{\infty}{(-1)^nn}$ diverge por crit. de divergencia.
\end{ej}

\begin{teo}[Criterio de la raiz] Dada la serie $\sum_{n=1}^{\infty}{a_n}$, sea $r:=\lim_{n\to\infty}{\sqrt[n]{|a_n|}}.$
  \emph{(i)\phantom{ii}} \quad si $r<1$, entonces la serie es absolutamente conv. (y por lo tanto es convergente). \\
  \emph{(ii)\phantom{i}} \quad si $r>1$, entonces la serie diverge. (puede ser $r=\infty$)\\(puede ser $r=\infty$) \\
  \emph{(iii)} \quad si $r=1$, no se puede asegurar nada.
\end{teo}

\section{Series de Potencias.}

Vamos a estudiar series en las cuales los terminos dependen de una variable \\ o sea $\sum_{n=0}^{\infty}{C_n (x-a)^n}$, con $a \in \mathbb{R}$ fijo y $x \in \mathbb{R}$.
\\\\
Estas series son una generalizacion de los polinomios y tienen muchas aplicaciones.
\\\\
Por ejemplo, se las utiliza para aproximar funciones como $sen(x)$, $e^x$, $\sqrt{x}$ y tambien para aproximar integrales como $\int_{0}^{1}{e^{-x^2}dx}$, ya que tienen propiedades que las convierten en faciles de manipular.
\pagebreak 
\begin{defi}
  Sean $\{C_n\}_{n=0}^{\infty}$ una sucesion de numeros reales y $a \in \mathbb{R}$. Llamamos serie de potencias centrada en $a$, a la serie 
  \[ 
  \sum_{n=0}^{\infty}{C_n(x-a)^n} = C_0+C_1(x-a)+C_2(x-a)^2+\dots 
  \]
  (notar que adoptamos la convencion $(x-a)^0=1$ aun cuando $x=a$).
\end{defi}
\bl En el caso particular de $a=0$, la serie de potencias es de la forma $\sum_{n=0}^{\infty}{C_nx^n}$. 

\begin{obs} \; \\
  Observemos que para cada $x \in \mathbb{R}$ fijo, $\sum_{n=0}^{\infty}{C_n(x-a)^n}$ es una serie de terminos constantes, o sea una serie numerica. A continuacion vamos a estudiar criterios para para cuales $x \in \mathbb{R}$ la serie converge.  
\end{obs}
\bl Notar que si $x=a$, $\sum_{n=0}^{\infty}{C_n(x-a)^n}=C_0 < \infty$, o sea, toda serie de potencias centrada en $a$ converge en $x=a$.
 \\  \\
 \bl Hay series de potencias que solo convergen en $x=a$ otras que convergen para algunos $x \in \mathbb{R}$ y otras que convergen en todo $x \in \mathbb{R}$.
\begin{ej}
  Sea $\{C_n\}_{n=0}^{\infty} = \{1\}_{n=0}^{\infty}$, y $a=0$, entonces la serie de potencias centrada en $0$ tiene la forma $\sum_{n=0}^{\infty}{x^n \; (\star)\leadsto}$ serie geometrica. \\ 
  Ya sabemos que la serie $(\star)$ converge y vale $\frac{1}{1-x} \; \Longleftrightarrow \; |x| < 1 $
    
\end{ej}
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v20.pdf_tex}
\end{figure}
\pagebreak
\begin{teo}
  Sea $\sum_{n=0}^{\infty}{C_n(x-a)^n}$ una serie de potencias. Entonces, se cumple exactamente una de las siguientes: \\ 
   
  \emph{(i)\phantom{ii}} La serie converge sólo cuando $x=a$. \\\\ 
  \emph{(ii)\phantom{i}}  La serie es absolutamente convergente $\forall x \in \mathbb{R}$.   \\ \\  
  \emph{(iii)} $\exists \; R > 0$ tq la serie converge absolutamente $\forall x \; tq \; |x-a| < R$ y es divergente $\forall x \; tq \; |x-a| > R$. \\ (más adelante veremos una manera de calcular R) 

\end{teo}
\begin{obs}
Graficamente \emph{(iii)} denota 
\end{obs}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v21.pdf_tex}
\end{figure}


\begin{defi}
  Sea $\sum_{n=0}^{\infty}{C_n(x-a)^n}$ una serie de potencias. \\\\
\emph{(A)} Decimos que la serie tiene radio de convergencia $R=0$ si sólo converge en $x=a$.
\\ 
$\emph{(B)}$ Decimos que la serie tiene radio de convergencia $R=\infty$ si converge $\forall x \in \mathbb{R}$. 
\\
\emph{(C)} Si ocurre \emph{(iii)} en el teorema anterior decimos que $R$ es su radio de convergencia.
\end{defi}
\pagebreak
\begin{defi}
  Llamamos intervalo de convergencia al conjunto 
  \[ 
    I=\left\{ x \in \mathbb{R} : \sum_{n=0}^{\infty}{C_n(x-a)^n \text{ converge}}\right\}
  \]
\end{defi}

\begin{obs} \; \\\\
$\begin{array}{ll}
  $\bl$ \text{Si } $R = 0$, & \text{entonces } I=\{a\}. \\\\
  $\bl$ \text{Si } R=\infty, & \text{entonces } I=(-\infty,\infty)=\mathbb{R}. \\\\
  $\bl$ \text{Si } 0<R<\infty, & \text{entonces } I \text{ puede ser} \\
  \end{array}$ \\
  $ \quad (a-R,a+R) \; , \; (a-R,a+R] \; , \; [a-R, a+R) \; \text{o} \; [a-R,a+R].$
\end{obs}

\begin{obs}
  Notar que si $\sum_{n=0}^{\infty}{c_n(x-a)^n}$ converge en algun $\textcolor{verdep2}{x_0} \neq a $, entonces por \emph{(iii)} del teorema anterior $R \geq |x_0-a|$ y ademas la serie \\ converge \textcolor{verdep2}{ $\forall x$ tq $|x-a|< |x_0-a|$}. 
  \\
  Por otro lado, si la serie diverge en \textcolor{rojop2}{$x_1$}, entonces $R \leq |x_1-a|$ y ademas la serie  diverge \;  \textcolor{rojop2}{$\forall x$ tq $|x-a|>|x_1-a|$}.
\end{obs}
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v22.pdf_tex}
\end{figure}

\begin{ej}
  Determine el radio de convergencia $R$ y el intervalo de convergencia $I$ del a serie $\sum_{n=1}^{\infty}{\frac{1}{n}x^n}. \quad \quad \textcolor{azulp2}{\left(c_n=\frac{1}{n}, \; \; a=0\right)}$ \\ 
  \\
  \bl Si \textcolor{rojop2}{$x=\phantom{-}1$}, tenemos \textcolor{rojop2}{$\sum_{n=1}^{\infty}{\frac{1}{n}}$ divergente }(serie armonica). \\Luego, \textcolor{rojop2}{$R \leq 1$}. \textcolor{azulp2}{(1)} \\
  \\
  \bl Si \textcolor{verdep2}{$x=-1$}, tenemos \textcolor{verdep2}{$\sum_{n=1}^{\infty}{(-1)^n\frac{1}{n}}$ convergente }(crit. series alternantes). \\Luego, \textcolor{verdep2}{$R \geq 1$}. \textcolor{azulp2}{(2)} 
  \\\\
  De \textcolor{azulp2}{(1)} y  \textcolor{azulp2}{(2)} concluimos que $R=1$ y que $I=\textcolor{verdep2}{[}-1,1\textcolor{rojop2}{)}.$
\end{ej}

\pagebreak

A continuacion veremos un criterio que nos permite calcular el radio de convergencia.

\begin{teo}[Criterio del cociente para series de potencias] \; \\
  Dada la serie de potencias $\sum_{n=0}^{\infty}{c_n(x-a)^n}$, con $c_n \neq 0$\; $\forall n \geq n_0$ y $R$ su radio de convergencia. Escribimos \[ 
    L := \lim_{n\to\infty}{\frac{|c_{n+1}|}{|c_{n}|}}.
  \]
 $\left.
\begin{array}{lll}
  \emph{(i)\phantom{ii}} \text{ Si } & 0<L<\infty, & \text{entonces }R=\frac{1}{L}. \\
  \emph{(ii)\phantom{i}} \text{ Si} & \phantom{abcd}L=0, & \text{entonces }R=\infty. \\
  \emph{(iii)} \text{ Si } & \phantom{abcd}L=\infty, & \text{entonces }R=0.
\end{array}\right. \quad \quad ``R=\frac{1}{L}."$
\end{teo}

\begin{demo}
  Para cada $x\neq a$, podemos aplicar el criterio del cociente para series numericas a la serie $I=\sum_{n=0}^{\infty}{\textcolor{rojop2}{\underbrace{\textcolor{black}{c_n(x-a)^n}}_{a_n}}}$.
\\
Tenemos que \[
  \lim_{n\to\infty}{\frac{\left|a_{n+1}\right|}{\left|a_n\right|}}=\lim_{n\to\infty}{\frac{\left|c_{n+1}(x-a)^{n+1}\right|}{\left|c_n(x-a)^n\right|}}=\lim_{n\to\infty}{\frac{\left|c_{n+1}\right|}{\left|c_n\right|}|x-a|}=L|x-a|.
\]\\
\emph{(i)\phantom{ii}} Supongamos $0<L<\infty$. \\
Luego, por el crit. del cociente para series numericas si $\left\{\begin{array}{l}
    L|x-a|<1 \Rightarrow I \text{ converge absolutamente.} \\
    L|x-a|>1 \Rightarrow I \text{ diverge.}
\end{array}\right.$ \\ 
O sea, si $\left\{\begin{array}{l}
    |x-a|<\frac{1}{L} \Rightarrow I \text{ conv. absolutamente.} \\ 
    |x-a| > \frac{1}{L} \Rightarrow I \text{ diverge}.
\end{array}\right.$ \quad \quad $\therefore R=\frac{1}{L}.$ \\\\
\emph{(ii)\phantom{i}} Si $L=0$,\phantom{,,} entonces $L|x-a|<1|$ $ \forall x \in \mathbb{R}$ y $\therefore R=\infty$. \\ \\
\emph{(iii)} Si $L=\infty$, entonces $L|x-a|=\infty$ $\forall x \neq a$ y $\therefore R=0$.
\end{demo}

\begin{ej}
  Calcule el radio $R$ e intervalo de convergencia $I$ de las siguientes series de potencias. \\ \\ 
\emph{(1)} $\sum_{n=0}^{\infty}{n!x^n}$. \quad \quad $\left(\
  \begin{array}{l}
c_n=n! > 0 \\ 
a\phantom{_n}=0
  \end{array}
  \right)$ \\
Tenemos que $\lim_{n\to\infty}{\frac{|c_{n+1}|}{c_n}}=\lim_{n\to\infty}{\frac{(n+1)!}{n!}}=\lim_{n\to\infty}{n+1}=\infty.$ \\Luego, $R=0$ e $I=\{0\}$. (o se, la serie diverge $\forall x \neq 0$). \\ \\ \\ 
\emph{(2)} $\sum_{n=0}^{\infty}{n^3x^n}$\quad \quad $\left(\
  \begin{array}{l}
    c_n=n^3 > 0 \\ 
a\phantom{_n}=0
  \end{array}
  \right)$ \\
  Tenemos que $\lim_{n\to\infty}{\frac{|c_{n+1}|}{|c_n|}}=\lim_{n\to\infty}{\frac{(n+1)^3}{n^3}}=1(=L)$. Luego, $R=1(=\frac{1}{L})$. \\
  Ademas, en $x=-1$ y en $x=1$ la serie diverge (por el criterio de la divergencia). \\
  Entonces $I=(-1,1).$
\\ \\
\emph{(3)} $\sum_{n=1}^{\infty}{(-1)^{n+1}\frac{2^n}{n3^n}(x-1)^n}$\quad \quad $\left(\
  \begin{array}{l}
    c_n=(-1)^{n+1}\frac{2^n}{n3^n} \\ 
a\phantom{_n}=1
  \end{array}
  \right)$ \\
  Tenemos que $\lim_{n\to\infty}{\frac{|c_{n+1}|}{|c_n|}}
=
\lim_{n\to\infty}{\frac{\frac{2^{n+1}}{(n+1)3^{n+1}}}{\frac{2^n}{n3^n}}}
=
\lim_{n\to\infty}{\frac{2}{3}\frac{n}{n+1}}
=
\frac{2}{3}$. Luego, $R=\frac{3}{2}.$
\\
\\
\\
Veamos que pasa en $x=a-R=1-\frac{3}{2}$\; y \;$x=a+R=1+\frac{3}{2}$. \\\\
\bl Si $x=1-\frac{3}{2}$, obtenemos $\sum_{n=1}^{\infty}{(-1)^{n+1}{\frac{2^n}{n3^n}\left(-\frac{3}{2}\right)^n}}=\sum_{n=1}^{\infty}{(-1)^{2n+1}\frac{1}{n}}$. \\ $\longrightarrow$ diverge (por ser serie armonica). \\ 
\\
\bl Si $x=1+\frac{3}{2}$, obtenemos $\sum_{n=1}^{\infty}{(-1)^{n+1}\frac{2^n}{n3^n}\left(\frac{3}{2}\right)^n}=\sum_{n=1}^{\infty}{(-1)^{n+1}\frac{1}{n}}$. \\ $\longrightarrow$ converge (por criterio para series alternantes). \\ \\ 
Por lo tanto, el intervalo de convergencia es $I=\left(1-\frac{3}{2},1+\frac{3}{2}\right]=\left(-\frac{1}{2},\frac{5}{2}\right]$. 
\end{ej}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v23.pdf_tex}
\end{figure}

\pagebreak


\begin{center}
  \textbf{Representación de funciones como series de potencias}
\end{center}
Para cada $x$ tq la serie de potencias $\sum_{n=0}^{\infty}{c_n(x-a)^n}$ converge, la serie define una funcion $f(x):=\sum_{n=0}^{\infty}{c_n(x-a)^n}$ cuyo dominio es el intervalo de convergencia. 

\begin{ej} \; \\ 
  \emph{(1)} \quad $\frac{1}{1-x}=1+x+x^2+\dots =\sum_{n=0}^{\infty}{x^n}$, si $|x|<1$. \\ \\
  \emph{(2)} \quad $\frac{1}{1+x^2}= \frac{1}{1-(-x^2)} \overset{\textcolor{rojop2}{(\bigstar)}}{=}\sum_{n=0}^{\infty}{(-x^2)^n}=\sum_{n=0}^{\infty}{(-1)^nx^{2n}}$, la igualdad $\textcolor{rojop2}{(\star)}$ vale si $|-x^2|<1$, o sea, si $|x|<1$. \\ Luego, $\frac{1}{1+x^2} = \sum_{n=0}^{\infty}{(-1)^nx^{2n}}$, si $|x|<1$ \big($\Leftrightarrow x \in (-1,1)$\big). \\\\
\emph{(3)} \quad $\frac{1}{2+x}=\frac{1}{2\left(1-\left(-\frac{x}{2}\right)\right)} \overset{\textcolor{azulp2}{(\bigstar)}}{=}\frac{1}{2}\sum_{n=0}^{\infty}{\left(-\frac{x}{2}\right)^n}=\sum_{n=0}^{\infty}{\frac{(-1)^nx^n}{2^{n+1}}}$, la igualdad \textcolor{azulp2}{($\star$)} vale si $\left|-\frac{x}{2}\right|<1$, o sea $|x|<2$. \\ Luego, $\frac{1}{2+x}=\sum_{n=0}^{\infty}{\frac{(-1)^n}{2^{n+1}}x^n}$, si $x \in (-2,2)$.
\end{ej}

\begin{teo}[Derivación e integración de una serie de potencias] \; \\
  Si la serie de potencias $\sum_{n=1}^{\infty}{c_n(x-a)^n}$ tiene radio de convergencia $R>0$, entonces la función $f(x) := c_0 + c_1 (x-a) + c_2 (x-a)^2 + \dots = \sum_{n=0}^{\infty}{c_n(x-a)^n}$ es derivable (y por lo tanto continua) en el intervalo $\big(a-R, a + R\big)$. Además  \\\\ $\begin{array}{ll}
    \emph{(i)\phantom{i}} f'(x) & = c_1+2c_2(x-a)+3c_3(x-a)^2+\dots \\
                                & = \sum_{n=1}^{\infty}{nc_n(x-a)^{n-1}}.  \\\\
    \emph{(ii)} \int{f(x)dx} & = C+c_0(x-a)+c_1\frac{(x-a)^2}{2}+c_2\frac{(x-a)^3}{3}+\dots \\ 
                             & =C+\sum_{n=0}^{\infty}{\frac{c_n}{n+1}(x-a)^{n+1}}. 
  \end{array}$ \\ \\ Los radios de convergencia de las series de potencia de \emph{(i)} y \emph{(ii)} son R.
\end{teo} \pagebreak
\begin{obs} \; \\
  Puede suceder que los intervalos de convergencias de \emph{(i)} y \emph{(ii)} \textbf{no} sean igual al de la serie original.
\end{obs}
 
\begin{obs} \; \\
Otra forma de escribir las ecuaciones \emph{(i)} y \emph{(ii)} es \\ \\ $\begin{array}{llcr}
\text{(I)\phantom{i}} \frac{d}{dx} \left[\sum_{n=0}^{\infty}{c_n(x-a)^n}\right] &  =\sum_{n=0}^{\infty}{\frac{d}{dx}\left[c_n(x-a)^n\right]} & & \text{\big(``se deriva término a término''\big)}\\ \\
\text{(II)} \int{\left[\sum_{n=0}^{\infty}{c_n(x-a)^n}\right]} &  =\sum_{n=0}^{\infty}{\int{c_n(x-a)^ndx}}& & \text{\big(``se integra término a término''\big)}\\

\end{array}$
\end{obs}

\begin{ej} \; \\
 (1) \quad  Expresar la función $g(x)=\frac{1}{(1-x)^2}$ como una serie de potencias. \\ \\
  Notemos que $g(x)\overset{\textcolor{rojop2}{(\star)}}{=}f'(x)$ con $f(x)=\frac{1}{1-x}.$ \\ 
  Ademas sabemos que $f(x)\overset{\textcolor{rojop2}{(\star\star)}}{=}\sum_{n=0}^{\infty}{x^n}$ si $|x|<1$, o sea su radio de conv. es $1$. \\ 
  Luego, \[\frac{1}{(1-x)^2}=g(x)\overset{\textcolor{rojop2}{(\star)}}{=}f'(x)\overset{\textcolor{rojop2}{(\star\star)}}{=}\left[\sum_{n=0}^{\infty}{x^n}\right]'\overset{\textcolor{rojop2}{\text{(I)}}}{=}\sum_{n=0}^{\infty}{nx^{n-1}}=\sum_{n=0}^{\infty}{(n+1)x^n}\] y el radio de convergencia es $R=1$. \\ \\ \\
  (2) Expresar la función $ln(x-1)$ como una serie de potencias. \\ \\ 
  Observemos que  $-ln(1-x)\overset{\textcolor{rojop2}{(\star)}}{=}\int{f(x)dx}$, con $f(x)=\frac{1}{1-x}$. \\
  Ademas, $f(x)\overset{\textcolor{rojop2}{(\star\star)}}{=}\sum_{n=0}^{\infty}{x^n}$, si $|x|<1$. \\
  Luego \[
-ln(1-x)\overset{\textcolor{rojop2}{(\star)}}{=}\int{f(x)dx}\overset{\textcolor{rojop2}{(\star\star)}}{=}\int{\sum_{n=0}^{\infty}{x^n}dx}\overset{\textcolor{rojop2}{\text{(II)}}}{=}\sum_{n=0}^{\infty}{\int{x^ndx}}=C+\sum_{n=1}^{\infty}{\frac{x^n}{n}}, \quad \text{si } |x|<1.
  \]
  Para determinar $C$, evaluamos en $x=0$ obteniendo \[
-ln(1)=C \quad \Rightarrow \quad C=0.
  \]
  Por lo tanto \quad $ln(1-x)=-\sum_{n=1}^{\infty}{\frac{x^n}{n}}$, si $|x|<1$ \quad \big(o sea $R=1$\big).
\end{ej} 
\pagebreak
\begin{center}
  \textbf{Serie de Taylor y Polinomio de Taylor.}
\end{center}
Queremos estudiar: ¿qué funciones se pueden representar como series de potencias? ¿cómo es posible hallar esa representación? \\\\

\bl Sea $f$ una funcion que se puede representar como serie de potencias, es decir \[ 
  f(x)=c_0+c_1(x-a)+c_2(x-a)^2+c_3(x-a)^3+\dots = \sum_{n=0}^{\infty}{c_n(x-a)^n} \quad \forall x \in \big(a-R,a+R\big).
\]

 Si evaluamos $f$ en $x=a$, obtenemos \fbox{$f(a)=c_0$}.
\\\\
\bl Por el teorema anterior, podemos derivar $f$ y obtenemos \[
f'(x)=c_1+2c_2(x-a)+3c_3(x-a)^2+4c_4(x-a)^3+\dots
\]
 Si evaluamos $f'$ en $x=a$, obtenemos \fbox{$f'(a)=c_1$}.
\\\\
\bl Aplicando nuevamente el teorema a $f'$ nos queda 
\[ 
f''(x)=2c_2+2\cdot 3 c_3 (x-a)+3\cdot 4 c_4(x-a)^2+\dots
\]
 Si evaluamos $f''$ en $x=a$, obtenemos \fbox{$f''(a)=2c_2$}. \\  

\bl Aplicando el teorema a $f''$ nos queda \[ 
f'''(x)=2\cdot 3 c_3+2\cdot3\cdot4 c_4(x-a)+\dots
\] \\
 Si evaluamos $f'''$ en $x=a$, obtenemos \fbox{$f'''(a)=2\cdot3c_3$}.
\\\\
De manera general, obtenemos \fbox{$f^{(n)}(a)=n!c_n$} donde $f^{(n)}$ es la derivada n-esima  de $f$ y $n!=1\cdot2\cdot3\cdots n$ \big(con la convencion $0!=!$ y $f^{(0)}=f$\big).
\\\\
Hemos demostrado el siguiente teorema:
\begin{teo} \; \\
Si $f$ se puede representar como una serie de potencias centrada en $a$, es decir, si $f(x)=\sum_{n=0}^{\infty}{c_n(x-a)^n}\quad \forall x$ tq $|x-a|<R$. Entonces \[
  c_n=\frac{f^{(n)}(a)}{n!}.
\] 
\end{teo}
\pagebreak
\begin{defi}
  dada una funcion $f$ que tiene derivadas de todos los ordendes en $a$, se llama \underline{serie de Taylor de $f$ centrada en $a$} a la serie de potencias \[
  \sum_{n=0}^{\infty}{\frac{f^{(n)}(a)}{n!}(x-a)^n}
  =
f(a) + f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^2+\frac{f'''(a)}{3!}(x-a)^3+\dots
\]
\end{defi}

\begin{obs}\; \\
  \emph{(1)} Para el caso especial $a=0$ la serie queda $\sum_{n=0}^{\infty}{\frac{f^{(n)}(0)}{n!}x^n}$ y se suele llamar Serie de Maclaurin. \\ \\
  \emph{(2)} El teorema anterior nos dice que si $f$ se puede respresentar como una serie de potencias centrada en $a$, entonces esa serie es la serie de Taylor de $f$ centrada en $a$ (y por lo tanto $f$ es igual a su serie de Taylor).
\end{obs}

\begin{ej}
  calcule la serie de Taylor de $f(x)=e^x$ centrada en $a=0$ (Maclaurin) y determine su radio de convergencia.
\\\\
\bl Para calcular de Serie de Taylor de $f$ en $0$ debemos hallar $f^{(n)}(0)$ \quad $\forall  n \geq 0$. \\ \\
Como en este caso $f^{(n)}(x)=e^x$ $\quad \forall n \geq 0$, tenemos que $f^{(n)}(0)=1 \quad \forall n \geq 0$. \\
Luego, $\sum_{n=0}^{\infty}{\frac{f^{(n)}(0)}{n!}x^n=\sum_{n=0}^{\infty}{\frac{x^n}{n!}=1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\dots}}$
 \\ \\  \\
 \bl Para averiguar su radio de convergencia utilizamos el criterio del cociente. \\ 
 Como $L=\lim_{n\to\infty}{\frac{|c_{n+1}|}{|c_{n}|}}=\lim_{n\to\infty}{\frac{n!}{(n+1)!}}=\lim_{n\to\infty}{\frac{1}{n+1}=0} \quad \Rightarrow \quad R=\infty.$
\end{ej}

\underline{Conclusion}: $\sum_{n=0}^{\infty}{\frac{x^n}{n!}}$ converge $\forall x \in \mathbb{R}$ 
$\left(\text{esto nos dice que }\lim_{n\to\infty}{\frac{x^n}{n!}}=0\text{ para cualquier }x \in \mathbb{R}\right)$.
\\\\
\bl Nos preguntamos ahora: ¿es cierto que $e^x=\sum_{n=0}^{\infty}{\frac{x^n}{n!}}$? \\\\
O de manera mas general: ¿cuando una funcion $f$ es igual a su serie de Taylor? es decir, ¿cuando es cierto que $f(x)=\sum_{n=0}^{\infty}{\frac{f^{(n)}(a)}{n!}(x-a)^n}$?
\pagebreak
\begin{defi}
\; \\ 
Sea $f$ tq existen $f'(a), f''(a), \dots ,f^{(n)}(a).$ Para $n \geq 0$, definios el \underline{polinomio de} \underline{Taylor de $f$ de orden $n$ centrado en $a$} como \[ \begin{array}{lll}
T_{n,a}(x)& := & \sum_{j=0}^{n}{\frac{f^{(j)}(a)}{j!}(x-a)^j} \\ & \phantom{:}= & f(a)+f'(a)(x-a)+\frac{}{}(x-a)^2+\dots+\frac{f^{(n)}(a)}{n!}(x-a)^n. \end{array}
\]
\end{defi}

\begin{obs} \; \\
  \emph{(1)} Notar que la n-esima suma parcial de la serie de Taylor es justamente el poliomio de Taylor de orden $n$.
  \\\\
  \emph{(2)} Notar que $T_{1,a}$ es la recta tangente al grafico de $f$ en el punto $\big(a,f(a)\big)$.
  \\\\
  \emph{(3)} Notar que $f$ y su polinomio de Taylor de orden $n$ $T_{n,a}$ satisfacen que \\ $f^{(j)}(a)=T^{(j)}(a)\quad \forall j \text{ tq }0 \leq j \leq n$
\end{obs}

\begin{tikzpicture}
\begin{axis}[
  legend pos=outer north east,
  legend cell align={left},
  ticks=none,
  axis lines = middle,
  xmin=-2, xmax=2,
  ymin=-1, ymax=2,
  ]
\addplot [
    domain=-2:2, 
    samples=100, 
    color=black,
    ]
    {e^x};


\addplot [
    domain=-2:2, 
    samples=100, 
    color=orange,
    ]
    {1};

\addplot [
    domain=-2:2, 
    samples=100, 
    color=verdep2,
    ]
    {1+x};

\addplot [
    domain=-2:2, 
    samples=100, 
    color=azulp2,
    ]
    {1+x+x^2/2};

\addplot [
    domain=-2:2, 
    samples=100, 
    color=purple,
    ]
    {1+x+x^2/2+x^3/6};
 \legend{
$y=e^x$,
$T_{0,0}(x)=f(0)=e^0=1$,
$T_{1,0}(x)=f(0)+f'(0)x+1+x$,
$T_{2,0}(x)=f(0)+f'(0)x+f''(0)\frac{x^2}{2!}=1+x+\frac{x^2}{2}$,
$T_{3,0}(x)=f(0)+\dots+f'''(0)\frac{x^3}{3!}=1+x+\frac{x^2}{2}+\frac{x^3}{6}$,
  }
\addlegendentry{Measurment}
\end{axis}
\end{tikzpicture}

\begin{defi}
  se define el \underline{resto de Taylor de orden $n$ centrado en $a$} como \[
  R_{n,a}(x):=f(x)-T_{n,a}(x)
\] $\big($Por lo tanto, $f(x)=T_{n,a}(x)+R_{n,a}(x)\big)$.
\end{defi}

\begin{defi}
 Sea $f$ una funcion tq existe $f^{(n)}(a)$ \quad $\forall n \geq 0$. Se cumple \end{defi}\[
   f(x)=\sum_{n=0}^{\infty}{\frac{f^{(n)}(a)}{n!}(x-a)^n} \; \forall x \in \big(a-c,a+c\big) \quad \Leftrightarrow \quad \lim_{n\to\infty}{R_{n,a}(a)}=0 \; \forall x \in \big(a-c,a+c\big).
 \] \;
 \pagebreak 
 
 \begin{demo} \; \\
   $\Rightarrow )$ Supongamos que $f(x)=\sum_{n=0}^{\infty}{\frac{f^{(n)}(a)}{n!}(x-a)^n}$. Entonces por definicion de serie tenemos que $f(x)=\lim_{n\to\infty}{T_{n,a}} \quad \big(\text{limite de sumas parciales}\big)$. \\\\\\
   $\Leftarrow )$ Si $\lim_{n\to\infty}{R_{n,a}(a)}=0 \quad \forall x \in \big(a-c,a+c\big)$, entonces \[ 
     \lim_{n\to\infty}{T_{n,a}}=\lim_{n\to\infty}{\big(f(x)-R_{n,a}(x)\big)}=f(x)-\lim_{n\to\infty}{R_{n,a}(x)}=f(x) \quad \forall x \in \big(a-c,a+c\big).
   \]\qed
 \end{demo}

\bl Para usar el teorema anterior necesitamos tener alguna expresion para $R_{n,a}$
\begin{teo}[Formula de Lagrange para el resto] \; \\
  Sea $f$ una funcion tq existen $f', f'', \dots, f^{(n+1)}$ en un intervalo abierto $I$ y sea $a \in I$. Entonces, para cada $x \in I$ existe $t$ entre $x$ y $a$ $\big(t \in (x,a) \text{ si }x<a \;\; \text{ y } \;\; t \in (a,x) \text{ si } x>a\big)$ tal que \[ 
    R_{n,a}(x)=\frac{f^{(n+1)}(t)}{(n+1)!}(x-a)^{n+1}.
  \]
\end{teo}

\begin{defi} \; \\
  Llamamos formula de Taylor a  
  \begin{align*}
   &  &&f(x)=\sum_{j=0}^{n}{\frac{f^{(j)}(a)}{j!}(x-a)^j}&&+\frac{f^{(n+1)}(t)}{(n+1)!}(x-a)^{n+1}. \\ 
   &      &&\phantom{f(x)}= T_{n,a}(x) &&+ R_{n,a}(x) 
  \end{align*}
   con $t$ entre $a$ y $x$. 
\end{defi}
\pagebreak
\begin{center}
\textbf{Ejemplos y Aplicaciones.}
\end{center}

\begin{ej} \; \\
  Probar que $e^x = \sum_{n=0}^{\infty}{\frac{x^n}{n!}}\quad \forall x \in \mathbb{R}$.\\\\
  \bl Ya vimos que $\sum_{n=0}^{\infty}{\frac{x^n}{n!}}$ es la serie de Taylor de $\overset{f(x)=e^x}{f}$ \\ \\
  \bl Para probar que vale la igualdad, por el teorema anterior basta ver que $\lim_{n\to\infty}{R_{n,0}(x)=0}$. \\
  Por la formula de Lagrange $\R_{n,0}(x)=\frac{f^{(n+1)}(t)}{(n+1)!}x^{n+1}=\frac{e^tx^{n+1}}{(n+1)!}$, para algun $t$ entre $0$ y $x$. \\
  Luego, para $t \in \big(-x,x\big)$ tenemos \[ 
    0 \leq |R_{n,0}(x)|=\frac{e^t|x|^{n+1}}{(n+1)!} \leq e^{|x|} \frac{|x|^{n+1}}{(n+1)!} \underset{n\to\infty}{\longrightarrow} 0 \left(\begin{array}{l}
        \text{ya vimos que }\frac{|x|^{n+1}}{(n+1)!} \underset{n\to\infty}{\longrightarrow} 0  \\
        \text{para cualquier } x \in \mathbb{R}
    \end{array}\right)
  \]
 \bl Entonces, $\lim_{n\to\infty}{R_{n,0}(x)=0} \; \forall x \in \mathbb{R}$ y por lo tanto vale $e^x=\sum_{n\to\infty}^{\infty}{\frac{x^n}{n!}} \quad \forall x \in \mathbb{R}$.

\end{ej}
\begin{ej}
  Dar la serie de Taylor de $f(x)=sen(x)$ alrededor de $a=0$ (Maclaurin) y probar que coincide con $sen(x)\quad \forall x \in \mathbb{R}$ \\\\
  \bl Para hallar la serie de Taylor debemos calcular $f^{(n)}(0) \; \forall n \geq 0$. Tenemos que \\ $$\begin{array}{rlrlrlrlr}
    f(x) & = & sen(x) & \longrightarrow & f(0) & = & sen(0) & = & 0 \\
    f'(x) & = & cos(x) & \longrightarrow & f'(0) & = & cos(0)& = & 1 \\
    f''(x) & = & -sen(x) & \longrightarrow & f''(0) & = & -sen(0)& = & 0 \\
    f'''(x) & = & -cos(x) & \longrightarrow & f'''(0) & = & -cos(0)& = & -1 \\
    f''''(x) & = & sen(x) & \longrightarrow & f''''(0) & = & sen(0)& = & 0 \\
  \end{array}$$ 
  y luego se va repitiendo lo anterior. En general, tenemos que \[ 
    f^{(2n)}(0)=0\quad \quad \text{ y } \quad \quad f^{(2n+1)}(0)=(-1)^n \quad \quad \forall n \geq 0.
    \] \bl Luego, la serie de Taylor de $sen(x)$ centrada en $a=0$ queda \[
    f(0)+f'(0)x+\frac{f''(0)}{2}x^2+\frac{f'''(0)}{3!}x^3 + \dots = x- \frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\dots=\sum_{n=0}^{\infty}{\frac{(-1)^n}{(2n+1)!}x^{2n+1}}.
  \] \\\\\\\\\\
  \bl Veamos ahora que la serie coincida con la funcion $\forall x \in \mathbb{R}$. \\\\
Como $f^{(n+1)}{(t)}=\pm sen(t) \text { o } \pm cos(t)$, en cualquier caso vale $|f^{(n+1)}{(t)}| \leq 1$. \\ \\
  Luego, \[ 
  0 \leq |R_{n,0}(x)|=\frac{|f^{(n+1)}(t)}{(n+1)!}|x|^{n+1}\leq \frac{|x|^{n+1}}{(n+1)!} \underset{n\to\infty}{\longrightarrow} 0. 
\]
\bl O sea, $\lim_{n\to\infty}{R_{n,0}(x)}=0 \quad \forall x \in \mathbb{R}$ y por lo tanto $sen(x)=\sum_{n=0}^{\infty}{\frac{(-1)^{n}x^{2n+1}}{(2n+1)!}}$. 
\end{ej}

\begin{ej}
  Estimar el error que se comete si se aproxima $sen(0.2)$ por el valor en $x=0.2$ de su polinomio de Taylor de orden $7$ centrado en $a=0$, o sea $T_{7,0}(0.2)$. \\ \\ 
  \bl Queremos estimar el valor de $|\sen(0.2)-T_{7,0}(0.2)|$. \\\\ Sabemos que $sen(x)=T_{7,0}{x}+R_{7,0}(x) \quad \forall x \in \mathbb{R} \quad \big(\text{Formula de Taylor}\big)$ \\\\ Por lo tanto $|sen(0.2)-T_{7,0}(0.2)|=|R_{7,0}(0.2)|$. \\ \\Ahora, $R_{7,0}(0.2)=\frac{sen^{(8)}(t)}{8!}(0.2)^8$ para algun $t \in \big(0,0.2\big)$. Como se cumple que $|sen^{(8)}(t)|\leq 1 \quad \forall t \in \mathbb{R}$, entonces \[ 
    |R_{7,0}(0.2)|=\frac{|sen^{(8)}(t)|}{8!}(0.2)^{(8)} \leq \frac{1}{8!}\left(\frac{2}{10}\right)^8 = \frac{1}{8!5^8}
\]
\bl \underline{Conclusion}: el error que se comete al aproximar $sen(0.2)$ por $T_{7,0}(0.2)$ es menor $\frac{1}{8!5^8} \approx 6.3\times10^{-11}$.
\end{ej}
\begin{ej}
  Estimar el error que se comete si se aproxima $sen(x)$ por $T_{7,0}(x)$ para cualquier $x \in \left(-\frac{1}{2},\frac{1}{2}\right)$. \\ \\
  \bl Queremos estimar $|sen(x)-T_{7,0}(x)|=|R_{7,0}(x)|$ para $x \in \left(-\frac{1}{2},\frac{1}{2}\right)$.
  \\\\
  Como $|R_{7,0}(x)|=\frac{|sen^{(8)}(t)||x|^8}{8!} \leq \frac{|x|^8}{8!} \leq \frac{1}{8!} \cdot\left(\frac{1}{2}\right)^8 = \frac{1}{8!2^8}$, entonces el error sera menor que $\frac{1}{8!2^8}$ para cualquier $x \in \left(-\frac{1}{2},\frac{1}{2}\right)$.
\end{ej}\pagebreak
\begin{ej}
  Encontrar los $x \in \mathbb{R}$ tq el polinomio de Taylor de orden $7$ centrado en $a=0$ de $f(x)=sen(x)$ aproxima a $sen(x)$ con un error menor que $10^-5$. \\\\
  \bl Buscamos hallar los $x \in \mathbb{R}$ tq $|sen(x)-T_{7,0}(x)|<10^-5$.\\\\
  Como $|sen(x)-T_{7,0}(x)|=|R_{7,0}(x)|$ basta hallar los $x \in \mathbb{R}$ tq $|R_{7,0}(x)| < 10^-5$. \\\\
  Ahora, \[
  |R_{7,0}(x)| \underbrace{=}_{\textcolor{azulp2}{\underset{\underset{t \in (x,0)}{\text{o}}}{t \in (0,x)}}} \frac{|sen^{(8)}(t)|}{8!} |x|^8 \leq \frac{1}{8!}|x|^8 \underbrace{\textless}_{\textcolor{rojop2}{?}} 10^{-5}
\]
Luego, basta tomar $x \in \mathbb{R}$ tq $|x|^8 < \frac{8!}{10^5}$. O sea, todos los $x \in \mathbb{R}$ tq $|x| < \left(\frac{8!}{10^5}\right)^{\frac{1}{8}}$ cumplen lo requerido.
\end{ej}
\begin{ej}
  Usando un polinomio de Taylor adecuado, hallar un valor aprox. de $\sqrt{e}$ con un error menor a $10^{-2}$. \\\\
  \bl Notemos que $\sqrt{e}=e^{\frac{1}{2}}$. Luego, elegimos $f(x)=e^x$ y $a=0$ $\left(\text{ya que es facil de calcular } f^{(n)}(0) \forall n\right)$.
 \\\\
 Sabemos que $f(x)=T_{n,0}(x)+R_{n,0}(x).$ \\\\
 \bl Lo que se nos pide es hallar $n$ tal que \[ 
\left|f\left(\frac{1}{2}\right)-T_{n,0}\left(\frac{1}{2}\right)\right|=\left|R_{n,0}\left(\frac{1}{2}\right)\right| < 10^{-2}.
\]Ahora, como $R_{n,0}\left(\frac{1}{2}\right)=\frac{e^t}{(n+1)!}\left(\frac{1}{2}\right)^{n+1}$, para algun $t \in \left(0,\frac{1}{2}\right)$ y $f(x)=e^x$ satisface que $e^t < e^{\frac{1}{2}} < e^{1}=2.7183\dots < 3$ para $t \in \left(0,\frac{1}{2}\right)$, tenemos \[\left|R_{n,0}\left(\frac{1}{2}\right)\right|<\frac{3}{(n+1)!}\cdot \left(\frac{1}{2}\right)^{n+1} \underbrace{\textless}_{\textcolor{rojop2}{?}} 10^-2 \quad \text{ o equivalentemente } \quad  3 \cdot 10^2 < 2^{n+1}(n+1)! \quad \quad (\textcolor{rojop2}{\star})
\] Probamos cual $n$ satisface $\textcolor{rojop2}{(\star)}$ \quad $\big(3 \cdot 10^2 = 300\big)$ \\\\
$\begin{array}{lllll}
  n=0 & \rightsquigarrow & 2 \cdot 1! & = 2 & \text{No \textcolor{rojop2}{$\times$}} \\
  n=1 & \rightsquigarrow & 4 \cdot 2! & = 8 & \text{No \textcolor{rojop2}{$\times$}} \\
    n=3 & \rightsquigarrow & 8 \cdot 3! & = 48 & \text{No \textcolor{rojop2}{$\times$}} \\
    n=4 & \rightsquigarrow & 16 \cdot 4! & = 384 & \text{Si \; \textcolor{verdep2}{\ok}}
  \end{array}$ \\ O sea, $T_{3,0}\left(\frac{1}{2}\right)$ aproxima a $\sqrt{e}$ con un error menor a $10^{-2}$.
\end{ej}

\section{Calculo Vectorial.}
  
\bl A continuacion vamos a introducir la nocion de vector en el plano $(n=2)$ y en el espacio $n=3$. 
\begin{defi}
  $R^n=\left\{A:=(a_1,a_2, \dots , a_n): a_i \in \mathbb{R} \; \forall i\right\}$. En $\mathbb{R}^n$ se definen dos operaciones: \\\\
  \bl suma: $$(a_1,a_2, \dots ,a_n)+(b_1,b_2, \dots ,b_n):=(a_1+b_1, a_2+b_2, \dots , a_n+b_n).$$ 
  \bl multiplicacion por escalares: para $r \in \mathbb{R}$, $$r \cdot (a_1, a_2, \dots, a_n) = (ra_1, ra_2, \dots, ra_n).$$ 
  Con estas operaciones, $R^n$ es un espacio vectorial sobre el cuerpo $\mathbb{R}$ y sus elementos se llaman vectores (o puntos).
\end{defi}

\begin{obs} \; \\
  (1) Denotamos por $-A=(-1)\cdot A$ y definimos la resta $B-A:=B+(-A)$. \\
  (2) A veces denotamos al vector nulo simplemente $0=(0,0, \dots, 0).$
\end{obs}

\begin{center}
  \textbf{Representacion grafica o geometrica de vectores en $\mathbb{R}^2 \text{ y } \mathbb{R}^3$.}
\end{center}
En $\R^2$
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v24.pdf_tex}
\end{figure}

Representaremos a los vectores como puntos o como flechas \underline{desde el origen} hasta el punto correspondiente. \begin{obs}
  Como vector, $A$ tiene direccion, sentido y longitud; mientras que $-A$ tiene igual direccion y longitud que $A$ pero sentido opuesto.
\end{obs}
\pagebreak
En $\R^3$
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v25.pdf_tex}
\end{figure}

\begin{center}
\textbf{Regla del paralelogramo.}
\end{center}

\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v26.pdf_tex}
\end{figure}

\pagebreak
\begin{obs}
  \;
\end{obs}
$w$ \underline{no} representa un punto del plano pero $v$ \underline{si}. Sin embargo, como vectores $v$ y $w$ coinciden.

\begin{figure}[h]
\centering
\def\svgwidth{0.45\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v27.pdf_tex}
\end{figure}
Como vectores $A-B$ y $(A-B)$ son equivalentes.
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v28.pdf_tex}
\end{figure}

\begin{defi}[Producto escalar o producto interno en $\R^n$] \; \\
  Dados $A,B \in \R^n$ con $A=(a_1, \dots, a_n)$ y $B=(b_1, \dots, b_n)$ el producto escalar entre $A$ y $B$ es el \underline{numero} \[ 
    \langle A,B \rangle := a_1 \cdot b_1 + a_2 \cdot b_2 + \dots + a_n b_n = \sum_{j=1}^{n}{a_jb_j}. 
  \]
\end{defi}

\begin{ej}
  Calcular el producto escalar entre $A=(1,-2,3)$ y $B=(5,\frac{1}{2},0)$. \\\\ Por definicion, $\langle A,B \rangle = 1\cdot 5 + (-2) \cdot \frac{1}{2} + 3 \cdot 0 = 5 - 1 + 0 = 4.$
\end{ej}

\begin{obs}
 \; \\
 A veces el producto escalar (interno) entre $A$ y $B$ se denota por $A \cdot B$. 
\end{obs}
\pagebreak 
\begin{teo}[Propiedades del producto interno]
  \;  \\
  Dados $A,B,C \in \mathbb{R}^n$ y $r \in \mathbb{R}$, las siguientes son validas: \\\\  $\begin{array}[t]{llcl}
    (1) & \langle A,B \rangle & = & \langle B,A \rangle \\ 
    (2) &  \langle A+B, C \rangle & = & \langle A,C \rangle + \langle B,C \rangle  \quad \text{y} \quad \langle A,B+C \rangle = \langle A,B \rangle + \langle A,C \rangle  \\
    (3) & r \langle A,B \rangle & = & \langle rA,B \rangle = \langle A, rB \rangle  \\
    (4) & \langle A,A \rangle  & \geq  & 0 \\
    (5) & \langle A,A \rangle & = & 0 \quad \Leftrightarrow \quad A=(0, \dots , 0).
      \end{array}$
    \end{teo}
\begin{demo}
  [Ejercicio!] Usar la def. de producto escalar y las propiedades de los numeros reales.
\end{demo}
\begin{defi}
  \; \\ Definimos la \underline{norma} de un vector $A=(a_1, \dots, a_n) \in \mathbb{R}^n$ como \[
    ||A|| =: \sqrt{a_1^2+a_2^2+\dots+a_n^2}=\sqrt{\langle A,A \rangle}.
  \]
\end{defi}
\begin{obs}
  \; \\
  Notar que si $n=1$, o sea en $\mathbb{R}$, $||A||=|A|$. 
\end{obs}
\bl Geometricamente en $\mathbb{R}^2 \text{ y } \mathbb{R}^3$, $||A||$ es la longitud del vector que representa a $A$. 

\underline{En $\mathbb{R}^2$}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v29.pdf_tex}
\end{figure}

\underline{En $\mathbb{R}^3$}
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v30.pdf_tex}
\end{figure}  \\\\
\bl Notar tambien que $||A||$ es la distancia del \underline{punto} $A$ al origen,  o sea $dist(A,0)=d(A,0)=||A||$. 

\begin{defi}
  \; \\
  Definimos la distancia entre dos vectores $A$ y $B$ en $\mathbb{R}^n$ como \[  
    d(A,B):=||A-B|| \quad \quad \quad \quad \left(\text{notar que }d(A,0)=||A||\right). \]
\end{defi}
\bl Geometricamente en $\mathbb{R}^2$ y $\mathbb{R}^3$, $||A-B||=\text{ longitud del vector }A-B$ \\
\phantom{\bl geometricamente a en $\mathbb{r}^2$ y $\mathbb{r}^3$, $||a-b||$}($=$ distancia entre el pto. $A$ y \\
\phantom{\bl geometricamente en $\mathbb{r}^2$ y $\mathbb{r}^3$, $||a-b||$} \quad \quad el pto. $B$)

\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v31.pdf_tex}
\end{figure}

\begin{ej}
  La distancia entre $A=(1,0,2)$ y $B=(1,3,-1)$ es \[ 
    d(A,B)=||A-B||=||(1,0,2)-(1,3,-1)||=||(0,-3,3)||\sqrt{0^2+(-3)^2+3^2}=\sqrt{18}.
  \]
\end{ej}

\begin{teo}[Propiedades de la norma de un vector]
  Sean $A,B \in \mathbb{R}^n$ y $r \in \mathbb{R}$. Entonces,\\\\ $\begin{array}{llcl}
    (1) & ||A|| \geq 0 \text{ y } ||A||=0 & \Leftrightarrow & A=(0,0,\dots,0) \\ \\
    (2) & ||rA|| & = &  |r|\; ||A|| \\\\
    (3) & ||A+B|| & \leq & ||A|| + ||B|| (\text{ desigualdad triangular}) \\\\
  (4) & \langle A,B \rangle & = & ||A||\; ||B|| \; cos(\theta), \quad  \text{donde } 0 \leq \theta \leq \pi \text{ es el}\\ & & & \quad \quad \quad \quad \text{angulo (radianes) entre A y B}.\\\\
  (5) & |\langle A,B \rangle| & \leq & ||A||\; ||B||,  \text{ desigualdad de Cauchy-Schwarz}
  \end{array}$
\end{teo}
\pagebreak 
\begin{obs} \; \\
  notemos que (4) es una consecuencia del Teo. del coseno 

\end{obs}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v32.pdf_tex}
\end{figure}

Veamos como obtenemos (4).

\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v33.pdf_tex}
\end{figure}

Igualando \textcolor{azulp2}{(1)} y \textcolor{azulp2}{(2)} obtenemos 
\[
  \langle A,B \rangle = ||A|| \; ||B|| \; cos(\theta). \quad \textcolor{verdep2}{\ok}
\] 

\begin{defi}
  dados $A,B \in \mathbb{R}^n$ con $A \neq 0$ y $B \neq 0$ decimos que $A$ y $B$ \\\\
  \emph{(i\phantom{i})} \quad Son \underline{ortogonales} (o perpendiculares) si $\langle A,B \rangle = 0$ \\
  \emph{(ii)} \quad Son \underline{paralelos} si $A=rB$ para algun $r \in \mathbb{R}$.
\end{defi}
\begin{obs}
  en $\mathbb{R}^2$ y $\mathbb{R}^3$ la definicion anterior coincide con la usual: \\\\
  \bl si $A$ y $B$ son perpendiculares, entonces el angulo entre ellos es $\frac{\pi}{2}$. Luego, como $cos(\frac{\pi}{2})=0$ por (4) del teorema anterior tenemos que $\langle A,B \rangle = 0$. \\\\ 
  \bl si son paralelos, trasladandolos para que comiencen en el origen, tenemos que estan en una misma recta, o sea uno es multiplo del otro.
\end{obs}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v34.pdf_tex}
\end{figure}

\pagebreak

\begin{center}
  \textbf{Rectas en $\mathbb{R}^2$ y $\mathbb{R}^3$.}
\end{center}
Supongamos $n=2$ o $3$. Sean $P_0 \in \mathbb{R}^n$ y $V \in \mathbb{R}^n$ con $v \neq 0$. \\ \\
\bl Los puntos $tv$, con $t \in \mathbb{R}$, describen la recta $l_1$ que tiene direccion $v$ y pasa por el origen. \\\\
\bl Los puntos $P_0 + tv,$ con $t \in \mathbb{R}$, describen la rectga $l_2$ que tiene direccion $v$ y que pasa por $P_0$.

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v35.pdf_tex}
\end{figure}

(En $\mathbb{R}^3$ el grafico es similar)

\begin{defi}
  Dados $P_0 \in \mathbb{R}^n$ y $v \in \mathbb{R}^n$ con $v \neq 0$, la recta $l$ que pasa por el punto $P_0$ y tiene direccion $v$ es el conjunto de todos los puntos $\mathbf{x}=(x,y)$  $\big(\text{o } \mathbf{x}=(x,y,z) \in \mathbb{R}^3\big)$ tales que \[
    \mathbf{x} = P_0 + tv, \quad \quad \text{con } t \in \mathbb{R} \quad \quad \textcolor{verdep2}{\rightarrow \text{ Ecuacion vectorial de la recta}}
  \]
  O sea, \[\begin{array}{l}
    l = \{\mathbf{x} \in \mathbb{R}^2 : \mathbf{x} = P_0 + tv, \text{ con } t \in \mathbb{R} \} \quad \big(\text{si $n=2, \; \mathbf{x}=(x,y)$}\big) \\ 
    l = \{ \mathbf{x} \in \mathbb{R}^3 : \mathbf{x} = P_0 + tv, \text{ con } t \in \mathbb{R}\} \quad \big($\text{si $n=3, \; \mathbf{x}=(x,y,z)$}$\big)
    \end{array} \]
\end{defi}
\pagebreak
\begin{ej}
  Dar la ecuacion vectorial de la recta $l$ que pasa por $P_0 =(1,1,3)$ y tiene direccion $v=(0,1,1)$. \\\\ 
  \bl La ecuacion vectorial es \[ 
    \mathbf{x}=(1,1,3)+t(0,1,1), \text{ con } t \in \mathbb{R}
  \]
\end{ej}
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v36.pdf_tex}
\end{figure}

¿Pertenecen los puntos $P_1 = (0,0,2)$ y $P_2 = (1,-1,1)$ a la recta $l$?  \\

\bl Sabemos que $P=(x_0,y_0,z_0) \in l$ si existe $t$ tq $P=P_0 + tv$, es decir si existe $t \in \mathbb{R}$ tq \quad $(x_0,y_0,z_0)$\;$=(1,1,3)+t \; (0,1,1)$\\
\phantom{$t \in \mathbb{R}$ tq \quad $(x_0,y_0,z_0)$}\;$= (1,\; 1+t,\; 3+t)$ \\
Por lo tanto, $P_1=(0,0,2) \in l$ si existe $t \in \mathbb{R}$ tq  \\\\$
  \quad \quad \begin{array}{llc}
  \quad \quad \phantom{-} 0 =1  & \to & \text{esta ecuacion es una contradiccion y por lo}\\
  \quad \quad \phantom{-} 0 = 1 + t & & \text{tanto $P_1=(0,0,2)$ no pertenece a la recta $l$}.\\ 
 \quad \quad \phantom{-}2 = t+3
    \end{array}
$ \\\\
\bl Para ver si $P_2=(1,-1,1) \in l $ debemos ver si existe $t \in \mathbb{R}$ tq \\\\
$\begin{array}{llc}
 \quad \quad \phantom{-}1 = 1 & & \\
 \quad \quad   -1 = 1+t & \to & t=-2 \quad \textcolor{verdep2}{\ok} \\
  \quad \quad  \phantom{-}1 = 3+t & \to & t=-2 \quad \textcolor{verdep2}{\ok} \\
\end{array}$. Luego, $P_2 \in l$.
\pagebreak
\begin{defi}
  Decimos que dos rectas son paralelas si sus vectores direccion son paralelos y decimos que son ortogonales (o perpendiculares) si sus vectores direccion son ortogonales. 
\end{defi}

\begin{ej}
  \; \\
  (1) \quad \bl Las rectas  $\begin{array}{ll}
   &  \mathbf{x}=(0,1,3)+t(1,-3,0), \text{ con } t \in \mathbb{R} \\
    y & \mathbf{x}=t(-2,6,0), \text{ con } t \in \mathbb{R}
  \end{array}$\\\\ son paralelas ya que $v_1= (1,-3,0)$ y $v_2=(-2,6,0)$ son paralelos. \\\\\\
  (2) \quad \bl Las rectas $\begin{array}{ll}
   &  \mathbf{x}=(2,\pi,0)+t(1,0,0), \text{ con } t \in \mathbb{R} \\
    y & \mathbf{x}=(3,\pi,0)+t(0,2,100), \text{ con } t \in \mathbb{R}
  \end{array}$ \\ \\  son perpendiculares ya que sus vectores direccion son ortogonales. \\\\ En efecto, $\langle(1,0,0),(0,2,100) \rangle = 1 \cdot 0 + 0 \cdot 2 + 0 \cdot 100 = 0. $
\end{ej}
\; \\
\underline{\textbf{Ejercicio}}: ver que las rectas se cortan en el punto $(3,\pi,0)$.
\\\\\\
\bl Sabemos por los axiomas de la geometria euclidiana que dados dos puntos $P_0$ y $P_1$ en $\mathbb{R}^2$ (o $\R^3$), existe una unica recta que pasa por ellos. \\\\Para dar la ecuacion de esta recta, necesitamos un vector paralelo a ella. Este vector puede ser $P_1-P_0$ (o $P_0-P_1$). 
\begin{defi}
  dados $P_0,P_1 \in \R^2$ (o $R^3$) la ecuacion vectoriales de la recta que pasa por $P_0$ y $P_1$ es \[
    \mathbf{x}=P_0+t(P_1-P_0) \text{, con } t \in \mathbb{R}.
  \]
\end{defi}
\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v37.pdf_tex}
\end{figure}

\begin{obs}
  definiciones equivalentes son \[
    \mathbf{x} = P_1+t(P_1-P_0) \quad \text{o} \quad \mathbf{x}=P_0+t(P_0-P_1) \quad \text{o} \quad \mathbf{x}=P_1+t(P_0-P_1).
  \]
\end{obs}
\begin{ej}
  dar la ecuacion vectorial de la recta que pasa por los puntos $(1,2,3)$ y $(3,2,1)$. \\ \\ 
  La ecuacion es \quad $\mathbf{x}=(1,2,3)+t(2,0,-2)$. \\\\
  Otras formas de dar la ecuacion de una recta 
\end{ej}

\begin{center}
\textbf{Otras formas de dar la ecuacion de una recta.}
\end{center}
\bl Supongamos $n=2$. Sea $P_0 = (x_0,y_0)$ y $v=(v_1,v_2) \neq (0,0)$. \\\\ La ecuacion vectorial de la recta que pasa por $P_0$ y tiene direccion $v$ es \[ \begin{array}{rcl}
  \mathbf{x}& = & P_0+tv \quad \quad \quad \text{o equivalentemente} \\ 
  (x,y) & = & (x_0,y_0) + t(v_1,v_2).
\end{array}
\] 
Igualando coordenada a coordenada tenemos \[ 
  \textcolor{verdep2}{(EP)} \left\{\begin{array}{l}
x = x_0+tv_1 \\
y=y_0+tv_2
\end{array}\right. \textcolor{verdep2}{\to \text{ Ecuacion parametrica.}}
\] 
\bl Supongamos que $v_1 \neq 0$. Despejando $t$ en la primera ecuacion de $(EP)$ y reemplazando en la segunda obtenemos \[
t=\frac{x-x_0}{v_1},\;  \text{ y luego }\; y = y_0 + \frac{(x-x_0)}{v_1} v_2 = \textcolor{rojop2}{\underbrace{\textcolor{black}{\frac{v_2}{v_1}}}_{a}} x + \textcolor{rojop2}{\underbrace{\textcolor{black}{\left (y_0 - \frac{v_2}{v_1} x_0 \right )}}_{b}}
\]
Luego, $y=ax+b$ \textcolor{verdep2}{$\to$ \text{ecuacion en forma explicita de la recta}}. \\\\ \phantom{Luego,} $y-ax+b=0$ \textcolor{verdep2}{$\to$ \text{ecuacion en forma implicita de la recta.}}


\begin{ej}
  Dar la forma explicita de la recta que pasa por $P_0=(1,2)$ y $P_1=(3,1)$. \\\\ 
  \bl Sabemos que la ec. vectorial de la recta que pasa por $P_0$ y $P_1$ es $\mathbf{x}=P_0+t(P_1-P_0)$. \\ \\ Luego, $\mathbf{x}=(1,2)+t(2,-1)$, con $t \in \mathbb{R}$. \\\\
Entonces tenemos que la recta pasa por $P_0=(1,2)$ y tiene direccion $v=(2,-1)$. \\\\ Por lo tanto tenemos que \[
  \begin{array}{l}
    a=\frac{v_2}{v_1}=-\frac{1}{2} \\
    b=2-\left(-\frac{1}{2}\right)\cdot 1 = \frac{5}{2}
  \end{array}\] Finalmente, la ecuacion explicita de la recta es $y = -\frac{1}{2} x + 5$.
\end{ej}
\begin{center}
\textbf{Ecuacion de la recta en $\R^3$.}
\end{center}
Dados $P_0=(x_0,y_0,z_0)$ y $v=(v_1,v_2,v_3)$ tenemos que \\\\ 
$\begin{array}{llll}
  $\bl$ &  \; \mathbf{x}= P_0+tv, & \text{con } t \in \mathbb{R} & \to \text{ ecuacion vectorial} \\ \\
  $\bl$ & \begin{array}{l}
x = x_0 + tv_1 \\
y=y_0 + tv_2 \\
z=z_0 + tv_3
  \end{array}, & \text{ con } t \in \mathbb{R} & \to \text{ecuacion parametrica} \\ \\
 \end{array}$ \\ \\ 
 $\begin{array}{lll}
  $\bl$ & \; \text{No hay ecuacion explicita e implicita.} & 
 \end{array}$

\begin{center}
\textbf{Planos en $\R^3$.}
\end{center}
Sean $v$ y $w$ dos vectores no nulos y no paralelos en $\mathbb{R}^3$. \\\\
\bl Si consideramos todos los multiplos de $v$ $\big(tv \text{ con } t \in \mathbb{R}\big)$ obtenemos la recta $l_1$ que tiene direccion $v$ y pasa por el origen. \\\\
\bl Si consideramos todos los multiplos de $w$ $\big(tw \text{ con } t \in \mathbb{R}\big)$ obtenemos la recta $l_2$ que tiene direccion $w$ y pasa por el origen. 

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v38.pdf_tex}
\end{figure}
\pagebreak
\bl Si sumamos cada punto de $l_1$ con un punto de $l_2$ vamos a obtener un plano que esta generado por $v$ y $w$ y pasa por el origen $\left[\text{Por ejemplo, }\mathbb{R}^2=\left\{t\overset{\textcolor{rojop2}{v}}{(1,0,0)}+r\overset{\textcolor{verdep2}{w}}{(0,1,1)}\; : \; t,r \in \mathbb{R}\right\}\right]$.
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v39.pdf_tex}
\end{figure}
\\
\bl Si a este plano le sumamos un punto fijo $P$, obtenemos un plano paralelo y que pasa por $P$.
\begin{defi}
  Dados, $v,w \in \mathbb{R}^3$ con $v \neq 0 \neq w$ y $v \neq sw $ $\forall s \in \mathbb{R}$ y dado $P \in \mathbb{R}^3$, decimos que \[ 
    \mathbf{x}=P+tv+rw, \text{ \quad con \; } t,r \in \mathbb{R} 
  \] es la ecuacion vectorial del plano generada por $v$ y $w$ que pasa por el punto $P$.
\end{defi}

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v40.pdf_tex}
\end{figure}
\begin{ej}
  Dar la ecuacion vectorial del plano que pasa por $(1,2,4)$ y esta generado por $(1,2,2)$ y $(2,5,0)$ . \\ \\ 
  \bl La ecuacion del plano es \[ 
    \mathbf{x}=(1,2,4)+t(1,2,2)+r(2,5,0) \text{ con } t, r \in \mathbb{R}.
    \] \bl ¿El punto $P_0=(0,1,0)$ pertenece al plano? \\\\ $P_0$ esta en el plano si existen $t$ y $r$ en $\mathbb{R}$ tal que $$(0,1,0)=(1+t+2r,\; 2+2t+5r, \;4+2t)$$ es decir, \[
    \begin{array}{lll}
      1+t+2r=0 & & \longrightarrow 1-2+\frac{6}{5} = 0 \text{ absurdo !}\\
2+2t+5r =1 & \quad \quad \quad \quad \quad \longrightarrow 2-4+5r=1 \; \therefore r = \frac{3}{5} &  \\
4+2t = 0 & \to t = -2 & 
    \end{array}
  \] \underline{Conclusion}: $P_0$ \underline{no} pertenece al plano ya que no existen $t$ y $r$ en $\mathbb{R}$ tal que $P_0=(1+t+2r, 2+2t+5r,4+2t)$
\end{ej}
\; \\ \\ 
\textcolor{rojop2}{\bl} Por geometria euclideana sabemos que un plano queda determinado por algun de las siguientes posibilidades: \\\\
\textcolor{rojop2}{(1)} Tres puntos no colineales. \\\\
\textcolor{rojop2}{(2)} Una recta y un punto fuera de ella. \\\\ 
\textcolor{rojop2}{(3)} Dos rectas paralelsa (distintas). \\\\

\textcolor{rojop2}{\bl} ¿Como determinar la ecuacion del plano en los casos \textcolor{rojop2}{(1)}, \textcolor{rojop2}{(2)} y \textcolor{rojop2}{(3)}? 
\\\\
\textcolor{rojop2}{(1)} Sean $P$, $Q$ y $R$ tres puntos no colineales \big(no son paralelos\big).\\ 
\\ Luego, $P-Q$ y $R-Q$ son dos vectores no nulos y no parlelos que generan el plano.\\\\\\\\\\\\\\\; \\\\
Entonces, el plano que contiene a $P$, $Q$ y $R$  es el plano que pasa por $P$ y esta generado por $P-Q$ y $R-Q$, o sea \[
  \mathbf{x}=P+t(P-Q)+r(R-Q), \text{ con } t, r \in \mathbb{R}.
\] \;
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v41.pdf_tex}
\end{figure}

\begin{ej}
  Dar la ecuacion vectorial del plano que psa por los puntos $\textcolor{rojop2}{\underbrace{\textcolor{black}{(0,1,0)}}_{\text{P}}}$, $\textcolor{rojop2}{\underbrace{\textcolor{black}{(1,2,1)}}_{\text{Q}}}$ y $\textcolor{rojop2}{\underbrace{\textcolor{black}{(-1,2,3)}}_{\text{R}}}$. \\\\ 
  \bl Tenemos que \[ 
    P-Q = (-1,-1,-1) \quad \text{y} \quad R-Q=(-2,0,2)
  \] por lo tanto la ecuacion es $$\mathbf{x}=(0,1,0)+t(-1,-1,-1)+r(-2,0,-2), \quad \text{ con } \; t, r \in \mathbb{R}.$$
\end{ej}
\pagebreak
\textcolor{rojop2}{(2)} Si tenemos una recta $l$ y un punto $P$ fuera de ella, entonces sligiendo dos puntos $Q$ y $R$ en la recta tenemos tres puntos no colineales y aplicamos \textcolor{rojop2}{(1)}. \\\\
\textcolor{rojop2}{(3)} Si tenemos dos rectas paralelas nos basta elegir dos puntos $P$ y $Q$ sobre un de las rectas y un punto $R$ sobre la otra y luego procedemos como el caso \textcolor{rojop2}{(1)} para encontrar la ecuacion determinaa por las dos rectas

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v42.pdf_tex}
\end{figure}
\;
\pagebreak \textcolor{rojop2}{\bl} Notemos que un plano tambien queda determinado si damos un vector $N$ perpendicular a dicho plano y un punto $P_0$ por el que pasa. \\\\ Si la ecuacion del plano es \[
  \mathbf{x}=P_0+tv+rw
\] entonces $\mathbf{x}-P_0$ es perpendicular a $N$ o sea, $\langle \mathbf{x}-P_0 , N \rangle = 0$

\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v43.pdf_tex}
\end{figure} 
\begin{defi}
  \; \\
  El plano normal a $N$ y que pasa por $P_0$ es el conjunto de puntos $\mathbf{x} \in \mathbb{R}^3$ tq $\mathbf{x}-P_0$ es perpendicular a $N$, es decir \[
    \langle \mathbf{x} - P_0, N\rangle = 0  \quad \quad \textcolor{verdep2}{\to} \quad \quad \text{\textcolor{verdep2}{ecuacion normal del plano.}}
  \]
\end{defi}
\begin{obs}
  Sean $\mathbf{x}=(x,y,z), P_0=(x_0,y_0,z_0)$ y $N=(a,b,c)$, entonces la ecuacion normal del plano queda \[
    \begin{array}{lllll}
  & \langle (x,y,z) - (x_0,y_0,z_0), (a,b,c) \rangle  & = 0 \quad \Leftrightarrow \quad & \langle (x-x_0,y-y_0,z-z_0), (a,b,c) \rangle &  = 0  \\
      \Leftrightarrow & (x-x_0)a+(y-y_0)b+(z-z_0)c & = 0  \quad \Leftrightarrow \quad & ax+bx+cz=\underbrace{ax_0+bx_0+cz_0}_{:= \;  d \text{ (dato)}} .
\end{array}\]
Es decir, \[ 
  ax+by+cz = d \quad \quad \textcolor{verdep2}{\to} \quad \quad \text{\textcolor{verdep2}{ecuacion cartesiana del plano.}}
\]
\end{obs}

\begin{ej}
  Dar la ecuacion normal y cartesiana del plano normal a \\ $N=(3,2,1)$ y que pasa por $(2,-1,1)$. \\\\ \bl La ecuacion normal del plano es: $ \langle (x,y,z)-(2,-1,1),(3,2,1) \rangle = 0 $. \\ \\ 
  \bl La ecuacion cartesiana del plano es: $3x+2y+z=d$ para un ``cierto'' $d \in \mathbb{R}$.
  \\\\
  ¿Como hallar $d$? $\to$ reemplazamos $(x,y,z)$ por $(2,-1,1)$ o sea \[ 
  d=3\cdot 2 + 2 \cdot (-1) + 1 = 6 - 2 + 1 = 5 \quad \text{(lo que hicimos fue calcular } ax_0+by_0+cz_0 \text{)}
  \] La ecuacion cartesiana es: $3x+2y+z=5$.
  \\\\ \textcolor{rojop2}{\bl} ¿Los puntos $(0,0,2)$ y $(0,0,5)$ pertenecen al plano? \\\\ Veamos si satisfacen la ecuacion caratesiana.\\\\ $\begin{array}{llll}
    \bullet \quad 3 \cdot 0 + 2 \cdot 0 + 2 = 5 \quad \text{\textcolor{rojop2}{x} absurdo!} \quad \quad \text{Por lo tanto } (0,0,2) \text{ \underline{no}  esta en el plano.} \\     \bullet \quad 3 \cdot 0 + 2 \cdot 0 + 5 = 5 \quad \text{\textcolor{verdep2}{\ok}\phantom{absurdo!}} \quad \quad \text{Por lo tanto } (0,0,5) \text{ \underline{si}  esta en el plano.}
 \end{array}$
\end{ej}

\begin{defi}
  Dados dos vectores $V=(v_1,v_2,v_3)$ y $W=(w_1,w_2,w_3)$ definimos el producto vectorial $V \times W $ como \[
  V \times W = (v_2w_3-w_2v_3,\; w_1v_3-v_1w_3, \; v_1w_2-w_1v_2).
  \]
\end{defi}
\begin{obs} \; \\ Para calcular cada coordenada de $V \times W$ calculo el determinante de la matriz con las columnas en rojo eliminadas\\
  $$\underbrace{\left(\begin{array}{lll}
      \textcolor{rojop2}{v_1} & v_2 & v_3 \\ 
      \textcolor{rojop2}{w_1} & w_2 & w_3 
\end{array}\right)}_{det}
  -
  \underbrace{\left(\begin{array}{lll} 
      v_1 & \textcolor{rojop2}{v_2} & v_3 \\ 
      w_1 & \textcolor{rojop2}{w_2} & w_3 
\end{array}\right)}_{det}
  +
  \underbrace{\left(\begin{array}{lll}
      v_1 & v_2 & \textcolor{rojop2}{v_3} \\ 
        w_1 & w_2 & \textcolor{rojop2}{w_3} 
  \end{array}\right)}_{det}$$
\end{obs}

El vector $V$ $\times$ $W$ es perpendicular a $V$ y $W$ y por lo tanto el plano generado por $V$ y $W$. \big(Siempre que $V$ y $W$ sean ambos no nulos y no paralelos. \\ Si $V=0$ o $W=0$ o $V$ y $W$ paralelos, entonces $V \times W = (0,0,0)$ \quad Ejercicio! \big)
\\\\
\textcolor{rojop2}{\bl} ¿Como pasar de la ecuacion vectorial del plano a la ecuacion normal del plano? \\\\
La ecucion vectorial del plano que pasa por $P$ y esta generado por $V$ y $W$ es \[
  \mathbf{x}=P+tw+rv,\quad \quad \text{con}\quad t,r \in \mathbb{R}. 
\]
Como el vector $V \times W$ es ortogonal a $V$ y $W$ $\left(\begin{array}{l}
  \therefore \text{ a su suma } \\ 
  \text{ y cualquier } \\ 
  \text{ comb. lineal}
  \end{array}\right)$ entonces \[ 
  \langle \mathbf{x}-P, V \times W \rangle = 0 \quad \text{ es la ecuacion normal del plano.}
\]
\begin{ej}
  Dar la ecuacion normal y cartesiana del plano $\mathbf{x}=(2,1,0)+t(1,1,2)+r(0,2,3)$. \\\\ \bl Definimos $$N=(1,1,2) \times (0,2,3) = (3-4,-3,2)=(-1,-3,2)$$ Luego, la ecuacion normal es \[
\langle (x,y,z)-(2,1,0), \; (-1,-3,2)\rangle = 0.
  \]
\end{ej}
\begin{obs}
  Recordar que para calcular $N$ hicimos \[
\underbrace{\left(\begin{array}{lll}
      \textcolor{rojop2}{1} & 1 & 2 \\ 
      \textcolor{rojop2}{0} & 2 & 3 
\end{array}\right)}_{det}
  -
  \underbrace{\left(\begin{array}{lll} 
      1 & \textcolor{rojop2}{1} & 2 \\ 
      0 & \textcolor{rojop2}{2} & 3 
\end{array}\right)}_{det}
  +
  \underbrace{\left(\begin{array}{lll}
      1 & 1 & \textcolor{rojop2}{2} \\ 
      0 & 2 & \textcolor{rojop2}{3} 
  \end{array}\right)}_{det}.
  \]
\end{obs}\;
\\ \\ \bl Par la cartesiana sabemos que es $-x-3y+2z=d$, donde $d$ se obtiene al reemplazar $(x,y,z)=(2,1,0)$, es decir 
\[ 
  \underbrace{-2-3\cdot 1 + 2\cdot 0 }_{-5}=d.
\] Luego, la ecuacion cartesiana es $-x-3y+2z = -5$.
\\\\\\\\
\textcolor{rojop2}{\bl} ¿Como pasar de la ecuacion normal del plano a la ecuacion vectorial? \\\\ \bl Basta encontrar tres puntos $P$, $Q$ y $R$ no colineales (y estamos en \textcolor{rojop2}{(1)} de antes). \\\\ Luego, definimos $V=P-Q$ y $W=R-Q$. Asi la ecuacion vectorial queda \[
  \mathbf{x}=P+t(P-Q)+r(R-Q),\quad \quad \text{con} \quad t,r \in \mathbb{R}.
\]
\begin{defi}
 Decimos que $\alpha$ es el angulo entre dos planos si $\alpha$ es el angulo entre sus vectores normales (o perpendiculares).
\end{defi}
\begin{ej}
  Obtener el coseno del angulo entre los planos $x+y+z=0$ y $x+2y+3z=1$. \\\\ Tenemos que $N_1=(1,1,1)$ y $N_2=(1,2,3)$. \\\\ Luego, \[ 
    \langle N_1,N_2 \rangle = 1+2+3=6= ||N_1|| \; ||N_2|| \; \underbrace{cos(N_1,N_2)}_{\textcolor{rojop2}{\underset{N_1 \text{ y } N_2}{\text{coseno del angulo entre}}}}
    \]  Como, $||N_1||=\sqrt{3}$ y $||N_2||=\sqrt{14}$, tenemos que \[ 
    cos(N_1,N_2)=\frac{6}{\sqrt{3}\sqrt{14}}.
  \]
\end{ej} \pagebreak
\underline{Vista en $\mathbb{R}^3$} 

\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v44.pdf_tex}
\end{figure}

\underline{Proyeccion en $\mathbb{R}^2$}

\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v45.pdf_tex}
\end{figure}
Notemos que segun el sentido de $N_1$ y $N_2$ se obtendra alguno de los $2$ angulos suplementarios $\textcolor{verdep2}{\alpha}$ o $\textcolor{rojop2}{\tilde{\alpha}}$ \big($\pi = \alpha + \tilde{\alpha}$\big).
\\\\ \textcolor{rojop2}{\bl} Por convencion vamos a considerar el menor de estos y el cual satisface \\
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v46.pdf_tex}
\end{figure} \\
\bl Recordar que $cos(x)=-cos(x+\pi)$, luego como $\tilde{\alpha}=\pi-\alpha=\pi+(-\alpha)$ \\ $cos(\tilde{\alpha})=cos\big(\pi+(-\alpha)\big)=-cos(-\alpha)=-cos(\alpha)$. 
\pagebreak
\begin{center}
\textbf{Funciones vectoriales.}
\end{center}
\begin{defi}
  Dadas $f_i : \mathbb{R} \to \mathbb{R}, i=1,\dots, n$.\\Llamamos funcion vectorial a la funcion $f: \mathbb{R} \to \mathbb{R}^n$ dada por $$f(t) := \big(f_1(t),\dots, f_n(t)\big).$$ Los $f_i$ se llaman funciones coordenadas de $f$. \\\\ El dominio de $f$ es\quad \quad  $    Dom(f) := \bigcap_{i=1}^{n} Dom(f_i)$.
\end{defi}
\begin{ej}
\; \\
\\ \bl Si $f(t)=(\textcolor{rojop2}{\underbrace{\textcolor{black}{t+2}}_{f_1(t)}},\textcolor{verdep2}{\underbrace{\textcolor{black}{t^3}}_{f_2(t)}})$, entonces como $Dom(f_1)=\mathbb{R}=Dom(f_2)$ \\ \\ Luego \quad $Dom(f)=\mathbb{R}$. \\\\
\bl Si $f(t)=\left(\sqrt{t},\frac{1}{t},sen(t)\right)$. Tenemos que $\begin{array}{l}Dom(f_1)=[0,\infty) \\ Dom(f_2)=\mathbb{R}-\{0\}\\ Dom(f_3)=\mathbb{R}\end{array}$.\\\\ Luego $Dom(f)=(0,\infty)$.

\end{ej}
\begin{defi}
  Si $f: \mathbb{R} \to \mathbb{R}^n$ es una funcion vectorial, la imagen de $f$ es el conjunto de $\mathbb{R}^n$ definido por \[ 
    Im(f) := \big\{ (y_1, \dots , y_n) \in \mathbb{R}^n : \exists t \in Dom(f)  \text{ con } f(t)=y_1, \dots, y_n)  \big\}.
    \]
    \phantom{)}\textcolor{verdep2}{\bl} Cuando $n=2$, decimos que la imagen de $f$ es una curva en el plano.\\\\
    \phantom{)}\textcolor{verdep2}{\bl} Cuando $n=3$, decimos que la imagen de $f$ es una curva en el espacio.


\end{defi}
\begin{ej}
 De el dominio e imagen de las sigueintes funciones vectoriales. \\\\ \textcolor{verdep2}{(1)} $f(t)=(t,2-t,3+2t)$. \\\\
 \bl Como $Dom(f_1)=Dom(f_2)=Dom(f_3)=\mathbb{R}$, entonces $Dom(f)=\mathbb{R}$. \\\\ 
 \bl $Im(f)$ es la recta en el espacio y es paralela al vector $(1,-1,2)$ ya que \\\\ 
 \phantom{\bl} $f(t)=(t,2-t,3+2t)=(0,2,3)+t(1,-1,2)$ \\\\
 \phantom{\bl} $Im(f)=\big\{(y_1,y_2,y_3) \in \mathbb{R}^3 : (y_1,y_2,y_3)=(0,2,3)+t(1,-1,2) \text{ con } t \in \mathbb{R}\big\}$.
 \\\\\\
\bl \textcolor{verdep2}{(2)} $g(t)=\big(cos(t), sen(t)\big)$. Tenemos que $g_1(t)=cos(t)$ y $g_2(t)=sen(t)$.\\\\ 
\bl Como $Dom(g_1)=Dom(g_2)=\mathbb{R}$, entonces $Dom(g)=\mathbb{R}$. \\\\
\bl La imagen de $g$ esta contenida en el circulo de radio $1$ y centro $0$ pues \\\\ \phantom{\bl}$cos(t)^2+sen(t)^2=1 \quad \forall t \in \mathbb{R}$. De hecho, la imagen es exactamente ese circulo. \\\\\phantom{\bl}O sea, $Im(f)=\big\{(y_1,y_2) \in \mathbb{R}^2 : y_1^2 + y_2^2 = 1\big\}$.
\end{ej}

\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v47.pdf_tex}
\end{figure}
\; \\\\ \bl \textcolor{verdep2}{(3)} $h(t)=\big(sen(t),cos(t)\big)$ \\ \\ 
\bl $Dom(h)=\mathbb{R}$ \\\\
\bl $Dom(h)=Im(g) \leadsto $ pero el circulo unidad se recorre en sentido contrario
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v48.pdf_tex}
\end{figure} \; \pagebreak
\; \\\\ \bl \textcolor{verdep2}{(3')} $r(t)=\big(cos(t),sen(t),2\big)$\\\\ \bl 
Como $Dom(r_1)=Dom(r_2)=Dom(R_3)=\mathbb{R}$, entonces $Dom (r)=\mathbb{R}$. \\\\ 
La imagen de $r$ es el circulo de radio $1$ y centro $0$ en el plano $(y_1,y_2)$ y con altura $y_3=2$. O sea \[ 
  Im(f)=\big\{(y_1,y_2,y_3)\in \mathbb{R}^3 : y_1^2+y_2^2+1 \land y_3=2\big\}
\] 
\begin{figure}[h]
\centering
\def\svgwidth{0.25\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v49.pdf_tex}
\end{figure}
\; \\\\ 
\bl \textcolor{verdep2}{(4)} $r(t)=\big(cos(t),sen(t),t\big)$\\\\ \bl  Como $Dom(h_1)=Dom(h_2)=Dom(h_3)$, entonces $Dom(h)=\mathbb{R}$. \\
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v50.pdf_tex}
\end{figure}\\
\bl La imagen de $h$ es una ``helice'' en el espacio. \\ \\ \phantom{\bl} ``Es una curva que se enrosca en el cilindro de radio 1''. \[
  Im(h)=\big\{(y_1,y_2,y_3) \in \mathbb{R}^3 : (y_1,y_2,y_3) = \big(cos(t),sen(t),t\big) \text{ con } t \in \mathbb{R}\big\}
  \]
  \; 
  \pagebreak \begin{defi}
  Dados $a \in \mathbb{R}$ y $f : \mathbb{R} \to \mathbb{R}^n$ una funcion vectorial, definimos el limite de $f$ cuando $t \to a $ como \[ 
  \lim_{t \to a}{f(t)} := \left( \lim_{t \to a}{f_1(t)}, \dots , \lim_{t \to a }{f_n(t)} \right) \]
  siempre que los limites $\lim_{t \to a}{f_i(t)}$ existan $\forall i = 1, \dots ,n$. 
  \\\\
Si $a \in Dom(f)$, decimos que $f$ es continua en $t=a$ si $\lim_{t \to a}{f(t) = f(a)}$.
\\ \\
O sea, $f$ es continua en $a$ $\Leftrightarrow$ $f_i$ es continua en $a$ $\forall i = 1, \dots , n$.
  \end{defi}
\begin{ej} \; \\
  \textcolor{verdep2}{(1)} Sea $f(t)=\big(3,sen^2(t),2t+1\big).$ \\ \\ Tenemos que \[ 
    \begin{aligned}
      \lim_{t\to 0}{f(t)}=\lim_{t \to 0}{\big(3,sen^2(t),2t+1\big)} &=\left(\lim_{t \to 0}{3},\lim_{t \to 0}{sen^2(t)},\lim_{t \to 0}{2t+1}\right) \\ 
                          &= (3,0,1)=f(0)
    \end{aligned}
  \]Luego, $\lim_{t \to 0}{f(t)=f(0)} \quad \therefore f$ es continua en $t=0$ (ver que es continua en $\mathbb{R}$).\\\\
  \textcolor{verdep2}{(2)} Sea $f(t)=\left(\frac{1}{t-1},\sqrt{t}\right)$. \\ \\ \bl $\lim_{t \to 1}{f(t)}=\lim_{t \to 1}{\left(\frac{1}{t-1},\sqrt{t}\right)}$ no existe pues $\lim_{t \to 1}{\frac{1}{t-1}}$ no existe. \\ \\ 
  \bl $f$ es continua en todo su dominio, es decir $f$ es continua en \[ 
    \{t \in \mathbb{R} : t \geq 0 \land t \neq 1 \} \quad \quad \big(\text{¿Por que?}\big)
  \]
\end{ej}
\begin{defi}
  Sea $f : Dom(f) \in \mathbb{R} \to \mathbb{R}^n$ funcion vectoril y $a \in \mathbb{R}f$, definimos la derivada de $f$ en $t=a$ como \[
    f'(a):= \lim_{h \to 0}{\frac{f(a+h)-f(a)}{h}} \quad \text{ siempre que este limite exista.}
  \]
\end{defi}
\begin{obs}
  Notemos que entonces \[ 
    \begin{aligned}
      f'(a) &= \lim_{h \to 0}{\frac{\big(f_1(a+h), \dots ,f_n(a+h)\big)-\big(f_1(a), \dots , f_n(a)\big)}{h}} \\
            &= \lim_{h \to 0}{\left(\frac{f_1(a+h)-f_1(a)}{h}, \dots , \frac{f_n(a+h)-f_n(a)}{h}\right)} \\
            &= \left(\lim_{h \to 0}{\frac{f_1(a+h)-f_1(a)}{h}}, \dots, \lim_{h \to 0}{\frac{f_n(a+h)-f_n(a)}{h}}\right)=\big(f_1'(a), \dots ,f_n'(a)\big).
    \end{aligned}
  \] Es decir, $f'(a)=\big(f_1'(a), \dots ,f_n'(a)\big)$ \quad \big(``derivo coordenada a coordenada''\big).
\end{obs}\; \\
 \textcolor{rojop2}{\bl} Para las funciones vectoriales valen reglas de derivacion similares a las de las derivadas de funciones de $\mathbb{R}$ en $\mathbb{R}$.
\begin{center}
\textbf{Reglas de derivacion.}
\end{center}
Sea $f$ y $g$ funciones vectoriales, $\phi$ funcion de $\mathbb{R}$ en $\mathbb{R}$ y $k \in \mathbb{R}$, entonces \[
  \begin{array}{lllllll}
 & \emph{(i)} & & \big(f(t) \pm g(t) \big)' &&=& f'(t)\pm g'(t)\\ 
 & \emph{(ii)} & & \big(k f(t))' &&=& k \cdot f'(t) \\
 & \emph{(iii)} & & \big(\phi(t)\cdot f(t)\big)' &&=& \phi'(t) \; f(t) + \phi(t) \; f'(t) \\
 & \emph{(iv)} & & \langle f(t),g(t) \rangle' &&=& \langle f'(t),g(t)\rangle + \langle f(t), g'(t) \rangle \\ 
 & \emph{(v)} & & f\big(\phi(t)\big)' &&= & f'\big(\phi(t)\big) \cdot \phi'(t)
\end{array}
\]
 \begin{center}
\textbf{Interpretacion geometrica de la derivada.}
\end{center}
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v51.pdf_tex}
\end{figure}
\; \\ 
\textcolor{rojop2}{\bl} La imagen de $f$ es una curva en el espacio. \\\\
\quad \bl $f(t) =$ posicion en el tiempo $t$ \big(o vector al punto f(t)\big). \\\\
\quad \bl $f(a+h)-f(a)=v_1$ vector que va del punto $f(a)$ al punto $f(a+h)$. \\\\
\quad \bl $\frac{f(a+h)-f(a)}{h}=v_2$ es un vector paralelo al anterior $\left(\text{ya que }v_2=\frac{1}{h}\cdot v_1\right)$. \\\\
\bl Cuando $h$ se aproxima a $0$, $\frac{f(a+h)-f(a)}{h}$ se aproxima a un vector tangente a la curva de $f$ en $f(a)$.
\begin{obs}
  \; \\
  Usualmente decimos que $f(a)$ es el vector posicion y que $f'(a)$ e el vector tangente a la curva en $f(a)$.
\end{obs} \; \pagebreak
\begin{ej}
  Sea $f(t) = \big(cos(t),sen(t)\big).$ Dar el vector posicion y vector tangente a la curva definida para $a=-\frac{\pi}{2}$, $0$ y $\frac{\pi}{4}$. \\\\ 
  \bl Para dar el vector tangente primero debemos hallar $f'(t)$. \\\\
  \phantom{\bl} En este caso, $f'(t)=\big(cos'(t),sen'(t)\big)=\big(-sen(t),cos(t)\big) \quad \forall t \in \mathbb{R}$.\\\\ 
  \textcolor{rojop2}{\bl} Si $a= -\frac{\pi}{2}$ \\\\
  \quad \quad Vector posicion: $f\left(-\frac{\pi}{2}\right)=(0,-1)$\\\\
    \quad \quad Vector tangente: $f'\left(-\frac{\pi}{2}\right)=(1,0)$ \\ \\ \\ 
    \textcolor{rojop2}{\bl} Si $a=0$ \\\\
      \quad \quad Vector posicion: $f\left(0\right)=(1,0)$\\\\
    \quad \quad Vector tangente: $f'\left(0\right)=(0,1)$\\ \\ \\ 
    \textcolor{rojop2}{\bl} Si $a=\frac{\pi}{4}$ \\\\
    \quad \quad Vector posicion: $f\left(\frac{\pi}{4}\right)=\left(\frac{\sqrt{2}}{2},\frac{\sqrt{2}}{2}\right)$\\\\
    \quad \quad Vector tangente: $f'\left(\frac{\pi}{4}\right)=\left(-\frac{\sqrt{2}}{2},\frac{\sqrt{2}}{2}\right)$
\end{ej}
\begin{figure}[h]
\centering
\def\svgwidth{0.95\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v52.pdf_tex}
\end{figure}
\section{Funciones de varias variables.}
Dados dos conjuntos $A$ y $B$, recordemos que una funcion $f: A \to B$ es una regla que a cada elemento de $A$ le asigna exactamente un unico elemento de $B$. 
\begin{defi}
  Una funcion $f$ de $n$ variables es una regla que asigna a cada $n-tupla$ $\bar{x}:= (x_1, \dots , x_n)$ un unico numero real $f(\bar{x})=f(x_1,\dots,x_n)$. \\\\
   \textcolor{rojop2}{\bl} El dominio de $f$ es el subconjunto $Dom(f)$ de $\mathbb{R}^n$ dado por \[
   Dom(f)=\left\{\bar{x} \in \mathbb{R}^n : f(\bar{x}) \text{ esta bien definida}\right\}. \]  
     \textcolor{rojop2}{\bl} El rango o imagen de $f$ es el subconjunto de $Im(f)$ de $\mathbb{R}$ dado por \[ 
       Im(f)=\big\{y \in \mathbb{R} : \exists \bar{x} \in Dom(f) \text{ con } y=f(\bar{x})\big\}.
     \]
     \textcolor{rojop2}{\bl} El grafico de $f$ es el subconjunto $G(f)$ de $\mathbb{R}^{n+1}$ dado por \[ 
       \begin{array}{ll}
       G(f) & = \big\{ (x_1,\dots,x_n,x_{n+1}) \in \mathbb{R}^{n+1} : (x_1,\dots,x_n) \in Dom(f) \text{ y } \\ & \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad  x_{n+1} = f(x_1,\dots,x_n) \big\} \\
              & = \big\{\big(\bar{x},f(\bar{x})\big) \in \mathbb{R}^{n+1} : \bar{x} \in Dom(f)\big\}
       \end{array}
     \]
\end{defi} \; \\
\bl Notar que solo podemos dibujar el grafico de $f$ cuando \\\\
\quad \quad \textcolor{verdep2}{\bl} $n=1$ \quad \big(en cuyo caso decimos que $G(f)$ es una curva en el plano\big) \\\\
\quad \quad \textcolor{verdep2}{\bl} $n=2$ \quad \big(en cuyo caso decimos que $G(f)$ es una superficie en el espacio\big)
\begin{obs}
  \; \\
  \phantom{\bl} Si $n=2$ escribiremos $f(x,y)$ en lugar de $f(x_1,x_2)$ y \\
  \phantom{\bl} Si $n=3$ escribiremos $f(x,y,z)$ en lugar de $f(x_1,x_2,x_3)$.
\end{obs}
\pagebreak 
\begin{ej}
  \; \\
  \textcolor{verdep2}{(1)} Sea $f(x,y)=\sqrt{xy}$ \quad \text{\big(funcion de $n=2$ variables \big)} \\\\
 $\begin{array}{ll}
   \textcolor{rojop2}{\bullet}\;  Dom(f) & =\big\{(x,y) \in \mathbb{R}^2 : x\phantom{,}y \geq 0 \big\} \\ 
           & = \big\{(x,y) \in \mathbb{R}^2 : x,y \geq 0 \big\} \cup \big\{(x,y) \in \mathbb{R}^2 : x,y \leq 0 \big\}
  \end{array}$
\end{ej}
\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v53.pdf_tex}
\end{figure} \; \\

\textcolor{rojop2}{\bl} $Im(f)=[0,\infty)$. En efecto, si elegimos $y=1$ tenemos que \\\\ \phantom{\textcolor{rojop2}{\bl} $Im(f)=[$}$f(x,1) = \sqrt{x}$ y ya sabemos que $h(t) = \sqrt{t}$ es sobreyectiva \\\\ \phantom{\textcolor{rojop2}{\bl} $Im(f)=[$}de $[0,\infty) \to [0,\infty) \quad \therefore f(x,1)$ tambien. \\\\
\bl Otra forma : dado $z \geq 0 $ basta tomar $x=y=z$ y luego \[ 
  f(x,y)=\sqrt{xy} = \sqrt{z \cdot z} = \sqrt{z^2} = z \quad \therefore z \in Im(f). \quad \textcolor{verdep2}{\ok}
\]
\\\\ \pagebreak \\
\textcolor{verdep2}{(2)} Sea $f(x,y)=ln(x+y-2).$\\\\
\textcolor{rojop2}{\bl} \;  $Dom(f)=\big\{(x,y) \in \mathbb{R}^2 : x+y-2>0\big\} = \big\{(x,y) \in \mathbb{R}^2 : y > 2 - x \big\}$ \\
\begin{figure}[h]
\centering
\def\svgwidth{0.45\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v54.pdf_tex}
\end{figure}
\\
\textcolor{rojop2}{\bl} $Im(f)=\mathbb{R}$. \quad En efecto, si elegimos $x=0$ tenemos que \\\\
\phantom{\textcolor{rojop2}{\bl} $Im(f)$} $f(0,y)=ln(y-2)$ y ya sabemos que $h(t)=ln(t-2)$ de \\\\
\phantom{\textcolor{rojop2}{\bl} $Im(f)$} $[2,\infty) \to (-\infty,\infty)$ es sobreyectiva. \\\\
\bl Otra forma: dado $z \in \mathbb{R}$ basta tomar $(x,y)=(0,e^z+2) \in Dom(f)$ ya que \[
  f(0,e^z+2)=ln(e^z)=z. \quad \textcolor{verdep2}{\ok}
\] \pagebreak \\
\textcolor{verdep2}{(3)} Sea $f(x,y)=\sqrt{9-x^2-y^2}$ \quad \quad \big(notacion usual $z=f(x,y)$\big)\\\\
 \; $\begin{array}{ll}
 \textcolor{rojop2}{\bullet}\; Dom(f) &=\left\{(x,y)\in\mathbb{R}^2 : 0-x^2-y^2 \geq 0 \right\}\\ & =\left\{(x,y) \in \mathbb{R}^2 : x^2+y^2 \leq 3^2\right\} \textcolor{rojop2}{\to \begin{array}{l} \text{Eq. circunf.} \\
    \text{centrado en } (0,0) \\
\text{y de radio } 3\end{array}}\end{array}$

\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v55.pdf_tex}
\end{figure}
\; 
\textcolor{rojop2}{\bl} $Im(f)=[0,3]$ \\\\ En efecto, si $y=0$, $f(x,y) = \sqrt{9-x^2}$ sabemos que es sobreyectiva de \mbox{$[-3,3] \to [0,3]$} \\\\ \bl Otra forma: dado $0 \leq z \leq 3$, basta tomar $(x,y)=\big((9-z^2)^{\frac{1}{2}},0\big)$ ya que  \\ \\ $f\big((9-z^2)^\frac{1}{2},0\big)=\sqrt{9-(0-z^2)}=\sqrt{z^2}=z \quad \textcolor{verdep2}{\ok}$.


\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v56.pdf_tex}
\end{figure} \; 
\pagebreak \\

\textcolor{verdep2}{(4)} Sea $f(x,y)=-\sqrt{9-x^2-y^2}$ 
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v57.pdf_tex}
\end{figure} 
\begin{center}
\textbf{Limite y continuidad de funciones de varias variables.}
\end{center}
\begin{defi}
  Dado $r>0$ y $\bar{a} \in \mathbb{R}^n$, llamamos bola (abierta) de centro $\bar{a}$ y radio $r$ al conjunto \[ 
    B(\bar{a},r) := \left\{\bar{x} \in \mathbb{R}^n : || \bar{x} - \bar{a} || < r\right\}
  .\]
\end{defi}
\begin{obs}
  Si escribimos $\bar{x}=(x_1,\dots,x_n)$ y $a=(a_1,\dots, a_n)$, entonces \[
    \begin{array}{lllll}
      B(\bar{a},r)&=\left\{(x_1,\dots,x_n) \in \mathbb{R}^n : \sqrt{(x_1-a_1)^2+\dots + (x_n-a_n)^2}<r^{\phantom{2}}\right\}\\
                  &=\left\{(x_1,\dots,x_n)\in\mathbb{R}^n : \; \; \; \;  (x_1-a_1)^2+\dots+(x_n-a_n)^2 < r^2\right\}.
    \end{array}
  \]
\end{obs}
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v58.pdf_tex}
\end{figure} 
\begin{defi}[Límite] Sea $\bar{a} \in \mathbb{R}^n$ y $f : Dom(f) \subset \mathbb{R}^n \to \mathbb{R}$ definida en un dominio $Dom(f)$ que incluye puntos arbitrariamente cercanos a $\bar{a}$ . Decimos que \[ 
  \lim_{\bar{x} \to \bar{a}}{f(\bar{x})}=L \quad \quad \left(\text{o} \lim_{(x_1,\dots,x_n) \to (a_1, \dots ,a_n)}{f(x_1,\dots,x_n)}=L\right)
\]
\phantom{(}si $\forall \epsilon > 0,\; \exists \delta > 0$ \; tq \; $\bar{x} \in Dom(f) \cap B(\bar{a},\delta) \Rightarrow \big|f(\bar{x}-L) \big| < \epsilon$\\\\ \big(si $\bar{x} \in Dom(f)$ \; queda \; $||\bar{x}-\bar{a}|| < \delta \Rightarrow \big|f(\bar{x}-L)-L\big|<\epsilon$\big). \\\\ Esto significa que si nos acercamos ``por cualquier lado'' al punto $\bar{a}$, $f$ se acerca a $L$.
\end{defi}
Graficamente: 
\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v59.pdf_tex}
\end{figure} \\
\begin{obs}
  La definicion establece que la distancia (en $\mathbb{R}$) entre $f(\bar{x})$ y $L$ se puede hacer arbitrariamente pequeña haciendo que la distancia (en $\mathbb{R}^n$) entre $\bar{x}$ y $\bar{a}$ sea suficientemente pequeña. Sin embargo \underline{\textbf{no}} hay referencia a la direccion o modo de aproximacion. Luego, si existe el limite entonces $f(x,y)$ tiene que aproximarse a $L$ sin importar como $\bar{x}$ se aproxima a $\bar{a}$. \\\\ Por lo tanto, si encontramos dos maneras distintas de aproximarnos a $\bar{a}$ en los cuales la funcion $f(\bar{x})$ tiene diferentes limites, entonces esto nos dice que $\lim_{\bar{x} \to \bar{a}}{f(\bar{x})}$ \underline{\textbf{NO}} existe.
\end{obs}\pagebreak
Graficamente:
\begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v60.pdf_tex}
\end{figure}
\begin{ej}
  \; \\
  \textcolor{verdep2}{(1)} Sea $f(x,y)=\frac{xy}{x^2+y^2}$. Demuestre que $\lim_{\bar{x} \to \bar{0}}{f(\bar{x})}$ NO existe $\left(\lim_{(x,y) \to (0,0)}{f(x,y)}\right)$.\\\\
  Tenemos que $Dom(f)=\mathbb{R}^2-\big\{(0,0)\big\}$.\\\\
\textcolor{rojop2}{\bl} Si nos acercamos al $(0,0)$ por puntos del eje $x$, o sea si $(x,y)=(x,0) \to (0,0)$ como $f(x,0)=0$ tenemos que $\lim_{(x,0) \to (0,0)}{f(x,0)}=\lim_{x\to 0}{f(x,0)}=0. \quad \textcolor{rojop2}{(1)}$\\\\
\textcolor{verdep2}{\bl} Si nos acercamos al $(0,0)$ por la recta $y=x$, o sea si $(x,y)=(x,x) \to (0,0)$ \\ como $f(x,x)=\frac{xx}{x^2+x^2}=\frac{x^2}{2x^2}=\frac{1}{2}$ tenemos que \mbox{$\lim_{(x,y) \to 0}{f(x,y)}=\lim_{x\to 0}{f(x,x)}=\frac{1}{2}.\quad \textcolor{verdep2}{\text{(2)}}$}\\\\\\
De \textcolor{rojop2}{(1)} y \textcolor{verdep2}{(2)} concluimos que $\lim_{(x,y)\to(0,0)}{f(x,y)}$ NO existe.
\end{ej}
\begin{figure}[h]
\centering
\def\svgwidth{0.35\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v61.pdf_tex}
\end{figure}
\pagebreak 
\textcolor{verdep2}{(2)} Sea $f(x,y)=\frac{x^2+y^2}{y}$. Probar que $\lim_{(x,y)\to(0,0)}{f(x,y)}$ NO existe.
\\\\ 
Notar que $Dom(f)=\mathbb{R}^2-\big\{(x,0) \in \mathbb{R}^2 : x \in \mathbb{R}\big\} \quad \big(\text{``plano }- \text{ eje }x \text{''}\big)$ \\\\ 
\bl Si nos acercamos al $0,0$ por el eje $y$, o sea $(x,y)=(0,y) \to (0,0)$. Como \[
  f(0,y)=\frac{0^2+y^2}{y}=y, \; \text{entonces } \lim_{(0,y) \to (0,0)}{f(0,y)}=\lim_{y \to 0}{0,y}=\lim_{y \to 0}{y}=0. \quad \textcolor{rojop2}{\text{(1)}}
\]
\bl Si nos acercamos al $(0,0)$ por la parabola $y=x^2$, o sea si \mbox{$(x,y)=(x,x^2) \to (0,0)\text{. Como }$}\[
  f(x,x^2)=\frac{x^2+x^4}{x^2}=1+x^2, \; \text{entonces } \lim_{(x,x^2)\to(0,0)}{f(x,y)}=\lim_{x\to0}{f(x,x^2)}=\lim_{x\to 0}{1+x^2}=1. \quad \textcolor{verdep2}{\text(2)}
\]
De \textcolor{rojop2}{(1)} y \textcolor{verdep2}{(2)} concluimos que $\lim_{(x,y)\to(0,0)}{f(x,y)}$ NO existe.
\begin{figure}[h]
\centering
\def\svgwidth{0.35\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v62.pdf_tex}
\end{figure}\\
\underline{Ejercicio}: usando la definicion de limite demuestre que \mbox{$\lim_{(x,y)\to(0,0)}{\frac{x^2}{\sqrt{x^2+y^2}}}=0$.} 
\begin{defi}[Continuidad] Sea $f : Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$ y $\bar{a} \in \mathbb{R}^n$. Decimos que $f$ es continua en $\bar{a}$ si $$\bar{a} \in Dom(f) \; \text{ y } \; \lim_{\bar{x} \to \bar{a}}{f(\bar{x})}=f(\bar{a}).$$
  \bl Decimos que $f$ es continua si $f$ es continua $\forall \bar{x} \in Dom(f)$. 
\end{defi}
\begin{obs}
  Valen propiedades similares a las de funciones continuas de $\mathbb{R}$ en $\mathbb{R}$ O sea, si $f$ y $g$ son continuas, entonces tambien son continuas $f \pm g$, $f \cdot g$, etc.
\end{obs}
\pagebreak
\begin{center}
\textbf{Derivadas Parciales.}
\end{center}
\underline{Intro / Motivacion}: Sea $f : \mathbb{R}^2 \to \mathbb{R}$ y $(a,b) \in \mathbb{R}^2$. Si fijamos $b$, tenemos que $g(x):=f(x,b)$ es una funcion de una sola variable (la $x$) y entonces tiene sentido considerar su derivada en $x=a$. Esto es 
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v63.pdf_tex}
\end{figure} \; \\ \bl 
En general, para cualquier punto $(x,y)$ definimos la derivada parcial de $f$ con respecto a $x$ en el punto $(x,y)$ como \[
  \frac{\partial f}{\partial x} (x,y) = f_x (x,y) := \lim_{h \to 0}{\frac{f(x+h,y)-f(x,y)}{h}}.
\]
\bl Notar que para calcular $f_x(x,y)$ dejamos la variable $y$ fija (la pensamos como una constante) y derivamos respecto a la variable $x$. \\\\
\bl
  Si $f(x,y)=x^2y+e^y+x$ entonces $f_x(x,y)=2xy+1$.
  \begin{defi}
    Sean $f : Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$, $\bar{a}=(a_1,\dots,a_n) \in \mathbb{R}^n$ y suponiendo $B(\bar{a},r) \subset Dom(f)$ para algun $r>0$. Definimos la derivada parcial de $f$ respecto a $x_j$ en el punto $\bar{a}$ como \[\begin{aligned}
      \frac{\partial f}{\partial x_j}(a_1,\dots,a_n) &:= f_{x_j}(a_1,\dots,a_n)
  \\  &:= \lim_{h \to 0}{\frac{f(a_1,\dots,a_{j-1},a_{j}+h,a_{j+1},\dots,a_n)-f(a_1,\dots,a_n)}{h}}
    \end{aligned}
    \] siempre que este limite exista.
  \end{defi}
\begin{obs}
  \; \\\\  
  \textcolor{verdep2}{\bl} Si $n=2$ escribimos $f_x$ y $f_y$ en lugar de $f_{x_1}$ y $f_{x_2}$. \\\\
  \textcolor{verdep2}{\bl} Si $n=3$ escribimos $f_x$, $f_y$, $f_z$ en lugar de $f_{x_1}$, $f_{x_2}$, $f_{x_3}$.\\\\
  \textcolor{verdep2}{\bl} Si $n=1$ tenemos que $f_{x_1}(a)=f'(a)$ \quad (la derivada usual).
\end{obs}
\begin{obs}
  Para calcular la derivada parcial de $f$ respecto a $x_j$, consideramos todas las variables $x_k$ con $k \neq j$ como constantes y derviamos con respecto a la variable $x_j$. 
\end{obs}
\begin{ej}
  Sea $f(x,y,z) = \frac{xz}{y+z}$. Entonces, las derivadas parciales de $f$ son \[ 
    f_x(x,y,z)=\frac{z}{y+z}; \quad f_y(x,y,z)=-\frac{xz}{(y+z)^2}; \quad f_z(x,y,z)=\frac{x(y+z)-xz \cdot 1}{(y+z)^2}=\frac{xz}{(y+z)^2}.
  \] 
\end{ej}
\begin{obs}
  Sabemos que si $f : \mathbb{R} \to \mathbb{R}$ es derivable en $a \Rightarrow f$ es continua en $a$. Sin embargo, si $f: \mathbb{R}^n \to \mathbb{R}$ con $n \geq 2$ lo anterior no es cierto. Es decir pueden existir todas las derivadas parciales de $f$ en $\bar{a}$ pero $f$ puede ser discontinua en $\bar{a}$.\end{obs}
\begin{ej}
  Sea $f(x,y) = \left\{\begin{array}{ccl}
      \frac{xy}{x^2+y^2} & \text{si} & (x,y) \neq (0,0) \\
      0 & \text{si} & (x,y)=(0,0)
  \end{array}\right..$ \\
  Tenemos que $f_x(0,0)=\lim_{h \to 0}{\frac{f(0+h,0)-f(0,0)}{h}}=\lim_{h \to 0}{\frac{\overbrace{f(h,0)}^{= 0}-\overbrace{f(0,0)}^{= 0}}{h}}=0.$\\\\ De manera analoga se prueba que $f_y(0,0)=0$. Sin embargo $f$ NO puede ser continua en $(0,0)$ ya que ni siquiera existe $\lim_{(x,y) \to (0,0)}{f(x,y)}$ \quad (ver pagina 93). \\\\ 
  \bl Si pedimos continuidad de las derivadas parciales $f_{x_j}$ en $\bar{a}$ entonces podemos garantizar continuidad de $f$ en $\bar{a}$. \\\\ Esto es: 
\end{ej}
\begin{teo}
  Sea $f:Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$, $\bar{a} \in Dom(f)$ y \\ $B(\bar{a},r) \subset Dom(f)$, para algun $R>0$. \\\\ Si $f_{x_1}, \dots, f_{x_n}$ existen y son continuas para todo $\bar{x} \in B(\bar{a},r) \Rightarrow f$ es\\ continua para todo $\bar{x} \in B(\bar{a},r).$ \quad (En particular para $\bar{x}=\bar{a}$).
\end{teo}
\pagebreak
\begin{center}
\textbf{Interpretacion geometrica de las derivadas parciales.}
\end{center}
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v64.pdf_tex}
\end{figure} \; \\
Para $f : \mathbb{R}^n \to \mathbb{R}$, la derivada parcial $f_{x_j}(\bar{a})$ da la tasa de crecimiento de $f$ en $\bar{a}$ cuando nos movemos dejando todas las coordenadas fijas salvo la $j$-esima.
\pagebreak
\textcolor{rojop2}{\bl} Supongamos $f : \mathbb{R}^2 \to \mathbb{R}$ y sea $S$ el grafico de $f$, es decir \[
  S= \big\{(x,y,z) \in \mathbb{R}^3 : z=f(x,y) \land (x,y) \in Dom(f)\big\}.
\] 
Sea $\Pi_1$ el plano $y=b$ \; y \; $C_1=S \cap \Pi_1$. O sea $C_1$ es la imagen de la funcion vectorial \[ 
  \gamma_1 : \mathbb{R} \to \mathbb{R}^3 \text{ definida por } \gamma_1(x) = \big(x,b,f(x,b)\big).
\] 
Sabemos que $\gamma'_1(x)$ es un vector tangente a $\gamma_1(t)$. \\ Entonces $\gamma'(a)=\big(1,0,f_x(a,b)\big)$ es tangente a la curva $C_1$ en el punto $\big(a,b,f(a,b)\big)$.\\\\
Analogamente si $\Pi_2$ es el plano $x=a$\; y\; $C_2:= S \cap \Pi_2$, el vector $\big(0,1,f_y(a,b)\big)$ es tangente a $C_2$ en el punto $\big(a,b,f(a,b)\big)$.
\begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v65.pdf_tex}
\end{figure} \\
 \begin{align*}
  \textcolor{verdep2}{\bullet}\text{ Otra interpretacion: } & f_x(a,b) \text{ es la pendiente de la recta tangente a la curva }C_1.\\
                              & f_y(a,b) \text{ es la pendiente de la recta tangente a la curva }C_2. \end{align*}
                              \pagebreak
\begin{defi}
  Sea $f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$ y $(a,b) \in Dom(f)$. El plano que pasa por $\big(a,b,f(a,b)\big)$ y es generado por los vectores $\big(1,0,f_x(a,b)\big)$ y $\big(0,1,f_y(a,b)\big)$ se llama plano tangente al grafico de $f$ en el punto $\big(a,b,f(a,b)\big)$.
\end{defi}
\underline{Graficamente}:
\begin{figure}[h]
\centering
\def\svgwidth{0.35\textwidth}
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v66.pdf_tex}
\end{figure} 
\begin{obs}
  La ecuacion vectorial del plano tangente al grafico de $f$ en $\big(a,b,f(a,b)\big)$ es \[
    (x,y,z) = \big(a,b,f(a,b)\big)+t\big(1,0,f_x(a,b)\big)+r\big(0,1,f_y(a,b)\big), \text{ con } t, r \in \mathbb{R}.
  \]
  \bl Sabemos que el vector $\big(1,0,f_x(a,b) \times \big(0,1,f_y(a,b)\big)\big)= \big(-f_x(a,b),-f_y(a,b),1\big)$ es perpendicular al plano tangente. Luego, la ecuacion normal del plano tangente es \[
    \big\langle\big(x,y,z\big)-\big(a,b,f(a,b)\big) \; , \; \big(-f_x(a,b),-f_y(a,b),1\big)\big\rangle =0.
    \] O equivalentemente, la ecuacion cartesiana del plano tangente al grafico de $f$ en $\big(a,b,f(a,b)\big)$ es\[
    z=(x-a)f_x(a,b)+(y-b)f_y(a,b)+f(a,b)
  \]
\end{obs}\pagebreak
\begin{ej}
  Obtener la ecuacion del plano tangente al grafico de \mbox{$f(x,y)=sen\left(\frac{x}{y}\right)$} en el punto $\left(\pi, 4, sen\left(\frac{\pi}{4}\right)\right)$ y ademas dar la ecuacion de la recta normal a dicho plano y que pasa por el mismo punto.\\\\
  \bl Tenemos que: \begin{alignat*}{100}
    \bullet & f & (x,y)=&sen\left(\frac{x}{y}\right) &\leadsto & f & (\pi,4) = & sen\left(\frac{\pi}{4}\right) & = & \frac{\sqrt{2}}{2} \\
    \bullet & f_x & (x,y)=&cos\left(\frac{x}{y}\right)\cdot \left(\frac{1}{y}\right) &\leadsto & f_x & (\pi,4) = & cos\left(\frac{\pi}{4}\right) \cdot \left(\frac{1}{4}\right) &= & \frac{\sqrt{2}}{8} \\
    \bullet & f_y & (x,y)=&cos\left(\frac{x}{y}\right)\cdot \left(\frac{-x}{y^2}\right) &\leadsto & f_y & (\pi,4) = & cos\left(\frac{\pi}{4}\right) \cdot \left(\frac{-\pi}{16}\right)&  = & \frac{-\pi\sqrt{2}}{32} 
    \end{alignat*} \\ Luego, la ecuacion del plano tangente en el punto $\left(\pi,4,\frac{\sqrt{2}}{2}\right)$ es: \[ 
    z=\frac{\sqrt{2}}{8}(x - \pi)-\frac{\pi\sqrt{2}}{32}(y-4)+\frac{\sqrt{2}}{2}
  \] Por otra parte, la recta que pasa por el punto $\big(\pi,4,\frac{\sqrt{2}}{2}\big)$ y es normal al plano anterior es: \[
  (x,y,z)=\left(\pi,4,\frac{\sqrt{2}}{2}\right)+t\textcolor{rojop2}{\underbrace{\textcolor{black}{\left(-\frac{\sqrt{2}}{8},\frac{\sqrt{2}\pi}{32},1\right)}}_{\text{vector normal al plano}}} \text{ con } t \in \mathbb{R}
  .\]
\end{ej}
\pagebreak
\begin{center}
\textbf{Regla de la Cadena.}
\end{center}
\textcolor{rojop2}{\bl} Para funciones de $1$ varible sabemos que si $h : I_1 \subset \mathbb{R} \to I_2 $ y $ f: I_2 \subseteq \mathbb{R} \to I_3$ son funciones derivables en sus dominions, entonces la funcion \[
  g(t)=f\big(h(t)\big) \; \text{ es derivable y ademas }\; g'(t) = f'\big(h(t)\big)\cdot h'(t).
  \]
  $$\begin{array}{lcccc}
  t & \mapsto & h(t) & \mapsto & f\big(h(t)\big) \\
  \mathbb{R} & \xrightarrow{h} & \mathbb{R} & \xrightarrow{f} & \mathbb{R} \\
  I_1 & & I_2 & & I_3
\end{array}$$
\begin{teo}[Regla de la Cadena, Caso 1]
  Sea $f : Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$, $\bar{a} \in Dom(f)$ y tal que $\frac{\partial f}{\partial x_1},\dots,\frac{\partial f}{\partial x_n}$ existen y son continusa en $B(\bar{a},r)$ para algun $r>0$.\\\\
  Para $1 \leq i \leq n$ y un intervalo $I \subseteq \mathbb{R}$, sean $x_i : I \to \mathbb{R}$ funciones derivables $\forall t \in I$ y tal que $\big(x_1(t),\dots,x_n(t)\big) \in B(\bar{a},r) \; \forall t \in I.$ Entonces, la funcion \[
    g(t) := f\big(x_1(t), \dots, x_n (t)\big) \; \text{ es derivable } \; \forall t \in I \; \text{ y ademas }
    \] \[
    \frac{dg}{dt}=g'(t)= \frac{\partial f}{\partial x_1}\big(x_1(t),\dots,x_n(t)\big)\cdot x_1'(t) + \;  \dots \; + \frac{\partial f}{\partial x_n}\big(x_1(t),\dots,x_n(t)\big)\cdot x_n'(t). 
  \]
\end{teo}
\begin{figure}[h]
\centering
\def\svgwidth{1.5\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v67.pdf_tex}}
\end{figure} \pagebreak
\begin{ej}
  Sea $f(x,y)=x^2+y^2+xy$, con \mbox{$x(t)=sen(t), \; y(t)=e^t. \text{ Hallar } \frac{df}{dt}.$}\\\\
  \bl Tenemos que:  $$\begin{array}{lclclcl}
      \frac{\partial f}{\partial x}(x,y) & = & 2x+y & ; & \frac{\partial f}{\partial y}(x,y) & = & 2y+x. \\
                                         x'(t) & = & cos(t) & ; & y'(t) & = &  e^t.
                                         \end{array}$$ Luego, \[ 
                                         \begin{alignedat}{10}
                                           \frac{df}{dt} & = \frac{\partial f }{\partial x} \big(x(t),y(t)\big) \cdot x'(t) && + \frac{\partial f }{\partial y} \big(x(t),y(t)\big) \cdot y'(t) \\ 
                                                         & = \big(2x(t)+y(t)\big) \cdot (cos(t)) && + \big(2y(t)+x(t)\big) \cdot e^t \\ 
                                                         & = \big(2sen(t)+e^t\big) \cdot cos(t) && + \big(2e^t+sen(t)\big)\cdot e^t \quad \quad \textcolor{rojop2}{(\triangle)}
                                         \end{alignedat}
                                       \]
                                    
\end{ej}
\begin{obs}
  Notar que si escribimos \mbox{$f(t)=x^2(t)+y^2(t)+x(t)y(t)=sen^2(t)+e^{2t}+sen(t)e^t$} entonces $\frac{df}{dt}=2sen(t)cos(t)+2e^{2t}+cos(t)e^t+sen(t)e^t$ que es igual a \textcolor{rojop2}{$(\triangle)$}. 
\end{obs}\pagebreak
\begin{teo}[Regla de la Cadena, Caso 2]\;\\
Sea $f: Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}, \bar{a}_1 \in Dom(f)$ y tq $\frac{\partial f}{\partial x_1}$ y $\frac{\partial f}{\partial x_2}$ existen y son continuas en $B(\bar{a}_1,r_1)$ para algun $r_1>0$. \\\\Sean $ x : Dom(x) \subseteq \mathbb{R}^2 \to \mathbb{R}$ y $y : Dom(y) \subset \mathbb{R}^2 \to \mathbb{R}$ dos funciones con sus derivadas parciales continuas en $B(\bar{a}_0,r_0)$ para algun $r_0>0$ y tal que $\big(x(s,t),y(s,t)\big) \in B(\bar{a}_1,r_1) \; \forall (s,t) \in B(\bar{a}_0,r_0).$ \\\\ Entonces, la funcion definida por $$ g(s,t):=f\big(x(s,t),y(s,t)\big) \; \forall (s,t) \in B(\bar{a}_0,r_0)$$ tiene derivadas parciales dadas por \\\\ 
\bl $\frac{\partial g}{\partial s}(s,t)=\frac{\partial f}{\partial x}\big(x(s,t),y(s,t)\big)\cdot \frac{\partial x}{\partial s}(s,t)+\frac{\partial f}{\partial y}\big(x(s,t),y(s,t)\big)\cdot\frac{\partial y}{\partial s}(s,t)$ \\\\
\bl $\frac{\partial g}{\partial t}(s,t)=\frac{\partial f}{\partial x}\big(x(s,t),y(s,t)\big)\cdot \frac{\partial x}{\partial t}(s,t)+\frac{\partial f}{\partial y}\big(x(s,t),y(s,t)\big)\cdot\frac{\partial y}{\partial t}(s,t)$
\end{teo}
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v68.pdf_tex}}
\end{figure} \pagebreak
\begin{ej}
  Sea $f(x,y)=xy+2y^2+x^3$, donde \mbox{$x(s,t)=st, \; y(s,t)=e^{st}.$} \\Calcular $\frac{\partial f }{\partial s}$ en el punto $(s,t)=(1,1)$. \\\\
  \bl Tenemos que:  $$\begin{array}{lclclcl}
      f_x(x,y) & = & y+3x^2 & ; & f_y(x,y) & = & x+4y. \\
      x_s(s,t) & = & t & ; & y_s(s,t) & = &  t \; e^{st}.
      \end{array}$$ Luego \[
  \begin{alignedat}{10}
  \frac{\partial f}{\partial s} & = f_x \big(x(s,t),y(s,t)) \cdot x_s(s,t) && + f_y \big(x(s,t),y(s,t)\big) \cdot y_s(s,t) \\ 
                                & = \big(e^{st}+3(st)^2\big) \cdot t && + \big(st+4e^{st}\big) \cdot t\; e^{st}. \quad \quad \textcolor{rojop2}{(\square)}\end{alignedat}
      \]Finalmente, si evaluamos en $(s,t)=(1,1)$ obtenemos \[
      \frac{\partial f}{\partial s}(1,1)=(e+3)\cdot 1+(1+4e)e = 4e^2+2e+3.
    \]
                                       \end{ej}
\begin{obs}
  Notr que si escribimos \[ 
    \begin{aligned}
      f(s,t) & = x(s,t)y(s,t)+2y^2(s,t)+x^3(s,t) \\
             & =st \; e^{st} + 2 \; e^{2st} + s^3t^3
    \end{aligned}
  \] entonces $\frac{\partial f }{\partial s}(s,t)=te^{st}+st^2e^{st}+2\cdot2te^{2st}+3s^2t^3$ que es igual a \textcolor{rojop2}{$(\square)$}.
\end{obs}\pagebreak
\begin{center}
\textbf{Derivada direccional.}
\end{center}
\begin{defi}
  Decimos que $\bar{u}=(u_1,\dots,u_n) \in \mathbb{R}^n$ es un vector unitario si $||u||=1$. 
\end{defi}
\begin{defi}
  Sean $f: Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$, $\bar{a}=(a_1,\dots,a_n) \in \mathbb{R}^n$ tq $B(\bar{a},r)$ $\subseteq Dom(f)$ para algun $r>0$ y $\bar{u}$ un vector unitario. Definimos la derivada direccional de $f$ en la direccion de $\bar{u}$ en el punto $\bar{a}$ como \[
    \begin{aligned}
      D_{\bar{u}}f(\bar{a}) & = \lim_{h\to0}{\frac{f(\bar{a}+h\;\bar{u}-f(\bar{a}))}{h}} \\
                            & = \lim_{h \to 0}{\frac{f(a_1+h\;u_1,\dots,a_n+h\;u_n)-f(a_1,\dots,a_n)}{h}} 
  \end{aligned}\]si este limite existe.
\end{defi}
\begin{obs}
  \;\\
  \textcolor{verdep2}{(1)} Si el vector $\bar{u}$ no es unitario, entonces consideramos $\bar{v}=\frac{\bar{u}}{||\bar{u}||}$ $\left(\begin{array}{c}
      \text{unitario y misma direccion} \\
      \text{que } \bar{u}
  \end{array}\right)$. \\\\
  \textcolor{verdep2}{(2)} Si tomamos $\bar{u}=e_i=(0,\dots,0,\textcolor{azulp2}{1},0,\dots,0) (\textcolor{azulp2}{1} \text{ es la i-esima coordenada})$ entonces $D_{e_i}f(\bar{a})=\frac{\partial f}{\partial x_i}(\bar{a})$. O sea las derivadas parciales son un caso particular de derivada direccional. 
\end{obs}
\begin{defi}
  Sea $f : Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$ y $\bar{a} \in Dom(f)$ tq existen $\frac{\partial f}{\partial x_i}(\bar{a}) \; \forall i=1,\dots,n$. Llamamos gradiente de $f$ en $\bar{a}$ al vector \[
    \nabla f(\bar{a}):=\left(\frac{\partial f}{\partial x_1}(\bar{a}), \dots ,\frac{\partial f }{\partial x_n}(\bar{a})\right).
  \]
\end{defi}
\begin{teo}
  Sea $f: Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$ tal que $\frac{\partial f}{\partial x_i}(\bar{x})$ existen y \underline{son continuas} $\forall x \in B(\bar{a},r) \subseteq Dom(f)$ y $\forall i =1, \dots, n$ y $\bar{u}=(u_1,\dots,u_n)$ un vector unitario, entonces vale que \[
    D_{\bar{u}}f(\bar{a}) = \big\langle \nabla f(\bar{a}),\bar{u}\big\rangle = \frac{\partial f}{\partial x_1}(\bar{a})\; u_1 + \dots + \frac{\partial f}{\partial x_n}(\bar{a}) \; u_n.
  \]
\end{teo}\pagebreak
\begin{demo}
  Definimos $g(h)=f(a_1+h\;u_1,\dots,a_n+h\;u_n)$ \quad \big(funcion de \underline{$\mathbb{R}$ en $\mathbb{R}$}\big).\\\\
  Luego, \[ 
    D_{\bar{u}}f(\bar{a})=\lim_{h \to 0}{\frac{f(a_1+h \; u_1, \dots , a_n+h \; u_n)-f(a_1,\dots, a_n)}{h}}=\lim_{h t\o 0}{\frac{g(h)-g(0)}{h}}=g'(0). \quad \textcolor{rojop2}{(1)}
  \]
Ahora, por la regla de la cadena (caso 1) con $t=h$ \[
  \begin{aligned}
    g'(h) & = \frac{\partial f }{\partial x_1}(\bar{a}+h \; \bar{u}) \cdot \frac{\partial (a_1+h \; u_1)}{\partial h} + \dots + \frac{\partial f}{\partial x_n}\frac{\partial (a_n+h \; u_n)}{\partial h} \\
          &= \frac{\partial f}{\partial x_1}(\bar{a} + h  \; \bar{u}) \cdot u_1 + \dots + \frac{\partial f}{\partial x_n}(\bar{a}+h \; \bar{u}) \cdot u_n \\
          & = \big\langle \nabla f(\bar{a}+h\;\bar{u}),\bar{u}\big\rangle.
  \end{aligned}
\]
Con lo cual, $g'(0)=\big\langle \nabla f(\bar{a}),\bar{u} \big\rangle. \quad \textcolor{rojop2}{(2)}$ \\\\
De \textcolor{rojop2}{(1)} y \textcolor{rojop2}{(2)} obtenemos que $D_{\bar{u}}f(\bar{a})=\big\langle \nabla f(\bar{a}),\bar{u} \big\rangle$.
  \qed
  \end{demo}
\begin{center}
\textbf{Interpretacion geometrica de la derivada direccional.}
\end{center}
\textcolor{verdep2}{\bl} Sea $f: Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}, (x_0,y_0) \in Dom(f)$ y \[
P=\big(x_0,y_0,f(x_0,y_0)\big) \in Graf(f):=S.
\]
\textcolor{verdep2}{\bl} Sea $l$ la recta en el plano $x-y$ dada por \[
  (x,y) = (x_0,y_0)+t(u_1,u_2).
\]
Sea $\Pi$ el plano vertical que contiene a la recta $l$. \\\\
\textcolor{verdep2}{\bl} Sea $C := \Pi \cap S$ y $r$ la recta tangente a la curva $C$ en el punto $P$. Notemos que $C$ es la imagen de la funcion vectorial $g : \mathbb{R} \to \mathbb{R}^3$ dada por \[
  g(t)=\big(x_0+tu_1,y_0+tu_2,\underbrace{f(x_0+tu_1,y_0+tu_2)}_{:= h(t)}\big).
\]
Sabemos que $h'(t)$ da la pendiente de la recta tangente al grafico de $h$ (pues $h : \mathbb{R} \to \mathbb{R}$). \\\\
Ahora \[
h'(t)=\frac{\partial f}{\partial x_1}\big((x_0,y_0)+t\bar{u}\big)\cdot u_1 + \dots + \frac{\partial f}{\partial x_n}\big((x_0,y_0)+t\bar{u}\big)
  \] y por lo tanto \[
  h'(0)=\big\langle \nabla f(x_0,y_0),\bar{u}\big\rangle=D_{\bar{u}}f(x_0,y_0).
\]
\begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v69.pdf_tex}}
\end{figure} \\
\textcolor{verdep2}{\bl} Entonces $D_{\bar{u}}f(x_0,y_0)$ da la pendiente de $r$, o sea la tasa de crecimiento de $f$ en $(x_0,y_0)$, cuando nos movemos en la direccion $\bar{u}=(u_1,u_2).$ \\\\ Notar que $r$ viene dada por la ecuacion \[ 
(x,y,z)=\big(x_0,y_0,f(x_0,y_0)\big)+t\big(u_1,u_2,D_{\bar{u}}f(x_0,y_0)\big) \; \text{ para } t \in \mathbb{R}.
\] \pagebreak 
\begin{ej}
  Calcular la derivda direccional de $f(x,y)=xe^y$ en el punto $P=(2,0)$ en la direccion de $\bar{v}=(1,\sqrt{3})$.\\\\
  \textcolor{rojop2}{\bl} Notemos que $\bar{v}$ no es unitario ya que $||\bar{v}||=\sqrt{1+3}=2$. Luego, deberiamos considerar al vector $\bar{u}=\frac{\bar{v}}{||\bar{v}||}=\frac{1}{2}(1,\sqrt{3})$ que tiene la misma direccion que $\bar{v}$ pero es unitario. \\\\ Por otra parte, $\frac{\partial f}{\partial x}(x,y)=e^y$ y $\frac{\partial f}{\partial y}(x,y)=x e^y$, ambas son funciones continuas. \\\\ Luego, por teorema, $$\begin{aligned}
    D_{\bar{u}}f(2,0) & =\big\langle \nabla f(2,0),\bar{u} \big\rangle \\
                      & = \left\langle \left(e^0,2e^0\right),\left(\frac{1}{2},\frac{\sqrt{3}}{2}\right)\right\rangle = \frac{1}{2}+\sqrt{3}.
  \end{aligned}$$
\end{ej}
\begin{ej}
  Sea $f: Dom(f) \subseteq \mathbb{R}^n \to \mathbb{R}$ y $\bar{a} \in Dom(f)$ tq $\frac{\partial f}{\partial x_i}(\bar{x})$ existen y son continuas $\forall x \in B(\bar{a},r)$ y para $1 \leq i \leq n$. Si $\nabla f(\bar{a}) \neq (0,\dots,0)$, entonces \\\\
  \emph{(i)\phantom{i}} El vector $\bar{u}=\phantom{-}\frac{\nabla f(\bar{a})}{||\nabla f(\bar{a})||}$ da la direccion de maximo crecimiento de \mbox{$f \text{ en }\bar{a}$.} \\\\ 
  \emph{(ii)} El vector $\bar{v}=-\frac{\nabla f(\bar{a})}{||\nabla f(\bar{a})||}$ da la direccion de minimo crecimiento de $f$ en $\bar{a}$. \\\\
\end{ej}
\begin{demo}
  \; \\
  \bl Tenemos que $D_{\bar{u}}f(\bar{a})=\big\langle \nabla f(\bar{a},\bar{u})\big\rangle = || \nabla f(\bar{a})||\; ||\bar{u}|| \; cos(\theta)$. \\ \big(Notar que $||\bar{u}||=1$ y $cos(\theta)$ toma valores entre $-1$ y $1$.\big)\\\\ \bl Entonces tenemos que el maximo valor de $cos(\theta)$ \big(y por ende el maximo valor de $D_{\bar{u}}f(\bar{a})$\big) se da cuando $cos(\theta)=1$, y o sea $\theta=0$ y esto nos dice que $\nabla f(\bar{a})$ y $\bar{u}$ son paralelos y tienen mismo sentido. \\\\
  \bl De manera analoga, el minimo valor de $cos(\theta)$ es cuando vale $-1$, o sea $\theta=\pi$. Es decir, cuando los vectores $\nabla f(\bar{a})$ y $\bar{u}$ son paralelos y con sentido opuesto.
\end{demo}
\begin{obs}
  $\tilde{u}=\nabla f(\bar{a})$ y $\tilde{v}=-\nabla f(\bar{a})$ tienen la misma direccion que $\bar{u}$ y $\bar{v}$ respectivamente pero NO son unitarios.
\end{obs}
\pagebreak
\begin{ej}
  ¿En que direccion debemos movernos, paretiendo de $(1,2)$, para obtener la mayor tasa de crecimiento y la mayor tasa de decrecimiento de la funcion $f(x,y)=(x+y-2)^2$? \\\\
  \textcolor{rojop2}{\bl} Tenemos que $\nabla f(x,y)=\big(2(x+y-2),2(x+y-2)\big).$ Luego, $\nabla f(1,2)=(2,2)$. \\\\
  Por lo tanto : \[
    \begin{array}{ll}
    \bullet \text{ La tasa de mayor crecimiento es en la direccion }& \tilde{u}=\phantom{-}\nabla f(1,2)=(2,2). \\
    \bullet \text{ La tasa de mayor decrecimiento es en la direccion} & \tilde{v}=-\nabla f(1,2)=(-2,-2).
  \end{array}
  \]
\end{ej}
\begin{obs}
  Para poder calcular las derivadas direccionales y obtener los valores de las tasas de maximo crecimiento/decrecimiento debemos considerar los vectores $\bar{u}=\frac{\tilde{u}}{||\tilde{u}||}$ y $\bar{v}=\frac{\tilde{v}}{||\tilde{v}||}$.
\end{obs}\pagebreak
\begin{center}
\textbf{Curvas y Superficies de nivel.}
\end{center}
\begin{defi}
  Sea $k \in \mathbb{R}$ y $f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$. Llamamos curva de nivel $k$ de $f$ al subconjunto de $Dom(f)$ definida por \[
    C_k:=\big\{(x,y) \in Dom(f) : f(x,y) = k\big\}
  \]
  \big($C_k$ puede ser $\emptyset$, puntos aislados o una curva\big).
\end{defi}

\begin{ej}
Sea $f(x,y)=x^2+y^2$. \\\\
\textcolor{verdep2}{\bl} Si $k<0$, entonces $C_k = \emptyset$ \big(ya que $f(x,y) \geq 0$\big) \\\\
\textcolor{verdep2}{\bl} Si $k=0$, entonces $C_k=\{(0,0)\}$ \\\\ 
\textcolor{verdep2}{\bl} Si $k > 0$, entonces $C_k$ es un circulo centrado en $(0,0)$ y de radio $\sqrt{k}$\\\\ \big(las curvas de nivel nos ayudan a entender el grafico de $f$).
\end{ej}
  \begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v70.pdf_tex}}
\end{figure} \pagebreak
\begin{defi}
  Sea $k \in \mathbb{R}$ y $ f : Dom(f) \subseteq \mathbb{R}^3 \to \mathbb{R}$. Llamamos superficie de nivel $k$ de $f$ al subconjunto de $Dom(f)$ definido por \[
    S_k:=\big\{(x,y,z) \in Dom(f) : f(x,y,z)=k\big\}
  \]
\end{defi}
\begin{ej}
  Si $f(x,y,z)=x^2+y^2+z^2$ tenemos que \\\\
  \textcolor{verdep2}{\bl} Si $k<0$, $S_k=\emptyset$ \\\\
  \textcolor{verdep2}{\bl} Si $k=0$, $S_k=\big\{(0,0,0)\big\}$\\\\
  \textcolor{verdep2}{\bl} Si $k>0$, $S_k$ es una esfera centrada en $(0,0,0)$ y de radio $\sqrt{k}$
\end{ej}
\begin{obs}
  Notar que dado $P \in Dom(f)$, existe a lo sumo una curva (o superficie) de nivel que pasa por $P$. \\\\
  \textcolor{rojop2}{\bl} Dada $f: Dom(f) : \mathbb{R}^2 \to \mathbb{R}$, y $k \in \mathbb{R}$, consideramos $C_k$. Sea $\gamma$ una curva incluida en $C_k$. O sea, $\gamma$ es la imagen de una funcion vectorial $r(t)=\big(x(t),y(t))$, con $t$ en algun intervalo $I \subseteq \mathbb{R}$. Sea $t_0 \in I$ y denotamos $(x_0,y_0)=\big(x(t_0),y(t_0)\big)$
    . Como $\gamma(t)=\big(\gamma(t)=(x,t),y(t)\big) \in C_k \; \forall t \in I,$ tenemos que $f\big(x(t),y(t)\big)=k \; \forall t \in I$.\\\\Luego, por la regla de la cadena, \[
      \frac{\partial f}{\partial x}\big(x(t),y(t)\big) \cdot x'(t) + \frac{\partial f}{\partial y} \big(x(t),y(t)\big) \cdot y'(t) = 0\; \forall t \in I 
    \]
    En particular, para $t=t_0$ tenemos \[
      \frac{\partial f}{\partial x}\big(x(t_0),y(t_0)\big) \cdot x'(t_0) + \frac{\partial f}{\partial y} \big(x(t_0),y(t_0)\big) \cdot y'(t_0) = 0 
    \]
    O sea, \[
\big\langle \nabla f(x_0,y_0),\gamma'(t_0) \big\rangle =0.
\]Luego, si $\nabla f(x_0,y_0)\neq0$, tenemos que $\nabla f(x_0,y_0)$ es perpendicular (ortogonal) al vector tangente a la curva $\gamma$, y por lo tanto a la curva de nivel de $f$, que pasa por $(x_0,y_0)$.\\\\ Entonces, el vector $\left(-\frac{\partial f}{\partial y}(x_0,y_0),\frac{\partial f}{\partial x}(x_0,y_0)\right)$ es tangente a la curva de nivel $f$ que pasa por $(x_0,y_0)$. \\\\ Notar que este vector es perpendicular a $$ \nabla f(x_0,y_0)=\left(\frac{\partial f}{\partial x}(x_0,y_0),\frac{\partial f}{\partial x}(x_0,y_0)\right).$$
  \end{obs}\pagebreak
  \underline{Graficamente}:
  \begin{figure}[h]
\centering
\def\svgwidth{0.75\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v71.pdf_tex}}
\end{figure} \\ \pagebreak
\begin{defi}
  La recta tangente a la curva de nivel de $f$ que pasa por $(x_0,y_0)$ esta definida como \[
    (x,y)=(x_0,y_0)+t\left(-\frac{\partial f}{\partial y}(x_0,y_0),\frac{\partial f}{\partial x}(x_0,y_0)\right),\;\text{ con } t \in \mathbb{R}
  \]
\end{defi}
\begin{ej}
  Sea $f(x,y)=\frac{x-y}{x+y}$ y $P=(1,1)$. Calcular \\\\
  \emph{(i)\phantom{ii}} el gradiente de $f$ en $P$;\\\\
  \emph{(ii)\phantom{i}} la ecuacion de la recta tangente a la curva de nivel que pasa por $P$; \\\\
  \emph{(iii)} la ecuacion del plano tangente al grafico de $f$ en $P$.\\\\
  \underline{Respuestas}:\\\\ \emph{(i)\phantom{ii}} Tenemos que \mbox{$f_x(x,y)=\frac{x+y-(x-y)}{(x+y)^2}=\frac{2y}{(x+y)^2}$} y \mbox{$f_y(x,y)=\frac{-1\cdot(x+y)-(x-y)}{(x+y)^2}=-\frac{2x}{(x+y)^2}.$} \\\\ Por lo tanto $\nabla f(x,y)=\left(\frac{2y}{(x+y)^2},-\frac{2x}{(x+y)^2}\right)$ y en particular \mbox{$\nabla f(1,1)=\left(\frac{2}{4},-\frac{2}{4}\right)=\left(\frac{1}{2},-\frac{1}{2}\right).$} \\\\
  \emph{(ii)\phantom{i}} La ecuacion de la recta tangente a la curva de nivel que pasa por $P=(1,1)$ es \[
    (x,y)=(1,1)+t\left(\frac{1}{2},\frac{1}{2}\right), \; \text{ con } t \in \mathbb{R}.
    \]\emph{(iii)} La ecuacion del plano tangente al grafico de $f$ en $P$ es \[\begin{aligned}
    z & =f\overbrace{(1,1)}^{=0}+f_x(1,1)(x-1)+f_y(1,1)(y-1) \\
     & = \frac{1}{2}(x-1)-\frac{1}{2}(y-1).
  \end{aligned}\]
\end{ej} 
\textcolor{rojop2}{\bl} Dada $f : Dom(f) \subseteq \mathbb{R}^3 \to \mathbb{R}$ y $k \in \mathbb{R}$, consideramos $S_k$. Es facil ver que si $(x_0,y_0,z_0) \in S_k$ y $\nabla f(x_0,y_0,z_0) \neq 0$ entonces $\nabla f(x_0,y_0,z_0)$ es un vector perpendicular (ortogonal) al plano tangente a la superficie de nivel $S_k$ (al igual que para $n=2$ podemos considerar $\gamma(t)=\big(x(t),y(t),z(t)\big)$ tq su imagen este contenida en $S_k$ \; $\forall t \in I$ algun intervalo de $\mathbb{R}$, o sea $f\big(x(t),y(t),z(t)\big)=k \; \forall t \in I$. Luego derivando con respecto a $t$ obtenemos el resultado buscado). \pagebreak 
\begin{defi}
  La ecuacion del plano tangente a la superficie de nivel que pasa por $(x_0,y_0,z_0)$ es: \[
\big\langle (x,y,z)-(x_0,y_0,z_0), \nabla f(x_0,y_0,z_0) \big\rangle =0.
  \] Notar que $\nabla f(x_0,y_0,z_0)$ es el vector normal al plano.
\end{defi}
  \begin{figure}[h]
\centering
\def\svgwidth{0.65\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v72.pdf_tex}}
\end{figure} 
\begin{obs}
  Supongamos que $S$ es el grafico de una funcion $g : \mathbb{R}^2 \to \mathbb{R}$. O sea $S=\big\{(x,y,z) : z=g(x,y)\big\}.$ \\\\ Sea $(x_0,y_0,z_0)=\big(x_0,y_0,g(x_0,y_0)\big) \in S$. Vimos que el plano tangente al grafico de $g$ en el punto $\big(x_0,y_0,g(x_0,y_0)\big)$ es \[
    z=g(x_0,y_0)+g_x(x_0,y_0)(x-x_0)+g_y(x_0,y_0)(y-y_0). \quad \textcolor{rojop2}{(\triangle)}
    \] Si definimos ahora $f : \mathbb{R}^3 \to \mathbb{R}$ como $f(x,y,z)=z-g(x,y)$ tenemos que $S$ (grafico de $g$) es justamente $S_0$ la superficie de nivel $0$ de $f$. Por lo visto recien, el plano tangente a $(x_0,y_0,z_0) \in S_0=S$ esta dado por \[
\big\langle (x,y,z)-(x_0,y_0,z_0),\nabla f(x_0,y_0,z_0) \big\rangle =0
\]y como $z_0=g(x_0,y_0)$, $f_x(x,y,z)=-g_x(x,y)$, \mbox{$f_y(x,y,z)=-g_y(x,y)$}, \mbox{$f_z(x,y,z)=1$,} obtenemos \[
\big\langle \big(x-x_0,y-y_0,z-g(x_0,y_0)\big),\big(-g_x(x_0,y_0),-g_y(x_0,y_0),1\big) \big\rangle =0 \text{ que es justamente }\textcolor{rojop2}{(\triangle)}
\] Por lo tanto, las dos definiciones de plano tangente coinciden.
\end{obs}
\begin{ej}
  Dar la ecuacion del plano tangente a la esfera $S$ de centro $0$ y radio $1$, en el punto $(0,0,1)$. \\\\
  \textcolor{rojop2}{\bl} Consideremos la funcion $f : \mathbb{R}^3 \to \mathbb{R}$ definida por $f(x,y,z)=x^2+y^2+z^2$.\\\\ Tenemos que $S$ es justamente la superficie de nivel $S_1$ de $f$, o sea \[
    S=S_1=\big\{(x,y,z) \in \mathbb{R}^3 : f(x,y,z)=1\big\}=\big\{(x,y,z) \in \mathbb{R}^3 : \underset{\underset{\textcolor{rojop2}{\text{la ``cascara''}}}{\textcolor{rojop2}{\text{solo}}}}{x^2+y^2+z^2 = 1}\big\}
    \]Por lo tanto la ecuacion del plano tangente a $S$ en $(0,0,1)$ es \[
\big\langle (x,y,z)-(0,0,1),\nabla f(0,0,1) \big\rangle = 0.
\] Como $\nabla f(x,y,z)=(2x,2y,2z)$, tenemos que $\nabla f (0,0,1)=(0,0,2)$ y por lo tanto la ecuacion queda \[
\begin{aligned}
  \big\langle (x,y,z) - (0,0,1),(0,0,2)\big\rangle & = 0 \\
  (z-1)\cdot 2 & = 0 \\
  z & = 1
\end{aligned}
\]
\end{ej} \; 
  \begin{figure}[h]
\centering
\def\svgwidth{0.65\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v73.pdf_tex}}
\end{figure} \;  
\\\\\\\\\\\\\\\\\\
\underline{Ejercicio}:
  Dar la ecuacion del plano tangente al grafico de la\\ funcion $g(x,y)=\sqrt{1-x^2-y^2}$ en el punto $(0,0,1).$
  \begin{figure}[h]
\centering
\def\svgwidth{0.65\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v74.pdf_tex}}
\end{figure} 
\begin{center}
\textbf{Derivadas de orden $2$.}
\end{center}
\textcolor{rojop2}{\bl} Dada una funcion $f$ de $n$ variables, es decir $f(x_1,\dots,x_n)$, y tal que existen sus derivadas parciales $\frac{\partial f}{\partial x_1},\dots,\frac{\partial f}{\partial x_n}$ (que son funciones de $n$ variables), podemos preguntarnos si existen las derivadas parciales de cada funcion $\frac{\partial f}{\partial x_i}$, $1 \leq i \leq n$. \\\\ Estas se llaman derivadas parciales segundas (o de orden $2$) de $f$. \\\\
\textcolor{verdep2}{\bl} Si $n=2$, hay $4$ derivadas parciales de orden $2$: \\\\ $\begin{aligned} 
  (f_x)_x := f_{xx} := \frac{\partial f}{\partial x} \left(\frac{\partial f}{\partial x}\right) & = \frac{\partial^2 f}{\partial x^2} \\
  (f_x)_y := f_{xy} := \frac{\partial f}{\partial y} \left(\frac{\partial f}{\partial x}\right) & = \frac{\partial^2 f}{\partial y \partial x} \\
  (f_y)_x := f_{yx} := \frac{\partial f}{\partial x}\left(\frac{\partial f}{\partial y }\right) & =\frac{\partial^2 f}{\partial x \partial y} \\
  (f_y)_y := f_{yy} := \frac{\partial f}{\partial y}\left(\frac{\partial f}{\partial y }\right) & =\frac{\partial^2 f}{\partial y^2} \\
\end{aligned}$ \\\\
\textcolor{verdep2}{\bl} Si $n=3$, hay $9$ derivadas parciales de orden $2 : f_{xx},f_{xy},f_{xz},f_{yx},f_{yy}$, etc. \\\\
\textcolor{verdep2}{\bl} En general, si $f$ tiene $n$ variables, entonces hay $n^2$ derivadas parciales de orden $2$. \pagebreak
\begin{ej}
  \;\\ 
  \textcolor{verdep2}{(1)} Calcular las derivadas parciales de orden $2$ de $z = x^2 (1+y^2)=f(x,y)$.\\\\
  Tenemos que $z_x=2x(1+y^2)$ \; y \; $z_y=x^22y$.\\\\ Luego,\\\\ $\begin{aligned}
    z_{xx} & = 2(1+y^2) \\
    z_{xy} & = 2x2y=4xy \\
    z_{zx} & = 2x2y=4xy \\
    z_{zz} & = 2x^2.
  \end{aligned}$
  \\\\\\
  \textcolor{verdep2}{(2)} Si $z=f(x,y)$, con $x(s,t)=2s+3t$, $y(s,t)=3s-2t$, calcular $\frac{\partial^2 z}{\partial s \partial t}$.\\\\
  Primero debemos calcular $\frac{\partial z}{\partial t}$ y luego a esta funcion calcularle la derivada parcial con respecto a $s$. \\\\ Entonces, por la regla de la cadena (caso 2) \[
    \frac{\partial z}{\partial t}(s,t)=\frac{\partial f}{\partial x}\big(x(s,t),y(s,t)\big) \cdot \frac{\partial x}{\partial t}(s,t)+\frac{\partial f}{\partial y}\big(x(s,t),y(s,t)\big) \cdot \frac{\partial y}{\partial t}(s,t) \quad \textcolor{rojop2}{(\star)}
    \] donde $\frac{\partial x}{\partial t}(s,t)=3$ \; y \; $\frac{\partial y}{\partial t}(s,t)=-2.$ \\\\ Luego, \textcolor{rojop2}{$(\star)$} queda \[
    \frac{\partial z}{\partial t}(s,t)=3\frac{\partial f}{\partial x}\big(x(s,t),y(s,t)\big)-2\frac{\partial f}{\partial y}\big(x(s,t),y(s,t)\big).
    \]Calculemos la derivada parcial con respecto a $s$ de la funcion $\frac{\partial z}{\partial t}$ \[
    \frac{\partial^2z}{\partial s\partial t}=3\left[\frac{}{}\cdot \frac{\partial^2 f}{\partial x^2} + \frac{\partial x}{\partial s} \cdot \frac{\partial^2 f}{\partial y \partial x}\right]-2\left[\frac{\partial^2 f}{\partial x \partial y} \cdot \frac{\partial x}{\partial y} + \frac{\partial^2 f}{\partial y^2} \cdot \frac{\partial y}{\partial s}\right]
    \] donde $\frac{\partial x}{\partial s}(s,t)=2$ \; y \; $\frac{\partial y}{\partial s}(s,t)=3$.\\\\ Finalmente, \[
    \frac{\partial^2 z}{\partial s \partial t}=3\left[2 \frac{\partial^2 f}{\partial x^2}+3 \frac{\partial^2 f}{\partial y \partial x}\right]-2\left[2 \frac{\partial^2 f}{\partial x \partial y}+3\frac{\partial^2 f}{\partial y^2}\right].
  \]
\end{ej}
\begin{teo}
  Sea $f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$ y $\bar{a} \in Dom(f)$. Si las funciones $f_{xy}$ y $f_{yx}$ son ambas continuas en $B(\bar{a},r)  \subseteq Dom(f)$ para algun $r>0$, entonces \[
    f_{xy}(\bar{x})=f_{yx}(\bar{x}), \; \forall x \in B(\bar{a},r)
  \]
\end{teo}
\begin{center}
\textbf{Maximos y minimos de funciones de dos variables ($n=2$).}
\end{center}
\underline{Repaso}: sea $f : (\alpha, \beta) \to \mathbb{R}$ y sea $x_0 \in (\alpha,\beta)$. Si $f$ tiene un minimo local o un maximo local en $x_0$ entonces: 
  \begin{figure}[h]
\centering
\def\svgwidth{1\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v75.pdf_tex}}
\end{figure} \; \pagebreak
\begin{defi}
  Sea $f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$ y $(x_0,y_0) \in Dom(f)$. Decimos que \\\\
  \textcolor{rojop2}{\bl} $f$ tiene un maximo local (o relativo) en $(x_0,y_0)$ si existe una bola (disco) $B$ centrada en $(x_0,y_0)$, con $B \subseteq Dom(f)$ y tal que  $$f(x_0,y_0) \geq f(x,y) \quad \forall (x,y) \in B.$$ El numero $f(x_0,y_0)$ se llama valor maximo local de $f$. \\\\
  \textcolor{rojop2}{\bl} $f$ tiene un minimo local (o relativo) en $(x_0,y_0)$ si existe una bola $B$ centrada en $(x_0,y_0)$, con $B \subset Dom(f)$ y tal que \[
  f(x_0,y_0) \leq f(x,y) \quad \forall (x,y) \in B.
  \]
  El numero $f(x_0,y_0)$ se llama valor minimo local de $f$.\\\\
  \textcolor{rojop2}{\bl} SI las desigualdades se cumplen $\forall (x,y) \in Dom(f)$, entonces decimos que $f$ tiene un maximo absoluto (o minimo absoluto, segun corresponda) en $(x_0,y_0)$.
\end{defi}
\begin{obs}
  Decimos que $f$ tiene un extremo local en $(x_0,y_0)$ si $f$ tiene un maximo local o un minimo local en $(x_0,y_0)$.
\end{obs}
\begin{teo}
  Si $f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$ tiene un extremo local en $(x_0,y_0)$ y existen las derivadas parciales de $f$ en $(x_0,y_0)$, entonces $$f_x(x_0,y_0)=f_y(x_0,y_0)=0.$$
\end{teo}
\begin{demo} \;\\
  Sea $g(x)=f(x,y_0)$. Entonces, $g$ tiene un extremo local en $x=x_0$. Luego, \[
    0=g'(x_0)=f_x(x_0,y_0).
  \]
  De la misma forma tambien deducimos que $f_y(x_0,y_0)=0$
  \qed
\end{demo} \pagebreak
\begin{defi}
  Dada $f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$, $(x_0,y_0)$ se llama punto critico de $f$ si $$f_x(x_0,y_0)=f_y(x_0,y_0)=0 \quad \big(\text{o sea }\nabla f(x_0,y_0)=0\big).$$ Decimos demas que $(x_0,y_0)$ es punto singular de $f$ si $\nexists f_x(x_0,y_0)$ o $ \nexists f_y(x_0,y_0)$.
\end{defi}
\underline{Conclusion}: Si $f: Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$ tiene un extremo local en $(x_0,y_0)$, entonces \\\\ \textcolor{rojop2}{\bl} o bien $(x_0,y_0)$ es punto critico de $f$ \big(y por lo tanto $\nabla f(x_0,y_0)=0$\big) \\\\
\textcolor{rojop2}{\bl} o bien $(x_0,y_0)$ es punto singular de $f$ \big(y por lo tanto $\nexists \nabla f(x_0,y_0)$\big).
\\\\
\underline{Repaso}: Si $f : \mathbb{R} \to \mathbb{R}$ y $x_0$ es punto critico de $f$ \big(o sea $f'(x_0)=0$\big) y si ademas $$\left\{
\begin{array}{lcl} 
  f''(x_0)>0 & \Rightarrow & x_0 \text{ es minimo local de } f \\
  f''(x_0)<0 & \Rightarrow & x_0 \text{ es maximo local de } f \\
  f''(x_0)=0 & \Rightarrow & x_0 \text{ no podemos asegurar nada. } 
\end{array}\right.$$
\textcolor{rojop2}{\bl} Veamos un resultado similar para $f : \mathbb{R}^2 \to \mathbb{R}$.
\begin{teo}
  [Test de las derivadas segundas] \;\\
  \bl Sean $ f : Dom(f) \subseteq \mathbb{R}^2 \to \mathbb{R}$ y $(x_0,y_0) \in Dom(f)$. Supongamos que las derivadas parciales de $1^{\text{er}}$ y $2^{\text{do}}$ orden de $f$ son continuas en una \\ bola $B \subset Dom(f)$ de centro $(x_0,y_0)$ y supongamos ademas que \\ $\nabla f (x_0,y_0)=(0,0)$ \quad \big(o sea, $(x_0,y_0)$ es punto critico de $f$\big).\\\\
  Sea $$  D := D(x_0,y_0) :=f_{xx}(x_0,y_0)f_{yy}(x_0,y_0)-
\big[f_{xy}(x_0,y_0)\big]^2
$$ entonces:\\\\
\textcolor{rojop2}{(1)}  Si $D>0$ y $f_{xx}(x_0,y_0) > 0$ \; \big(o $f_{yy}(x_0,y_0)>0\big) \Rightarrow  f$ tiene un minimo local en $(x_0,y_0)$. \\\\
\textcolor{rojop2}{(2)} Si $D>0$ y $f_{xx}(x_0,y_0) < 0$ \; \big(o $f_{yy}(x_0,y_0)<0\big) \Rightarrow  f$ tiene un maximo local en $(x_0,y_0)$. \\\\
\textcolor{rojop2}{(3)} Si $D<0$, entonces $f$ \underline{no} es un maximo local ni un minimo local en $(x_0,y_0)$. En este caso decimos que $f$ tiene un punto silla en $(x_0,y_0)$. \\\\
\textcolor{rojop2}{(4)} Si $D=0$, no se puede asegurar nada.
\end{teo}
\pagebreak
\begin{obs}
Para recordar la formula que define $D(x_0,y_0)$ notemos que $D(x_0,y_0)$ es el determinante de la matriz \[
  H(x_0,y_0)=\left[\begin{array}{ll}
  f_{xx}(x_0,y_0) & f_{xy}(x_0,y_0) \\
  f_{yx}(x_0,y_0) & f_{yy}(x_0,y_0)
\end{array}\right] \begin{array}{ll}
  \rightarrow & \nabla f_x=(f_{xx},f_{xy}) \\
\rightarrow & \nabla f_{y} = (f_{yx},f_{yy})
\end{array}
\]
ya que $$det\big(H(x_0,y_0)\big) =f_{xx}(x_0,y_0)f_{yy}(x_0,y_0)-\underbrace{f_{yx}(x_0,y_0)f_{xy}(x_0,y_0)}_{\big[f_{xy}(x_0,y_0)\big]^2 \quad\textcolor{rojop2}{(\star)}}$$ 
$\textcolor{rojop2}{(\star)}$ Pues $f_{xy}(x_0,y_0)=f_{yx}(x_0,y_0)$ por Teo. anterior (pagina 120). \\\\
\textcolor{rojop2}{\bl} La matriz $H$ se llama hessiana de $f$ en $(x_0,y_0)$ y su determinante se llama hessiano (o discriminante) de $f$ en $x_0,y_0$.
\end{obs}
\begin{ej} Caso \textcolor{rojop2}{(3)}. Sea $f(x,y)=y^2-x^2$\\\\
  \bl Tenemos que $\nabla f(x,y)=(-2x,2y)$. Luego, $\nabla f (0,0)=(0,0),$ o sea $(0,0)$ es punto critico de $f$. \\\\
   \bl Ademas, $f_{xx}(x,y)=-2, \; f_{yy}(x,y)=2)$ \; y \; $f_{xy}(x,y)=f_{yx}(x,y)=0$. \\\\
   \bl Por lo tanto, $D(0,0)=det\left(\begin{array}{rl}
       -2 & 0 \\
       0 & 2
   \end{array}\right)=-4<0$ y entonces estamos en el caso \textcolor{rojop2}{(3)}. \\\\
   Analicemos el comportamiento de $f$ cuando nos acercamos al punto $(0,0)$.\\\\
   \textcolor{verdep2}{\bl} Si nos acercamos por el eje $y$ tenemos $f(0,y)=\phantom{-}y^2\geq0=f(0,0)$ luego $(0,0)$ \underline{NO} es maximo local.\\\\
   \textcolor{rojop2}{\bl} Si nos acercamos por el eje $x$ tenemos $f(x,0)=-x^2\leq0=f(0,0)$ luego, $(0,0)$ \underline{NO} es un minimo local.
\end{ej}
  \begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v76.pdf_tex}}
\end{figure} 
\bl En este caso decimos que $(0,0)$ es un punto de silla.
\begin{ej}
  Caso \textcolor{rojop2}{(4)} \\\\
  \textcolor{verdep2}{\emph{(i)\phantom{ii}}} Sea $f(x,y)=x^4+y^4$.\\\\ Es facil ver que $\nabla f (0,0)=(0,0)$ y que \mbox{$f_{xx}(0,0)=f_{yy}(0,0)=f_{xy}(0,0)=f_{yx}(0,0)=0$}.\\\\ Por lo tanto, $D(0,0)=0$ y estamos en el caso $\textcolor{rojop2}{(4)}.$\\\\ Ahora, por como esta definida $f$ tenemos que $f(x,y)=x^4+y^4 \\\\ f(x,y)=x^4+y^4 \geq 0 =f(0,0)$ y entonces $(0,0)$ es un minimo local (y global) de $f$. \\\\
  \textcolor{verdep2}{\emph{(ii)\phantom{i}}} Sea $h(x,y)=-(x^4+y^4)$. \\\\ Es facil ver (ejercicio!) que $D(0,0)=0$ y entonces tambien se cumple el caso \textcolor{rojop2}{(4)}.\\\\Sin embargo, por como esta definida $h$ tenemos que $(0,0)$ es un maximo local (y global) de $f$.\\\\
  \textcolor{verdep2}{\emph{(iii)}} Sea $g(x,y)=y^4-x^4$ \\\\
  Es facil ver (ejercicio!) que $D(0,0)=0$ y entonces estamos en el caso \textcolor{rojop2}{(4)}. \\\\Sin embargo, si graficamos $g$ nos damos cuenta que $(0,0)$ es un punto de silla de $g$ \big(analizar el comportamiento cuando nos acercamos a $(0,0)$\big). \\\\
  \textcolor{azulp2}{\bl} Por lo tanto, de \textcolor{verdep2}{\emph{(i)}},\textcolor{verdep2}{\emph{(ii)}} y \textcolor{verdep2}{\emph{(iii)}} vemos que si $D(x_0,y_0)=0$, el punto $(x_0,y_0)$ podria ser un maximo local, minimo local, o punto silla. Es decir, $D(x_0,y_0)=0$ NO nos asegura nada sobre que tipo de punto es $(x_0,y_0)$.
\end{ej}
\begin{ej}
  Encontrar y clasificar (maximos/minimos relativos, puntos silla) los puntos criticos de la funcion \mbox{$f(x,y)=x^4+y^4-4x^+2$}. \\\\
  \textcolor{azulp2}{\bl} Recordemos que $(x_0,y_0)$ es punto critico de $f$ si $\nabla f (x_0,y_0) =(0,0)$. \\\\ Tenemos que $\nabla f(x,y)=(4x^3-4y,4y^3-4x),$ entonces \[ 
    \nabla f(x,y)=(0,0) \Leftrightarrow \begin{array}{l}
4x^3-4y=0 \\
4y^3-4x=0
\end{array} \Leftrightarrow \underbrace{\begin{array}{l}
  \textcolor{rojop2}{x}^3=y \\
y^3 = x
\end{array}}_{\textcolor{rojop2}{reemplazo}} \Leftrightarrow y^9=y \Leftrightarrow y(y^8-1)=0 
  \] Por lo tanto, los unicos puntos criticos de $f$ son: $(0,0)$, $(1,1)$ y $(-1,-1)$. \\ \pagebreak \\
  Clasifiquemos estos puntos criticos utilizando el test de las $2^{\text{das}}$ derivadas.\\\\ Tenemos que: \\\\
  \bl $f_{xx}(x,y)=12x^2$ \\\\
  \bl $f_{yy}(x,y)=12y^2$ \\\\
  \bl $f_{xy}(x,y)=f_{yx}(x,y)=-4$. \\\\
  Entonces, $D(x,y)=det\left(\begin{array}{cc}
      12x^2 & -4 \\ 
      -4 & 12\cdot 4^2
  \end{array}\right)=144x^2y^2-16$.\\\\
  Luego, \\\\
  \bl $D(0,0)=-16<0$, y por lo tanto $(0,0)$ es punto de silla de $f$. \\\\
  \bl $D(1,1)=144-16>0$, y $f_{xx}(1,1)=12>0$ y por lo tanto $(1,1)$ es minimo local de $f$. \\\\
  \bl $D(-1,-1)=144-16>0$, y $f_{xx}(-1,-1)=12>0$, y por lo tanto $(-1,-1)$ es minimo local de $f$.
\end{ej}\pagebreak
\begin{ej}
  Encontrar la distancia mas corta desde el punto $(1,0,-2)$ al plano $x+2y+z=4$. \\\\ 
\bl Recordemos que si $Q=(x,y,z)$ es un punto en el espacio, la distancia entre $P$ y $Q$ es \[
  d\big(\textcolor{verdep2}{\underbrace{\textcolor{black}{(1,0,-2)}}_{P}},\textcolor{rojop2}{\underbrace{\textcolor{black}{(x,y,z)}}_{Q}}\big)=\sqrt{(x-1)^2+y^2+(z+2)^2}. \quad \textcolor{rojop2}{(\square)}
\]\;
  \begin{figure}[h]
\centering
\def\svgwidth{0.55\textwidth}
\makebox[\textwidth]{
\input{/home/jx/Escritorio/Cosas-Latex/Analisis/Figuras/v77.pdf_tex}}
\end{figure} \\
\bl Ahora, si consideramos que $Q$ esta en el plano $x+2y+z=4$, entonces $Q$ es de la forma $Q=(x,y,4-x-2y)$. Reemplazando en \textcolor{rojop2}{$(\square)$} tenemos que la distancia de $P$ a un punto $Q$ que esta en el plano es: \[
  d\big(P,Q(x,y,z)\big)=\underbrace{\sqrt{(x-1)^2+y^2+(6-x-2y)^2}}_{f(x,y)} \quad \quad (\geq 0)
\]
Por lo tanto, para hallar la distancia mas corta de $P$ al plano basta hallar el minimo de la funcion \textcolor{rojop2}{¿Por que?} \[
f(x,y)=(x-1)^2+y^2+(6-x-2y)^2
\]\textcolor{rojop2}{\big(el punto $(x_0,y_0)$ donde las funciones $d(x,y)$ y $f(x,y)$ toman su minimo valor coinciden, sin embargo no es cierto que $d(x_0,y_0)=f(x_0,y_0)$\big).}
\end{ej}
\begin{ej}
  (Esta en el practico!) : Hallar el punto $(x_0,y_0)$ donde $f$ alcance su minimo valor y calcular $d(x_0,y_0)=$ distancia mas corta de $P=(1,0-2)$ al plano $x+2y+z=4$.
\end{ej}



























\end{document}
